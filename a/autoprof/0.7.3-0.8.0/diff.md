# Comparing `tmp/autoprof-0.7.3-py2.py3-none-any.whl.zip` & `tmp/autoprof-0.8.0-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,84 +1,85 @@
-Zip file size: 152455 bytes, number of entries: 82
+Zip file size: 154126 bytes, number of entries: 83
 -rw-rw-r--  2.0 unx     3171 b- defN 23-Mar-17 23:11 autoprof/AP_config.py
--rw-rw-r--  2.0 unx     5755 b- defN 23-May-21 17:43 autoprof/__init__.py
+-rw-rw-r--  2.0 unx     5755 b- defN 23-May-28 02:02 autoprof/__init__.py
 -rw-rw-r--  2.0 unx      281 b- defN 23-Mar-17 23:11 autoprof/__main__.py
 -rw-rw-r--  2.0 unx     1092 b- defN 23-May-02 20:08 autoprof/fit/__init__.py
--rw-rw-r--  2.0 unx     6682 b- defN 23-May-21 17:43 autoprof/fit/base.py
+-rw-rw-r--  2.0 unx     6406 b- defN 23-May-28 02:02 autoprof/fit/base.py
 -rw-rw-r--  2.0 unx       30 b- defN 23-Apr-08 19:05 autoprof/fit/gp.py
--rw-rw-r--  2.0 unx     6704 b- defN 23-May-21 17:43 autoprof/fit/gradient.py
--rw-rw-r--  2.0 unx     6912 b- defN 23-May-21 17:43 autoprof/fit/hmc.py
--rw-rw-r--  2.0 unx    13206 b- defN 23-May-21 17:43 autoprof/fit/iterative.py
--rw-rw-r--  2.0 unx    31364 b- defN 23-May-21 17:43 autoprof/fit/lm.py
--rw-rw-r--  2.0 unx     4317 b- defN 23-May-21 17:43 autoprof/fit/mhmcmc.py
--rw-rw-r--  2.0 unx     7109 b- defN 23-May-21 17:43 autoprof/fit/nuts.py
+-rw-rw-r--  2.0 unx     6961 b- defN 23-May-28 02:02 autoprof/fit/gradient.py
+-rw-rw-r--  2.0 unx     6939 b- defN 23-May-28 02:02 autoprof/fit/hmc.py
+-rw-rw-r--  2.0 unx    13401 b- defN 23-May-28 02:02 autoprof/fit/iterative.py
+-rw-rw-r--  2.0 unx    31418 b- defN 23-May-28 02:02 autoprof/fit/lm.py
+-rw-rw-r--  2.0 unx     4381 b- defN 23-May-28 02:02 autoprof/fit/mhmcmc.py
+-rw-rw-r--  2.0 unx     7150 b- defN 23-May-28 02:02 autoprof/fit/nuts.py
 -rw-rw-r--  2.0 unx     1150 b- defN 23-May-21 17:33 autoprof/image/__init__.py
--rw-rw-r--  2.0 unx    11195 b- defN 23-Apr-21 02:55 autoprof/image/image_header.py
--rw-rw-r--  2.0 unx    21644 b- defN 23-May-21 02:29 autoprof/image/image_object.py
+-rw-rw-r--  2.0 unx    11526 b- defN 23-May-28 02:02 autoprof/image/image_header.py
+-rw-rw-r--  2.0 unx    21625 b- defN 23-May-28 02:02 autoprof/image/image_object.py
 -rw-rw-r--  2.0 unx     5269 b- defN 23-Apr-21 02:55 autoprof/image/jacobian_image.py
--rw-rw-r--  2.0 unx     6615 b- defN 23-Apr-21 02:55 autoprof/image/model_image.py
--rw-rw-r--  2.0 unx     6868 b- defN 23-May-21 17:33 autoprof/image/psf_image.py
--rw-rw-r--  2.0 unx    14679 b- defN 23-May-21 17:33 autoprof/image/target_image.py
--rw-rw-r--  2.0 unx    22836 b- defN 23-Apr-21 02:55 autoprof/image/window_object.py
+-rw-rw-r--  2.0 unx     6615 b- defN 23-May-24 20:23 autoprof/image/model_image.py
+-rw-rw-r--  2.0 unx     6721 b- defN 23-May-28 02:02 autoprof/image/psf_image.py
+-rw-rw-r--  2.0 unx    14763 b- defN 23-May-28 02:02 autoprof/image/target_image.py
+-rw-rw-r--  2.0 unx    22617 b- defN 23-May-28 02:02 autoprof/image/window_object.py
 -rw-rw-r--  2.0 unx      654 b- defN 23-Apr-01 17:55 autoprof/models/__init__.py
--rw-rw-r--  2.0 unx     4277 b- defN 23-May-21 17:43 autoprof/models/_model_methods.py
--rw-rw-r--  2.0 unx    20408 b- defN 23-May-10 21:56 autoprof/models/_shared_methods.py
--rw-rw-r--  2.0 unx    21301 b- defN 23-May-21 17:43 autoprof/models/core_model.py
--rw-rw-r--  2.0 unx     5971 b- defN 23-May-10 21:56 autoprof/models/edgeon_model.py
--rw-rw-r--  2.0 unx    12945 b- defN 23-May-10 21:56 autoprof/models/exponential_model.py
--rw-rw-r--  2.0 unx     2025 b- defN 23-May-10 21:56 autoprof/models/flatsky_model.py
--rw-rw-r--  2.0 unx     8373 b- defN 23-May-10 21:56 autoprof/models/foureirellipse_model.py
--rw-rw-r--  2.0 unx     4905 b- defN 23-May-10 21:56 autoprof/models/galaxy_model_object.py
--rw-rw-r--  2.0 unx    11956 b- defN 23-May-10 21:56 autoprof/models/gaussian_model.py
--rw-rw-r--  2.0 unx    14833 b- defN 23-May-21 17:43 autoprof/models/group_model_object.py
--rw-rw-r--  2.0 unx    26717 b- defN 23-May-21 17:43 autoprof/models/model_object.py
--rw-rw-r--  2.0 unx     3487 b- defN 23-May-10 21:56 autoprof/models/moffat_model.py
--rw-rw-r--  2.0 unx    17419 b- defN 23-May-10 21:56 autoprof/models/nuker_model.py
--rw-rw-r--  2.0 unx    17694 b- defN 23-May-21 17:43 autoprof/models/parameter_object.py
--rw-rw-r--  2.0 unx     2292 b- defN 23-May-10 21:56 autoprof/models/planesky_model.py
--rw-rw-r--  2.0 unx     3590 b- defN 23-May-21 17:33 autoprof/models/psf_model.py
--rw-rw-r--  2.0 unx     4653 b- defN 23-May-10 21:56 autoprof/models/ray_model.py
--rw-rw-r--  2.0 unx    14762 b- defN 23-May-10 21:56 autoprof/models/sersic_model.py
+-rw-rw-r--  2.0 unx     3360 b- defN 23-May-28 02:02 autoprof/models/_model_methods.py
+-rw-rw-r--  2.0 unx    19225 b- defN 23-May-28 02:02 autoprof/models/_shared_methods.py
+-rw-rw-r--  2.0 unx    12359 b- defN 23-May-28 02:02 autoprof/models/core_model.py
+-rw-rw-r--  2.0 unx     6986 b- defN 23-May-28 02:02 autoprof/models/edgeon_model.py
+-rw-rw-r--  2.0 unx    14433 b- defN 23-May-28 02:02 autoprof/models/exponential_model.py
+-rw-rw-r--  2.0 unx     2123 b- defN 23-May-28 02:02 autoprof/models/flatsky_model.py
+-rw-rw-r--  2.0 unx    10650 b- defN 23-May-28 02:02 autoprof/models/foureirellipse_model.py
+-rw-rw-r--  2.0 unx     5362 b- defN 23-May-28 02:02 autoprof/models/galaxy_model_object.py
+-rw-rw-r--  2.0 unx    13269 b- defN 23-May-28 02:02 autoprof/models/gaussian_model.py
+-rw-rw-r--  2.0 unx    11139 b- defN 23-May-28 02:02 autoprof/models/group_model_object.py
+-rw-rw-r--  2.0 unx    27706 b- defN 23-May-28 02:02 autoprof/models/model_object.py
+-rw-rw-r--  2.0 unx     3927 b- defN 23-May-28 02:02 autoprof/models/moffat_model.py
+-rw-rw-r--  2.0 unx    18974 b- defN 23-May-28 02:02 autoprof/models/nuker_model.py
+-rw-rw-r--  2.0 unx    12454 b- defN 23-May-28 02:02 autoprof/models/parameter_group.py
+-rw-rw-r--  2.0 unx    18097 b- defN 23-May-28 02:02 autoprof/models/parameter_object.py
+-rw-rw-r--  2.0 unx     2488 b- defN 23-May-28 02:02 autoprof/models/planesky_model.py
+-rw-rw-r--  2.0 unx     3785 b- defN 23-May-28 02:02 autoprof/models/psf_model.py
+-rw-rw-r--  2.0 unx     5021 b- defN 23-May-28 02:02 autoprof/models/ray_model.py
+-rw-rw-r--  2.0 unx    16233 b- defN 23-May-28 02:02 autoprof/models/sersic_model.py
 -rw-rw-r--  2.0 unx      875 b- defN 23-Mar-17 23:11 autoprof/models/sky_model_object.py
--rw-rw-r--  2.0 unx    10300 b- defN 23-May-10 21:56 autoprof/models/spline_model.py
--rw-rw-r--  2.0 unx     1125 b- defN 23-Mar-17 23:11 autoprof/models/star_model_object.py
--rw-rw-r--  2.0 unx     3073 b- defN 23-Mar-17 23:11 autoprof/models/superellipse_model.py
--rw-rw-r--  2.0 unx     4412 b- defN 23-May-10 21:56 autoprof/models/warp_model.py
--rw-rw-r--  2.0 unx     3546 b- defN 23-Apr-21 02:55 autoprof/models/wedge_model.py
+-rw-rw-r--  2.0 unx    10695 b- defN 23-May-28 02:02 autoprof/models/spline_model.py
+-rw-rw-r--  2.0 unx     1226 b- defN 23-May-28 02:02 autoprof/models/star_model_object.py
+-rw-rw-r--  2.0 unx     3259 b- defN 23-May-28 02:02 autoprof/models/superellipse_model.py
+-rw-rw-r--  2.0 unx     4700 b- defN 23-May-28 02:02 autoprof/models/warp_model.py
+-rw-rw-r--  2.0 unx     4004 b- defN 23-May-28 02:02 autoprof/models/wedge_model.py
 -rw-rw-r--  2.0 unx       57 b- defN 23-Feb-16 02:48 autoprof/parse_config/__init__.py
 -rw-rw-r--  2.0 unx     4147 b- defN 23-Mar-17 23:11 autoprof/parse_config/basic_config.py
 -rw-rw-r--  2.0 unx     4590 b- defN 23-Mar-17 23:11 autoprof/parse_config/galfit_config.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Feb-16 02:48 autoprof/parse_config/shared_methods.py
 -rw-rw-r--  2.0 unx       67 b- defN 22-Oct-27 02:37 autoprof/plots/__init__.py
--rw-rw-r--  2.0 unx     6903 b- defN 23-May-21 17:43 autoprof/plots/image.py
--rw-rw-r--  2.0 unx     7559 b- defN 23-May-01 22:29 autoprof/plots/profile.py
+-rw-rw-r--  2.0 unx     6959 b- defN 23-May-28 02:02 autoprof/plots/image.py
+-rw-rw-r--  2.0 unx     7557 b- defN 23-May-28 02:02 autoprof/plots/profile.py
 -rw-rw-r--  2.0 unx     3048 b- defN 23-Mar-17 23:11 autoprof/plots/shared_elements.py
--rw-rw-r--  2.0 unx    19994 b- defN 23-May-02 20:08 autoprof/plots/visuals.py
+-rw-rw-r--  2.0 unx    21022 b- defN 23-May-28 02:02 autoprof/plots/visuals.py
 -rw-rw-r--  2.0 unx        0 b- defN 22-Sep-15 14:58 autoprof/utils/__init__.py
 -rw-rw-r--  2.0 unx      800 b- defN 23-Mar-30 13:28 autoprof/utils/angle_operations.py
--rw-rw-r--  2.0 unx      472 b- defN 23-May-10 21:56 autoprof/utils/decorators.py
--rw-rw-r--  2.0 unx     9820 b- defN 23-May-10 20:09 autoprof/utils/interpolate.py
--rw-rw-r--  2.0 unx     6369 b- defN 23-Apr-28 21:02 autoprof/utils/operations.py
+-rw-rw-r--  2.0 unx      976 b- defN 23-May-28 02:02 autoprof/utils/decorators.py
+-rw-rw-r--  2.0 unx     9815 b- defN 23-May-28 02:02 autoprof/utils/interpolate.py
+-rw-rw-r--  2.0 unx     6633 b- defN 23-May-28 02:02 autoprof/utils/operations.py
 -rw-rw-r--  2.0 unx      963 b- defN 23-Mar-17 23:11 autoprof/utils/optimization.py
--rw-rw-r--  2.0 unx     5990 b- defN 23-Apr-01 17:55 autoprof/utils/parametric_profiles.py
+-rw-rw-r--  2.0 unx     5990 b- defN 23-May-28 01:51 autoprof/utils/parametric_profiles.py
 -rw-rw-r--  2.0 unx        0 b- defN 22-Dec-16 16:54 autoprof/utils/conversions/__init__.py
 -rw-rw-r--  2.0 unx     2317 b- defN 23-Mar-17 23:11 autoprof/utils/conversions/coordinates.py
 -rw-rw-r--  2.0 unx     1095 b- defN 23-Mar-21 14:13 autoprof/utils/conversions/dict_to_hdf5.py
 -rw-rw-r--  2.0 unx     1829 b- defN 23-Mar-30 13:28 autoprof/utils/conversions/functions.py
--rw-rw-r--  2.0 unx     3154 b- defN 23-May-11 14:59 autoprof/utils/conversions/optimization.py
+-rw-rw-r--  2.0 unx     3260 b- defN 23-May-28 02:02 autoprof/utils/conversions/optimization.py
 -rw-rw-r--  2.0 unx     2536 b- defN 23-Mar-30 13:28 autoprof/utils/conversions/units.py
 -rw-rw-r--  2.0 unx      281 b- defN 23-May-04 13:15 autoprof/utils/initialize/__init__.py
 -rw-rw-r--  2.0 unx     3103 b- defN 23-Mar-30 13:28 autoprof/utils/initialize/center.py
--rw-rw-r--  2.0 unx     4495 b- defN 23-May-04 13:20 autoprof/utils/initialize/construct_psf.py
+-rw-rw-r--  2.0 unx     4542 b- defN 23-May-28 02:02 autoprof/utils/initialize/construct_psf.py
 -rw-rw-r--  2.0 unx     3921 b- defN 23-Mar-17 23:11 autoprof/utils/initialize/initialize.py
 -rw-rw-r--  2.0 unx     7036 b- defN 23-Mar-30 13:28 autoprof/utils/initialize/segmentation_map.py
 -rw-rw-r--  2.0 unx        0 b- defN 22-Dec-16 16:54 autoprof/utils/isophote/__init__.py
 -rw-rw-r--  2.0 unx     1085 b- defN 23-Mar-17 23:11 autoprof/utils/isophote/ellipse.py
 -rw-rw-r--  2.0 unx     8531 b- defN 23-Mar-30 13:28 autoprof/utils/isophote/extract.py
 -rw-rw-r--  2.0 unx     7012 b- defN 23-Mar-17 23:11 autoprof/utils/isophote/integrate.py
--rw-rw-r--  2.0 unx    35149 b- defN 23-May-21 17:44 autoprof-0.7.3.dist-info/LICENSE
--rw-rw-r--  2.0 unx     3812 b- defN 23-May-21 17:44 autoprof-0.7.3.dist-info/METADATA
--rw-rw-r--  2.0 unx      110 b- defN 23-May-21 17:44 autoprof-0.7.3.dist-info/WHEEL
--rw-rw-r--  2.0 unx       57 b- defN 23-May-21 17:44 autoprof-0.7.3.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx        9 b- defN 23-May-21 17:44 autoprof-0.7.3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     7177 b- defN 23-May-21 17:44 autoprof-0.7.3.dist-info/RECORD
-82 files, 561960 bytes uncompressed, 141061 bytes compressed:  74.9%
+-rw-rw-r--  2.0 unx    35149 b- defN 23-May-28 02:03 autoprof-0.8.0.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     3812 b- defN 23-May-28 02:03 autoprof-0.8.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx      110 b- defN 23-May-28 02:03 autoprof-0.8.0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       57 b- defN 23-May-28 02:03 autoprof-0.8.0.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx        9 b- defN 23-May-28 02:03 autoprof-0.8.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     7270 b- defN 23-May-28 02:03 autoprof-0.8.0.dist-info/RECORD
+83 files, 575854 bytes uncompressed, 142588 bytes compressed:  75.2%
```

## zipnote {}

```diff
@@ -96,14 +96,17 @@
 
 Filename: autoprof/models/moffat_model.py
 Comment: 
 
 Filename: autoprof/models/nuker_model.py
 Comment: 
 
+Filename: autoprof/models/parameter_group.py
+Comment: 
+
 Filename: autoprof/models/parameter_object.py
 Comment: 
 
 Filename: autoprof/models/planesky_model.py
 Comment: 
 
 Filename: autoprof/models/psf_model.py
@@ -222,26 +225,26 @@
 
 Filename: autoprof/utils/isophote/extract.py
 Comment: 
 
 Filename: autoprof/utils/isophote/integrate.py
 Comment: 
 
-Filename: autoprof-0.7.3.dist-info/LICENSE
+Filename: autoprof-0.8.0.dist-info/LICENSE
 Comment: 
 
-Filename: autoprof-0.7.3.dist-info/METADATA
+Filename: autoprof-0.8.0.dist-info/METADATA
 Comment: 
 
-Filename: autoprof-0.7.3.dist-info/WHEEL
+Filename: autoprof-0.8.0.dist-info/WHEEL
 Comment: 
 
-Filename: autoprof-0.7.3.dist-info/entry_points.txt
+Filename: autoprof-0.8.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: autoprof-0.7.3.dist-info/top_level.txt
+Filename: autoprof-0.8.0.dist-info/top_level.txt
 Comment: 
 
-Filename: autoprof-0.7.3.dist-info/RECORD
+Filename: autoprof-0.8.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## autoprof/__init__.py

```diff
@@ -1,15 +1,15 @@
 import sys
 import argparse
 import requests
 from .parse_config import galfit_config, basic_config
 from . import models, image, plots, utils, fit, AP_config
 
 # meta data
-__version__ = "0.7.3"
+__version__ = "0.8.0"
 __author__ = "Connor Stone"
 __email__ = "connorstone628@gmail.com"
 
 
 def run_from_terminal() -> None:
     """
     Execute AutoProf from the command line with various options.
```

## autoprof/fit/base.py

```diff
@@ -56,32 +56,26 @@
             loss_history (List[float]): A list of the optimization losses.
             message (str): An informational message.
         """
 
         self.model = model
         self.verbose = kwargs.get("verbose", 0)
         self.fit_parameters_identity = fit_parameters_identity
-        
+
         if fit_window is None:
             self.fit_window = self.model.window
         else:
             self.fit_window = fit_window & self.model.window
 
         if initial_state is None:
-            try:
-                initial_state = self.model.get_parameter_vector(
-                    as_representation=True,
-                    parameters_identity=self.fit_parameters_identity,
-                )
-            except AssertionError:
-                self.model.initialize()
-                initial_state = self.model.get_parameter_vector(
-                    as_representation=True,
-                    parameters_identity=self.fit_parameters_identity,
-                )
+            self.model.initialize()
+            initial_state = self.model.parameters.get_vector(
+                as_representation=True,
+                parameters_identity=self.fit_parameters_identity,
+            )
         else:
             initial_state = torch.as_tensor(
                 initial_state, dtype=AP_config.ap_dtype, device=AP_config.ap_device
             )
 
         self.current_state = torch.as_tensor(
             initial_state, dtype=AP_config.ap_dtype, device=AP_config.ap_device
```

## autoprof/fit/gradient.py

```diff
@@ -55,14 +55,15 @@
         super().__init__(model, initial_state, **kwargs)
         self.current_state.requires_grad = True
 
         # set parameters from the user
         self.patience = kwargs.get("patience", None)
         self.method = kwargs.get("method", "NAdam").strip()
         self.optim_kwargs = kwargs.get("optim_kwargs", {})
+        self.report_freq = kwargs.get("report_freq", 10)
 
         # Default learning rate if none given. Equalt to 1 / sqrt(parames)
         if not "lr" in self.optim_kwargs:
             self.optim_kwargs["lr"] = 1.0 / (len(self.current_state) ** (0.5))
 
         # Instantiates the appropriate pytorch optimizer with the initial state and user provided kwargs
         self.optimizer = getattr(torch.optim, self.method)(
@@ -104,18 +105,21 @@
 
         loss = self.compute_loss()
 
         loss.backward()
 
         self.loss_history.append(loss.detach().cpu().item())
         self.lambda_history.append(np.copy(self.current_state.detach().cpu().numpy()))
-        if self.verbose > 0:
-            AP_config.ap_logger.info(f"loss: {loss.item()}")
-        if self.verbose > 1:
-            AP_config.ap_logger.info(f"gradient: {self.current_state.grad}")
+        if (
+            self.iteration % int(self.max_iter / self.report_freq) == 0
+        ) or self.iteration == self.max_iter:
+            if self.verbose > 0:
+                AP_config.ap_logger.info(f"iter: {self.iteration}, loss: {loss.item()}")
+            if self.verbose > 1:
+                AP_config.ap_logger.info(f"gradient: {self.current_state.grad}")
         self.optimizer.step()
 
     def fit(self) -> "BaseOptimizer":
         """
         Perform an iterative fit of the model parameters using the specified optimizer.
 
         The fit procedure continues until a stopping criteria is met,
@@ -142,13 +146,15 @@
                 if len(L) >= 3 and 0 < L[1] - L[0] < 1e-6 and 0 < L[2] - L[1] < 1e-6:
                     self.message = self.message + " success"
                     break
         except KeyboardInterrupt:
             self.message = self.message + " fail interrupted"
 
         # Set the model parameters to the best values from the fit and clear any previous model sampling
-        self.model.set_parameters(torch.tensor(self.res()), as_representation=True)
+        self.model.parameters.set_values(
+            torch.tensor(self.res()), as_representation=True
+        )
         if self.verbose > 1:
             AP_config.ap_logger.info(
                 f"Grad Fitting complete in {time() - start_fit} sec with message: {self.message}"
             )
         return self
```

## autoprof/fit/hmc.py

```diff
@@ -21,15 +21,15 @@
 # !Overwrite pyro configuration behavior!
 # currently this is the only way to provide
 # mass matrix manually
 ###########################################
 def new_configure(self, mass_matrix_shape, adapt_mass_matrix=True, options={}):
     """
     Sets up an initial mass matrix.
-    
+
     :param dict mass_matrix_shape: a dict that maps tuples of site names to the shape of
         the corresponding mass matrix. Each tuple of site names corresponds to a block.
     :param bool adapt_mass_matrix: a flag to decide whether an adaptation scheme will be used.
     :param dict options: tensor options to construct the initial mass matrix.
     """
     inverse_mass_matrix = {}
     for site_names, shape in mass_matrix_shape.items():
@@ -42,17 +42,20 @@
         )
         if adapt_mass_matrix:
             adapt_scheme = WelfordCovariance(diagonal=diagonal)
             self._adapt_scheme[site_names] = adapt_scheme
 
     if len(self.inverse_mass_matrix.keys()) == 0:
         self.inverse_mass_matrix = inverse_mass_matrix
+
+
 BlockMassMatrix.configure = new_configure
 ############################################
 
+
 class HMC(BaseOptimizer):
     """Hamiltonian Monte-Carlo sampler wrapper for the Pyro package.
 
     This MCMC algorithm uses gradients of the Chi^2 to more
     efficiently explore the probability distribution. Consider using
     the NUTS sampler instead of HMC, as it is generally better in most
     aspects.
@@ -72,15 +75,15 @@
         progress_bar (bool, optional): Whether to display a progress bar during sampling. Defaults to True.
         prior (distribution, optional): Prior distribution for the parameters. Defaults to None.
         warmup (int, optional): Number of warmup steps before actual sampling begins. Defaults to 100.
         hmc_kwargs (dict, optional): Additional keyword arguments for the HMC sampler. Defaults to {}.
         mcmc_kwargs (dict, optional): Additional keyword arguments for the MCMC process. Defaults to {}.
 
     """
-    
+
     def __init__(
         self,
         model: "AutoProf_Model",
         initial_state: Optional[Sequence] = None,
         max_iter: int = 1000,
         **kwargs
     ):
@@ -140,31 +143,33 @@
         }
         hmc_kwargs.update(self.hmc_kwargs)
         hmc_kernel = pyro_HMC(step, **hmc_kwargs)
         if self.inv_mass is not None:
             hmc_kernel.mass_matrix_adapter.inverse_mass_matrix = {("x",): self.inv_mass}
 
         # Provide an initial guess for the parameters
-        init_params = {"x": self.model.get_parameter_vector(as_representation=True)}
+        init_params = {"x": self.model.parameters.get_vector(as_representation=True)}
 
         # Run MCMC with the HMC sampler and the initial guess
         mcmc_kwargs = {
             "num_samples": self.max_iter,
             "warmup_steps": self.warmup,
             "initial_params": init_params,
             "disable_progbar": not self.progress_bar,
         }
         mcmc_kwargs.update(self.mcmc_kwargs)
         mcmc = pyro_MCMC(hmc_kernel, **mcmc_kwargs)
-        
+
         mcmc.run(self.model, self.prior)
         self.iteration += self.max_iter
 
         # Extract posterior samples
         chain = mcmc.get_samples()["x"]
 
         with torch.no_grad():
             for i in range(len(chain)):
-                chain[i] = self.model.transform(chain[i], to_representation = False)
+                chain[i] = self.model.parameters.transform(
+                    chain[i], to_representation=False
+                )
         self.chain = chain
-        
+
         return self
```

## autoprof/fit/iterative.py

```diff
@@ -84,20 +84,20 @@
         """
         Perform a single iteration of optimization.
         """
         if self.verbose > 0:
             AP_config.ap_logger.info("--------iter-------")
 
         # Fit each model individually
-        for model in self.model.model_list:
+        for model in self.model.models.values():
             if self.verbose > 0:
                 AP_config.ap_logger.info(model.name)
             self.sub_step(model)
         # Update the current state
-        self.current_state = self.model.get_parameter_vector(as_representation=True)
+        self.current_state = self.model.parameters.get_vector(as_representation=True)
 
         # Update the loss value
         with torch.no_grad():
             if self.verbose > 0:
                 AP_config.ap_logger.info("Update Chi^2 with new parameters")
             self.Y = self.model(
                 parameters=self.current_state,
@@ -164,15 +164,15 @@
                         self.message + f"fail max iterations reached: {self.iteration}"
                     )
                     break
 
         except KeyboardInterrupt:
             self.message = self.message + "fail interrupted"
 
-        self.model.set_parameters(self.res(), as_representation=True)
+        self.model.parameters.set_values(self.res(), as_representation=True)
         if self.verbose > 1:
             AP_config.ap_logger.info(
                 f"Iter Fitting complete in {time() - start_fit} sec with message: {self.message}"
             )
 
         return self
 
@@ -224,15 +224,15 @@
             # subtract masked pixels from degrees of freedom
             self.ndf -= torch.sum(
                 self.model.target[self.model.window].flatten("mask")
             ).item()
 
     def step(self):
         # These store the chunking information depending on which chunk mode is selected
-        param_ids = list(self.model.get_parameter_identity_vector())
+        param_ids = list(self.model.parameters.get_identity_vector())
         _chunk_index = 0
         _chunk_choices = None
         res = None
 
         if self.verbose > 0:
             AP_config.ap_logger.info("--------iter-------")
 
@@ -270,14 +270,18 @@
                     chunk = self.chunks[sub_index]
                 else:
                     if _chunk_index >= len(self.chunks):
                         break
                     # Select the next chunk in order
                     chunk = self.chunks[_chunk_index]
                     _chunk_index += 1
+            else:
+                raise ValueError(
+                    "Unrecognized chunks value, should be one of int, tuple. not: {type(self.chunks)}"
+                )
             if self.verbose > 0:
                 AP_config.ap_logger.info(str(chunk))
             del res
             res = LM(
                 self.model,
                 fit_parameters_identity=chunk,
                 ndf=self.ndf,
@@ -286,15 +290,15 @@
             if self.verbose > 0:
                 AP_config.ap_logger.info(f"chunk loss: {res.res_loss()}")
             if self.verbose > 1:
                 AP_config.ap_logger.info(f"chunk message: {res.message}")
 
         self.loss_history.append(res.res_loss())
         self.lambda_history.append(
-            self.model.get_parameter_vector(as_representation=True)
+            self.model.parameters.get_vector(as_representation=True)
             .detach()
             .cpu()
             .numpy()
         )
         if self.verbose > 0:
             AP_config.ap_logger.info(f"Loss: {self.loss_history[-1]}")
 
@@ -332,14 +336,14 @@
                         self.message + f"fail max iterations reached: {self.iteration}"
                     )
                     break
 
         except KeyboardInterrupt:
             self.message = self.message + "fail interrupted"
 
-        self.model.set_parameters(self.res(), as_representation=True)
+        self.model.parameters.set_values(self.res(), as_representation=True)
         if self.verbose > 1:
             AP_config.ap_logger.info(
                 f"Iter Fitting complete in {time() - start_fit} sec with message: {self.message}"
             )
 
         return self
```

## autoprof/fit/lm.py

```diff
@@ -395,15 +395,15 @@
             self.message = self.message + "fail interrupted"
 
         if self.message.startswith("fail") and self._count_finish > 0:
             self.message = (
                 self.message
                 + ". possibly converged to numerical precision and could not make a better step."
             )
-        self.model.set_parameters(
+        self.model.parameters.set_values(
             self.res(),
             as_representation=True,
             parameters_identity=self.fit_parameters_identity,
         )
         if self.verbose > 1:
             AP_config.ap_logger.info(
                 f"LM Fitting complete in {time() - start_fit} sec with message: {self.message}"
@@ -412,22 +412,22 @@
         return self
 
     def update_uncertainty(self):
         # set the uncertainty for each parameter
         cov = self.covariance_matrix
         if torch.all(torch.isfinite(cov)):
             try:
-                self.model.set_uncertainty(
+                self.model.parameters.set_uncertainty(
                     torch.sqrt(torch.abs(torch.diag(cov))),
                     as_representation=False,
                     parameters_identity=self.fit_parameters_identity,
                 )
             except RuntimeError as e:
                 AP_config.ap_logger.warning(f"Unable to update uncertainty due to: {e}")
-        
+
     @torch.no_grad()
     def undo_step(self) -> None:
         AP_config.ap_logger.info("undoing step, trying to recover")
         assert (
             self.decision_history.count("accept") >= 2
         ), "cannot undo with not enough accepted steps, retry with new parameters"
         assert len(self.decision_history) == len(self.lambda_history)
@@ -575,31 +575,33 @@
 
         # Apply mask if needed
         if self.model.target.has_mask:
             self.J[self.mask] = 0.0
 
         # Note that the most recent jacobian was a full autograd jacobian
         self.full_jac = True
-        
+
     def update_J_natural(self) -> None:
         """
         Update the jacobian using automatic differentiation, produces an accurate jacobian at the current state. Use this method to get the jacobian in the parameter space instead of representation space.
         """
         # Free up memory
         del self.J
         if "cpu" not in AP_config.ap_device:
             torch.cuda.empty_cache()
 
         # Compute jacobian on image
         self.J = self.model.jacobian(
-            torch.clone(self.model.transform(
-                self.current_state,
-                to_representation=False,
-                parameters_identity=self.fit_parameters_identity,
-            )).detach(),
+            torch.clone(
+                self.model.parameters.transform(
+                    self.current_state,
+                    to_representation=False,
+                    parameters_identity=self.fit_parameters_identity,
+                )
+            ).detach(),
             as_representation=False,
             parameters_identity=self.fit_parameters_identity,
             window=self.fit_window,
         ).flatten("data")
 
         # compute the constraint jacobian if needed
         if self.constraints is not None:
@@ -652,15 +654,15 @@
 
     @property
     @torch.no_grad()
     def covariance_matrix(self) -> torch.Tensor:
         if self._covariance_matrix is not None:
             return self._covariance_matrix
         self.update_J_natural()
-        self.update_hess()        
+        self.update_hess()
         try:
             self._covariance_matrix = torch.linalg.inv(self.hess)
         except:
             AP_config.ap_logger.warning(
                 "WARNING: Hessian is singular, likely at least one model is non-physical. Will massage Hessian to continue but results should be inspected."
             )
             self.hess += torch.eye(
@@ -786,24 +788,24 @@
             dtype=AP_config.ap_dtype,
             device=AP_config.ap_device,
         )
 
     def jacobian(self, model: "AutoProf_Model"):
         jac = jacobian(
             lambda P: self.constraint_func(P, *self.constraint_args),
-            model.get_parameter_vector(
+            model.parameters.get_vector(
                 as_representation=self.representation_parameters
             ),
             strategy="forward-mode",
             vectorize=True,
             create_graph=False,
         )
 
-        return jac.reshape(-1, np.sum(model.parameter_vector_len()))
+        return jac.reshape(-1, np.sum(model.parameters.vector_len()))
 
     def __call__(self, model: "AutoProf_Model"):
         return self.constraint_func(
-            model.get_parameter_vector(
+            model.parameters.get_vector(
                 as_representation=self.representation_parameters
             ),
             *self.constraint_args,
         )
```

## autoprof/fit/mhmcmc.py

```diff
@@ -27,15 +27,15 @@
     """
 
     def __init__(
         self,
         model: "AutoProf_Model",
         initial_state: Optional[Sequence] = None,
         max_iter: int = 1000,
-        **kwargs
+        **kwargs,
     ):
         super().__init__(model, initial_state, max_iter=max_iter, **kwargs)
 
         self.epsilon = kwargs.get("epsilon", 1e-2)
         self.progress_bar = kwargs.get("progress_bar", True)
         self.report_after = kwargs.get("report_after", int(self.max_iter / 10))
 
@@ -79,18 +79,22 @@
 
     def append_chain(self, state: torch.Tensor):
         """
         Add a state vector to the MCMC chain
         """
 
         self.chain.append(
-            self.model.transform(
+            self.model.parameters.transform(
                 state,
                 to_representation=False,
-            ).detach().cpu().clone().numpy()
+            )
+            .detach()
+            .cpu()
+            .clone()
+            .numpy()
         )
 
     @staticmethod
     def accept(log_alpha):
         """
         Evaluates randomly if a given proposal is accepted. This is done in log space which is more natural for the evaluation in the step.
         """
```

## autoprof/fit/nuts.py

```diff
@@ -21,15 +21,15 @@
 # !Overwrite pyro configuration behavior!
 # currently this is the only way to provide
 # mass matrix manually
 ###########################################
 def new_configure(self, mass_matrix_shape, adapt_mass_matrix=True, options={}):
     """
     Sets up an initial mass matrix.
-    
+
     :param dict mass_matrix_shape: a dict that maps tuples of site names to the shape of
         the corresponding mass matrix. Each tuple of site names corresponds to a block.
     :param bool adapt_mass_matrix: a flag to decide whether an adaptation scheme will be used.
     :param dict options: tensor options to construct the initial mass matrix.
     """
     inverse_mass_matrix = {}
     for site_names, shape in mass_matrix_shape.items():
@@ -42,31 +42,34 @@
         )
         if adapt_mass_matrix:
             adapt_scheme = WelfordCovariance(diagonal=diagonal)
             self._adapt_scheme[site_names] = adapt_scheme
 
     if len(self.inverse_mass_matrix.keys()) == 0:
         self.inverse_mass_matrix = inverse_mass_matrix
+
+
 BlockMassMatrix.configure = new_configure
 ############################################
 
+
 class NUTS(BaseOptimizer):
     """No U-Turn Sampler (NUTS) implementation for Hamiltonian Monte Carlo
     (HMC) based MCMC sampling.
 
     This is a wrapper for the Pyro package: https://docs.pyro.ai/en/stable/index.html
 
     The NUTS class provides an implementation of the No-U-Turn Sampler
     (NUTS) algorithm, which is a variation of the Hamiltonian Monte
     Carlo (HMC) method for Markov Chain Monte Carlo (MCMC)
     sampling. This implementation uses the Pyro library to perform the
     sampling. The NUTS algorithm utilizes gradients of the target
     distribution to more efficiently explore the probability
     distribution of the model.
-    
+
     More information on HMC and NUTS can be found at:
     https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo,
     https://arxiv.org/abs/1701.02434, and
     http://www.mcmchandbook.net/HandbookChapter5.pdf
 
     Args:
         model (AutoProf_Model): The model which will be sampled.
@@ -90,23 +93,23 @@
         self,
         model: "AutoProf_Model",
         initial_state: Optional[Sequence] = None,
         max_iter: int = 1000,
         **kwargs
     ):
         super().__init__(model, initial_state, max_iter=max_iter, **kwargs)
-        
+
         self.inv_mass = kwargs.get("inv_mass", None)
         self.epsilon = kwargs.get("epsilon", 1e-3)
         self.progress_bar = kwargs.get("progress_bar", True)
         self.prior = kwargs.get("prior", None)
         self.warmup = kwargs.get("warmup", 100)
         self.nuts_kwargs = kwargs.get("nuts_kwargs", {})
         self.mcmc_kwargs = kwargs.get("mcmc_kwargs", {})
-        
+
     def fit(
         self,
         state: Optional[torch.Tensor] = None,
         nsamples: Optional[int] = None,
         restart_chain: bool = True,
     ):
         """
@@ -137,34 +140,38 @@
             "full_mass": True,
             "adapt_step_size": True,
             "adapt_mass_matrix": self.inv_mass is None,
         }
         nuts_kwargs.update(self.nuts_kwargs)
         nuts_kernel = pyro_NUTS(step, **nuts_kwargs)
         if self.inv_mass is not None:
-            nuts_kernel.mass_matrix_adapter.inverse_mass_matrix = {("x",): self.inv_mass}
+            nuts_kernel.mass_matrix_adapter.inverse_mass_matrix = {
+                ("x",): self.inv_mass
+            }
 
         # Provide an initial guess for the parameters
-        init_params = {"x": self.model.get_parameter_vector(as_representation=True)}
+        init_params = {"x": self.model.parameters.get_vector(as_representation=True)}
 
         # Run MCMC with the NUTS sampler and the initial guess
         mcmc_kwargs = {
             "num_samples": self.max_iter,
             "warmup_steps": self.warmup,
             "initial_params": init_params,
             "disable_progbar": not self.progress_bar,
         }
         mcmc_kwargs.update(self.mcmc_kwargs)
         mcmc = pyro_MCMC(nuts_kernel, **mcmc_kwargs)
-        
+
         mcmc.run(self.model, self.prior)
         self.iteration += self.max_iter
 
         # Extract posterior samples
         chain = mcmc.get_samples()["x"]
 
         with torch.no_grad():
             for i in range(len(chain)):
-                chain[i] = self.model.transform(chain[i], to_representation = False)
+                chain[i] = self.model.parameters.transform(
+                    chain[i], to_representation=False
+                )
         self.chain = chain
-        
+
         return self
```

## autoprof/image/image_header.py

```diff
@@ -7,16 +7,16 @@
 from astropy.io import fits
 
 from .window_object import Window, Window_List
 from .. import AP_config
 
 __all__ = ["Image_Header"]
 
-class Image_Header(object):
 
+class Image_Header(object):
     def __init__(
         self,
         data_shape: Optional[torch.Tensor] = None,
         pixelscale: Optional[Union[float, torch.Tensor]] = None,
         window: Optional[Window] = None,
         filename: Optional[str] = None,
         zeropoint: Optional[Union[float, torch.Tensor]] = None,
@@ -238,15 +238,14 @@
             zeropoint=self.zeropoint,
             note=self.note,
             window=self.window.copy(),
             _identity=self.identity,
             **kwargs,
         )
 
-        
     def reduce(self, scale: int, **kwargs):
         """This operation will downsample an image by the factor given. If
         scale = 2 then 2x2 blocks of pixels will be summed together to
         form individual larger pixels. A new image object will be
         returned with the appropriate pixelscale and data tensor. Note
         that the window does not change in this operation since the
         pixels are condensed, but the pixel size is increased
@@ -275,14 +274,24 @@
           padding tuple[float]: length 4 tuple with amounts to pad each dimension in physical units
         """
         padding = np.array(padding)
         assert np.all(padding >= 0), "negative padding not allowed in expand method"
         pad_boundaries = tuple(np.int64(np.round(np.array(padding) / self.pixelscale)))
         self.window += tuple(padding)
 
+    def get_state(self):
+        state = {}
+        state["pixelscale"] = self.pixelscale.item()
+        if self.zeropoint is not None:
+            state["zeropoint"] = self.zeropoint.item()
+        state["window"] = self.window.get_state()
+        if self.note is not None:
+            state["note"] = self.note
+        return state
+
     def _save_image_list(self):
         img_header = fits.Header()
         img_header["IMAGE"] = "PRIMARY"
         img_header["PXLSCALE"] = str(self.pixelscale.detach().cpu().item())
         img_header["WINDOW"] = str(self.window.get_state())
         if not self.zeropoint is None:
             img_header["ZEROPNT"] = str(self.zeropoint.detach().cpu().item())
@@ -303,9 +312,11 @@
             if "IMAGE" in hdu.header and hdu.header["IMAGE"] == "PRIMARY":
                 self.pixelscale = eval(hdu.header.get("PXLSCALE"))
                 self.zeropoint = eval(hdu.header.get("ZEROPNT"))
                 self.note = hdu.header.get("NOTE")
                 self.window = Window(**eval(hdu.header.get("WINDOW")))
                 break
         return hdul
+
     def __str__(self):
-        return f"image pixelscale: {self.pixelscale} origin: {self.origin}\ndata: {self.data}"
+        state = self.get_state()
+        return "\n".join(f"{key}: {state[key]}" for key in state)
```

## autoprof/image/image_object.py

```diff
@@ -6,15 +6,16 @@
 import numpy as np
 from astropy.io import fits
 
 from .window_object import Window, Window_List
 from .image_header import Image_Header
 from .. import AP_config
 
-__all__ = ["Image", "Image_List"]    
+__all__ = ["Image", "Image_List"]
+
 
 class Image(object):
     """Core class to represent images with pixel values, pixel scale,
        and a window defining the spatial coordinates on the sky.
        It supports arithmetic operations with other image objects while preserving logical image boundaries.
        It also provides methods for determining the coordinate locations of pixels
 
@@ -67,36 +68,35 @@
         --------
         None
         """
         self._data = None
 
         if header is None:
             self.header = Image_Header(
-                data_shape = None if data is None else data.shape,
-                pixelscale = pixelscale,
-                window = window,
-                filename = filename,
-                zeropoint = zeropoint,
-                note = note,
-                origin = origin,
-                center = center,
-                _identity = _identity,
-                **kwargs
+                data_shape=None if data is None else data.shape,
+                pixelscale=pixelscale,
+                window=window,
+                filename=filename,
+                zeropoint=zeropoint,
+                note=note,
+                origin=origin,
+                center=center,
+                _identity=_identity,
+                **kwargs,
             )
         else:
             self.header = header
 
         if filename is not None:
             self.load(filename)
             return
 
         # set the data
         self.data = data
 
-
     @property
     def origin(self) -> torch.Tensor:
         """
         Returns the origin (bottom-left corner) of the image window.
 
         Returns:
             torch.Tensor: A 1D tensor of shape (2,) containing the (x, y) coordinates of the origin.
@@ -122,23 +122,27 @@
             torch.Tensor: A 1D tensor of shape (2,) containing the (x, y) coordinates of the center.
         """
         return self.header.window.center
 
     @property
     def window(self):
         return self.header.window
+
     @property
     def pixelscale(self):
         return self.header.pixelscale
+
     @property
     def zeropoint(self):
         return self.header.zeropoint
+
     @property
     def note(self):
         return self.header.note
+
     @property
     def identity(self):
         return self.header.identity
 
     def center_alignment(self) -> torch.Tensor:
         """Determine if the center of the image is aligned at a pixel center (True)
         or if it is aligned at a pixel edge (False).
@@ -195,15 +199,15 @@
         """Produce a copy of this image with all of the same properties. This
         can be used when one wishes to make temporary modifications to
         an image and then will want the original again.
 
         """
         return self.__class__(
             data=torch.clone(self.data),
-            header = self.header.copy(**kwargs),
+            header=self.header.copy(**kwargs),
             **kwargs,
         )
 
     def blank_copy(self, **kwargs):
         """Produces a blank copy of the image which has the same properties
         except that its data is now filled with zeros.
```

## autoprof/image/psf_image.py

```diff
@@ -26,27 +26,29 @@
 
     Methods:
         psf_border_int: Calculates and returns the convolution border size of the PSF image in integer format.
         psf_border: Calculates and returns the convolution border size of the PSF image in the units of pixelscale.
         _save_image_list: Saves the image list to the PSF HDU header.
         reduce: Reduces the size of the image using a given scale factor.
     """
-    
+
     def __init__(self, *args, **kwargs):
         """
         Initializes the PSF_Image class.
 
         Args:
             *args: Variable length argument list.
             **kwargs: Arbitrary keyword arguments.
                 psf_upscale (int, optional): Upscaling factor of the PSF. Default is 1.
                 band (str, optional): The band of the image. Default is None.
         """
         super().__init__(*args, **kwargs)
-        assert torch.all((torch.tensor(self.data.shape) % 2) == 1), "psf must have odd shape"
+        assert torch.all(
+            (torch.tensor(self.data.shape) % 2) == 1
+        ), "psf must have odd shape"
 
         self.psf_upscale = torch.as_tensor(
             kwargs.get("psf_upscale", 1), dtype=torch.int32, device=AP_config.ap_device
         )
 
         # set the band
         self.band = kwargs.get("band", None)
@@ -99,88 +101,87 @@
         psf_header["UPSCALE"] = int(self.psf_upscale.detach().cpu().item())
         image_list.append(
             fits.ImageHDU(self.data.detach().cpu().numpy(), header=psf_header)
         )
 
     def copy(self, **kwargs):
         """Creates a copy of the PSF_Image instance.
-        
+
         This method generates a copy of the PSF_Image object while maintaining the 'psf_upscale' and 'band' properties.
-        
+
         Args:
             **kwargs: Arbitrary keyword arguments.
-        
+
         Returns:
             PSF_Image: A copy of the current PSF_Image instance.
         """
         return super().copy(
-            psf_upscale = self.psf_upscale,
-            band = self.band,
+            psf_upscale=self.psf_upscale,
+            band=self.band,
         )
+
     def blank_copy(self, **kwargs):
         """Creates a blank copy of the PSF_Image instance.
-        
+
         This method generates a blank copy of the PSF_Image object while maintaining the 'psf_upscale' and 'band' properties.
-        
+
         Args:
             **kwargs: Arbitrary keyword arguments.
-        
+
         Returns:
             PSF_Image: A blank copy of the current PSF_Image instance with the same properties but no data.
         """
         return super().blank_copy(
-            psf_upscale = self.psf_upscale,
-            band = self.band,
+            psf_upscale=self.psf_upscale,
+            band=self.band,
         )
+
     def get_window(self, **kwargs):
         """Returns the window of the PSF_Image instance.
-        
+
         This method returns the window of the PSF_Image object while maintaining the 'psf_upscale' and 'band' properties.
-        
+
         Args:
             **kwargs: Arbitrary keyword arguments.
-        
+
         Returns:
             Window: The window associated with the PSF_Image instance.
         """
         return super().get_window(
-            psf_upscale = self.psf_upscale,
-            band = self.band,            
+            psf_upscale=self.psf_upscale,
+            band=self.band,
         )
 
-    def to(self, dtype = None, device = None):
+    def to(self, dtype=None, device=None):
         """Transfers the PSF_Image instance to the specified device and modifies its data type.
-        
-        This method changes the data type of the PSF_Image object and moves it to a specified device. 
+
+        This method changes the data type of the PSF_Image object and moves it to a specified device.
         If no device is provided, it defaults to 'AP_config.ap_device'.
-        
+
         Args:
             dtype (torch.dtype, optional): The desired data type to which the PSF_Image instance should be converted.
             device (torch.device, optional): The desired device to which the PSF_Image instance should be moved.
         """
         if device is None:
             device = AP_config.ap_device
-        self.psf_upscale = self.psf_upscale.to(device = device)
+        self.psf_upscale = self.psf_upscale.to(device=device)
         super().to(dtype=dtype, device=device)
-        
+
     def reduce(self, scale, **kwargs):
         """Reduces the size of the image using a given scale factor.
 
         This method is used to perform a reduction in the size of the PSF image. The new upscaling factor
         is calculated by dividing the existing upscaling factor with the provided scale factor.
 
         Args:
             scale (float): The scale factor by which the size of the PSF image needs to be reduced.
             **kwargs: Arbitrary keyword arguments. This can be used to pass additional parameters required by the method.
 
         Returns:
             PSF_Image: A new instance of PSF_Image class with the reduced image size.
         """
         return super().reduce(
-            scale,
-            psf_upscale = self.psf_upscale / scale,
-            band = self.band,
-            **kwargs
+            scale, psf_upscale=self.psf_upscale / scale, band=self.band, **kwargs
         )
 
     def expand(self, padding):
         raise NotImplementedError("expand not available for PSF_Image")
```

## autoprof/image/target_image.py

```diff
@@ -23,28 +23,29 @@
 
     image_count = 0
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         # set the band
         self.band = kwargs.get("band", None)
-        
+
         if not self.has_variance:
             self.set_variance(kwargs.get("variance", None))
         if not self.has_mask:
             self.set_mask(kwargs.get("mask", None))
         if not self.has_psf:
             self.set_psf(kwargs.get("psf", None), kwargs.get("psf_upscale", 1))
 
     @property
     def band(self):
         if self._band is None:
             self._band = str(Target_Image.image_count)
             Target_Image.image_count += 1
         return self._band
+
     @band.setter
     def band(self, val):
         self._band = val
 
     @property
     def variance(self):
         if self.has_variance:
@@ -107,27 +108,27 @@
             variance.to(dtype=AP_config.ap_dtype, device=AP_config.ap_device)
             if isinstance(variance, torch.Tensor)
             else torch.as_tensor(
                 variance, dtype=AP_config.ap_dtype, device=AP_config.ap_device
             )
         )
 
-    def set_psf(self, psf, psf_upscale = 1):
+    def set_psf(self, psf, psf_upscale=1):
         if psf is None:
             self._psf = None
             return
         if isinstance(psf, PSF_Image):
             self._psf = psf
             return
-        
+
         self._psf = PSF_Image(
             psf,
-            psf_upscale = psf_upscale,
-            pixelscale = self.pixelscale / psf_upscale,
-            band = self.band,
+            psf_upscale=psf_upscale,
+            pixelscale=self.pixelscale / psf_upscale,
+            band=self.band,
         )
 
     def set_mask(self, mask):
         if mask is None:
             self._mask = None
             return
         assert mask.shape == self.data.shape, "mask must have same shape as data"
@@ -172,17 +173,15 @@
         )
 
     def blank_copy(self, **kwargs):
         """Produces a blank copy of the image which has the same properties
         except that its data is not filled with zeros.
 
         """
-        return super().blank_copy(
-            mask=self._mask, psf=self._psf, **kwargs
-        )
+        return super().blank_copy(mask=self._mask, psf=self._psf, **kwargs)
 
     def get_window(self, window, **kwargs):
         """Get a sub-region of the image as defined by a window on the sky."""
         indices = window.get_indices(self)
         return super().get_window(
             window=window,
             variance=self._variance[indices] if self.has_variance else None,
@@ -267,15 +266,21 @@
         return image_list
 
     def load(self, filename):
         hdul = super().load(filename)
 
         for hdu in hdul:
             if "IMAGE" in hdu.header and hdu.header["IMAGE"] == "PSF":
-                self.set_psf(PSF_Image(np.array(hdu.data, dtype=np.float64), psf_upscale = hdu.header["UPSCALE"], pixelscale = self.pixelscale / hdu.header["UPSCALE"]))
+                self.set_psf(
+                    PSF_Image(
+                        np.array(hdu.data, dtype=np.float64),
+                        psf_upscale=hdu.header["UPSCALE"],
+                        pixelscale=self.pixelscale / hdu.header["UPSCALE"],
+                    )
+                )
             if "IMAGE" in hdu.header and hdu.header["IMAGE"] == "VARIANCE":
                 self.set_variance(np.array(hdu.data, dtype=np.float64))
             if "IMAGE" in hdu.header and hdu.header["IMAGE"] == "MASK":
                 self.set_mask(np.array(hdu.data, dtype=bool))
         return hdul
```

## autoprof/image/window_object.py

```diff
@@ -35,18 +35,14 @@
                 )
                 - self.shape / 2
             )
         else:
             raise ValueError(
                 "One of center or origin must be provided to create window"
             )
-        with torch.no_grad():
-            assert torch.all(
-                self.shape > 0
-            ), f"Window must have non-negative size: {self.origin.detach().cpu().numpy()}, {self.shape.detach().cpu().numpy()}"
 
     @property
     def center(self):
         return self.origin + self.shape / 2
 
     @property
     def plt_extent(self):
```

## autoprof/models/_model_methods.py

```diff
@@ -74,53 +74,18 @@
             else:
                 parameter_specs[p]["value"] = user_specs[p]
 
     return parameter_specs
 
 
 def build_parameters(self):
-    for p in self.parameter_specs:
-        # skip special parameters, these must be handled by the model child
-        if "|" in p:
-            continue
+    for p in self.__class__._parameter_order:
         # skip if the parameter already exists
         if p in self.parameters:
             continue
         # If a parameter object is provided, simply use as-is
         if isinstance(self.parameter_specs[p], Parameter):
-            self.parameters[p] = self.parameter_specs[p].to()
+            self.parameters.add_parameter(self.parameter_specs[p].to())
         elif isinstance(self.parameter_specs[p], dict):
-            self.parameters[p] = Parameter(p, **self.parameter_specs[p])
+            self.parameters.add_parameter(Parameter(p, **self.parameter_specs[p]))
         else:
             raise ValueError(f"unrecognized parameter specification for {p}")
-
-
-def __str__(self):
-    state = self.get_state()
-    presentation = ""
-    for key in state:
-        presentation = presentation + f"{key}: {state[key]}\n"
-    return presentation
-
-
-def __getitem__(self, key):
-    # Access an element from an array parameter
-    if isinstance(key, tuple):
-        return self.parameters[key[0]][key[1]]
-
-    # Try to access the parameter by name
-    if key in self.parameters:
-        return self.parameters[key]
-
-    # Try to get a particular element from an array parameter
-    if "|" in key and key[: key.find("|")] in self.parameters:
-        return self.parameters[key[: key.find("|")]][int(key[key.find("|") + 1 :])]
-
-    raise KeyError(f"{key} not in {self.name}. {str(self)}")
-
-
-def __contains__(self, key):
-    try:
-        self[key]
-        return True
-    except:
-        return False
```

## autoprof/models/_shared_methods.py

```diff
@@ -18,15 +18,15 @@
     exponential_np,
     spline_torch,
     moffat_torch,
     moffat_np,
     nuker_torch,
     nuker_np,
 )
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.conversions.coordinates import (
     Rotate_Cartesian,
     coord_to_index,
     index_to_coord,
 )
 from ..utils.conversions.functions import sersic_I0_to_flux_np, sersic_flux_to_I0_torch
 from ..image import Image_List, Target_Image, Model_Image_List, Target_Image_List
@@ -80,17 +80,17 @@
 
 
 # General parametric
 ######################################################################
 @torch.no_grad()
 @ignore_numpy_warnings
 def parametric_initialize(
-    model, target, prof_func, params, x0_func, force_uncertainty=None
+    model, parameters, target, prof_func, params, x0_func, force_uncertainty=None
 ):
-    if all(list(model[param].value is not None for param in params)):
+    if all(list(parameters[param].value is not None for param in params)):
         return
     # Get the sub-image area corresponding to the model image
     target_area = target[model.window]
     edge = np.concatenate(
         (
             target_area.data.detach().cpu().numpy()[:, 0],
             target_area.data.detach().cpu().numpy()[:, -1],
@@ -98,38 +98,40 @@
             target_area.data.detach().cpu().numpy()[-1, :],
         )
     )
     edge_average = np.median(edge)
     edge_scatter = iqr(edge, rng=(16, 84)) / 2
     # Convert center coordinates to target area array indices
     icenter = coord_to_index(
-        model["center"].value[0], model["center"].value[1], target_area
+        parameters["center"].value[0], parameters["center"].value[1], target_area
     )
     # Collect isophotes for 1D fit
     iso_info = isophotes(
         target_area.data.detach().cpu().numpy() - edge_average,
         (icenter[1].item(), icenter[0].item()),
         threshold=3 * edge_scatter,
-        pa=model["PA"].value.detach().cpu().item() if "PA" in model else 0.0,
-        q=model["q"].value.detach().cpu().item() if "q" in model else 1.0,
+        pa=parameters["PA"].value.detach().cpu().item() if "PA" in parameters else 0.0,
+        q=parameters["q"].value.detach().cpu().item() if "q" in parameters else 1.0,
         n_isophotes=15,
     )
     R = np.array(list(iso["R"] for iso in iso_info)) * target.pixelscale.item()
     flux = (
         np.array(list(iso["flux"] for iso in iso_info)) / target.pixelscale.item() ** 2
     )
     # Correct the flux if values are negative, so fit can be done in log space
     if np.sum(flux < 0) > 0:
         AP_config.ap_logger.debug("fixing flux")
         flux -= np.min(flux) - np.abs(np.min(flux) * 0.1)
     flux = np.log10(flux)
 
     x0 = list(x0_func(model, R, flux))
     for i, param in enumerate(params):
-        x0[i] = x0[i] if model[param].value is None else model[param].value.item()
+        x0[i] = (
+            x0[i] if parameters[param].value is None else parameters[param].value.item()
+        )
 
     def optim(x, r, f):
         residual = (f - np.log10(prof_func(r, *x))) ** 2
         N = np.argsort(residual)
         return np.mean(residual[:-3])
 
     res = minimize(optim, x0=x0, args=(R, flux), method="Nelder-Mead")
@@ -138,31 +140,40 @@
         reses = []
         for i in range(10):
             N = np.random.randint(0, len(R), len(R))
             reses.append(
                 minimize(optim, x0=x0, args=(R[N], flux[N]), method="Nelder-Mead")
             )
     for param, resx, x0x in zip(params, res.x, x0):
-        if model[param].value is None:
-            model[param].set_value(resx if res.success else x0x, override_locked=True)
-        if force_uncertainty is None and model[param].uncertainty is None:
-            model[param].set_uncertainty(
+        if parameters[param].value is None:
+            parameters[param].set_value(
+                resx if res.success else x0x, override_locked=True
+            )
+        if force_uncertainty is None and parameters[param].uncertainty is None:
+            parameters[param].set_uncertainty(
                 np.std(list(subres.x[params.index(param)] for subres in reses)),
                 override_locked=True,
             )
         elif force_uncertainty is not None:
-            model[param].set_uncertainty(
+            parameters[param].set_uncertainty(
                 force_uncertainty[params.index(param)], override_locked=True
             )
 
 
 @torch.no_grad()
 @ignore_numpy_warnings
 def parametric_segment_initialize(
-    model, target, prof_func, params, x0_func, segments, force_uncertainty=None
+    model=None,
+    parameters=None,
+    target=None,
+    prof_func=None,
+    params=None,
+    x0_func=None,
+    segments=None,
+    force_uncertainty=None,
 ):
     if all(list(model[param].value is not None for param in params)):
         return
     # Get the sub-image area corresponding to the model image
     target_area = target[model.window]
     edge = np.concatenate(
         (
@@ -255,248 +266,214 @@
                         override_locked=True,
                         index=r,
                     )
 
 
 # Exponential
 ######################################################################
-def exponential_radial_model(self, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def exponential_radial_model(self, R, image=None, parameters=None):
     return exponential_torch(
-        R, self["Re"].value, (10 ** self["Ie"].value) * sample_image.pixelscale ** 2
+        R,
+        parameters["Re"].value,
+        (10 ** parameters["Ie"].value) * image.pixelscale ** 2,
     )
 
 
-def exponential_iradial_model(self, i, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def exponential_iradial_model(self, i, R, image=None, parameters=None):
     return exponential_torch(
         R,
-        self["Re"].value[i],
-        (10 ** self["Ie"].value[i]) * sample_image.pixelscale ** 2,
+        parameters["Re"].value[i],
+        (10 ** parameters["Ie"].value[i]) * image.pixelscale ** 2,
     )
 
 
 # Sersic
 ######################################################################
-def sersic_radial_model(self, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def sersic_radial_model(self, R, image=None, parameters=None):
     return sersic_torch(
         R,
-        self["n"].value,
-        self["Re"].value,
-        (10 ** self["Ie"].value) * sample_image.pixelscale ** 2,
+        parameters["n"].value,
+        parameters["Re"].value,
+        (10 ** parameters["Ie"].value) * image.pixelscale ** 2,
     )
 
 
-def sersic_iradial_model(self, i, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def sersic_iradial_model(self, i, R, image=None, parameters=None):
     return sersic_torch(
         R,
-        self["n"].value[i],
-        self["Re"].value[i],
-        (10 ** self["Ie"].value[i]) * sample_image.pixelscale ** 2,
+        parameters["n"].value[i],
+        parameters["Re"].value[i],
+        (10 ** parameters["Ie"].value[i]) * image.pixelscale ** 2,
     )
 
 
 # Moffat
 ######################################################################
-def moffat_radial_model(self, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def moffat_radial_model(self, R, image=None, parameters=None):
     return moffat_torch(
         R,
-        self["n"].value,
-        self["Rd"].value,
-        (10 ** self["I0"].value) * sample_image.pixelscale ** 2,
+        parameters["n"].value,
+        parameters["Rd"].value,
+        (10 ** parameters["I0"].value) * image.pixelscale ** 2,
     )
 
 
-def moffat_iradial_model(self, i, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def moffat_iradial_model(self, i, R, image=None, parameters=None):
     return moffat_torch(
         R,
-        self["n"].value[i],
-        self["Rd"].value[i],
-        (10 ** self["I0"].value[i]) * sample_image.pixelscale ** 2,
+        parameters["n"].value[i],
+        parameters["Rd"].value[i],
+        (10 ** parameters["I0"].value[i]) * image.pixelscale ** 2,
     )
 
 
 # Nuker Profile
 ######################################################################
-def nuker_radial_model(self, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def nuker_radial_model(self, R, image=None, parameters=None):
     return nuker_torch(
         R,
-        self["Rb"].value,
-        (10 ** self["Ib"].value) * sample_image.pixelscale ** 2,
-        self["alpha"].value,
-        self["beta"].value,
-        self["gamma"].value,
+        parameters["Rb"].value,
+        (10 ** parameters["Ib"].value) * image.pixelscale ** 2,
+        parameters["alpha"].value,
+        parameters["beta"].value,
+        parameters["gamma"].value,
     )
 
 
-def nuker_iradial_model(self, i, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def nuker_iradial_model(self, i, R, image=None, parameters=None):
     return nuker_torch(
         R,
-        self["Rb"].value[i],
-        (10 ** self["Ib"].value[i]) * sample_image.pixelscale ** 2,
-        self["alpha"].value[i],
-        self["beta"].value[i],
-        self["gamma"].value[i],
+        parameters["Rb"].value[i],
+        (10 ** parameters["Ib"].value[i]) * image.pixelscale ** 2,
+        parameters["alpha"].value[i],
+        parameters["beta"].value[i],
+        parameters["gamma"].value[i],
     )
 
 
 # Gaussian
 ######################################################################
-def gaussian_radial_model(self, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def gaussian_radial_model(self, R, image=None, parameters=None):
     return gaussian_torch(
         R,
-        self["sigma"].value,
-        (10 ** self["flux"].value) * sample_image.pixelscale ** 2,
+        parameters["sigma"].value,
+        (10 ** parameters["flux"].value) * image.pixelscale ** 2,
     )
 
 
-def gaussian_iradial_model(self, i, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def gaussian_iradial_model(self, i, R, image=None, parameters=None):
     return gaussian_torch(
         R,
-        self["sigma"].value[i],
-        (10 ** self["flux"].value[i]) * sample_image.pixelscale ** 2,
+        parameters["sigma"].value[i],
+        (10 ** parameters["flux"].value[i]) * image.pixelscale ** 2,
     )
 
 
 # Spline
 ######################################################################
 @torch.no_grad()
 @ignore_numpy_warnings
 @select_target
-def spline_initialize(self, target=None):
-    super(self.__class__, self).initialize(target)
+@default_internal
+def spline_initialize(self, target=None, parameters=None, **kwargs):
+    super(self.__class__, self).initialize(target=target, parameters=parameters)
 
-    if self["I(R)"].value is not None:
-        # Create the I(R) profile radii to match the input profile intensity values
-        if self["I(R)"].prof is None:
-            # create logarithmically spaced profile radii
-            new_prof = [0] + list(
-                np.logspace(
-                    np.log10(2 * target.pixelscale),
-                    np.log10(np.sqrt(torch.sum((self.window.shape / 2) ** 2).item())),
-                    len(self["I(R)"].value),
-                )
-            )
-            new_prof.pop(-2)
-            # ensure no step is smaller than a pixelscale
-            for i in range(1, len(new_prof)):
-                if new_prof[i] - new_prof[i - 1] < target.pixelscale.item():
-                    new_prof[i] = new_prof[i - 1] + target.pixelscale.item()
-            self["I(R)"].set_profile(new_prof)
+    if parameters["I(R)"].value is not None and parameters["I(R)"].prof is not None:
         return
 
     # Create the I(R) profile radii if needed
-    if self["I(R)"].prof is None:
+    if parameters["I(R)"].prof is None:
         new_prof = [0, 2 * target.pixelscale]
         while new_prof[-1] < torch.max(self.window.shape / 2):
             new_prof.append(
                 new_prof[-1] + torch.max(2 * target.pixelscale, new_prof[-1] * 0.2)
             )
         new_prof.pop()
         new_prof.pop()
         new_prof.append(torch.sqrt(torch.sum((self.window.shape / 2) ** 2)))
-        self["I(R)"].set_profile(new_prof)
+        parameters["I(R)"].set_profile(new_prof)
 
-    profR = self["I(R)"].prof.detach().cpu().numpy()
+    profR = parameters["I(R)"].prof.detach().cpu().numpy()
     target_area = target[self.window]
     X, Y = target_area.get_coordinate_meshgrid_torch(
-        self["center"].value[0], self["center"].value[1]
+        parameters["center"].value[0], parameters["center"].value[1]
     )
-    X, Y = self.transform_coordinates(X, Y)
-    R = self.radius_metric(X, Y).detach().cpu().numpy()
+    X, Y = self.transform_coordinates(X, Y, target, parameters)
+    R = self.radius_metric(X, Y, target, parameters).detach().cpu().numpy()
     rad_bins = [profR[0]] + list((profR[:-1] + profR[1:]) / 2) + [profR[-1] * 100]
     raveldat = target_area.data.detach().cpu().numpy().ravel()
     I = (
         binned_statistic(R.ravel(), raveldat, statistic="median", bins=rad_bins)[0]
         / target_area.pixelscale.item() ** 2
     )
     N = np.isfinite(I)
     if not np.all(N):
         I[np.logical_not(N)] = np.interp(profR[np.logical_not(N)], profR[N], I[N])
     if I[-1] >= I[-2]:
-        I[-1] = I[-2]/2
+        I[-1] = I[-2] / 2
     S = binned_statistic(
         R.ravel(), raveldat, statistic=lambda d: iqr(d, rng=[16, 84]) / 2, bins=rad_bins
     )[0]
     N = np.isfinite(S)
     if not np.all(N):
         S[np.logical_not(N)] = np.interp(profR[np.logical_not(N)], profR[N], S[N])
-    self["I(R)"].set_value(np.log10(np.abs(I)), override_locked=True)
-    self["I(R)"].set_uncertainty(S / (np.abs(I) * np.log(10)), override_locked=True)
+    parameters["I(R)"].set_value(np.log10(np.abs(I)), override_locked=True)
+    parameters["I(R)"].set_uncertainty(
+        S / (np.abs(I) * np.log(10)), override_locked=True
+    )
 
 
 @torch.no_grad()
 @ignore_numpy_warnings
 @select_target
-def spline_segment_initialize(self, target=None, segments=1, symmetric=True):
-    super(self.__class__, self).initialize(target)
+@default_internal
+def spline_segment_initialize(
+    self, target=None, parameters=None, segments=1, symmetric=True, **kwargs
+):
+    super(self.__class__, self).initialize(target=target, parameters=parameters)
 
-    if self["I(R)"].value is not None:
-        # Create the I(R) profile radii to match the input profile intensity values
-        if self["I(R)"].prof is None:
-            # create logarithmically spaced profile radii
-            new_prof = [0] + list(
-                np.logspace(
-                    np.log10(2 * target.pixelscale),
-                    np.log10(np.sqrt(torch.sum((self.window.shape / 2) ** 2).item())),
-                    len(self["I(R)"].value),
-                )
-            )
-            new_prof.pop(-2)
-            # ensure no step is smaller than a pixelscale
-            for i in range(1, len(new_prof)):
-                if new_prof[i] - new_prof[i - 1] < target.pixelscale.item():
-                    new_prof[i] = new_prof[i - 1] + target.pixelscale.item()
-            self["I(R)"].set_profile(new_prof)
+    if parameters["I(R)"].value is not None and parameters["I(R)"].prof is not None:
         return
 
     # Create the I(R) profile radii if needed
-    if self["I(R)"].prof is None:
+    if parameters["I(R)"].prof is None:
         new_prof = [0, 2 * target.pixelscale]
         while new_prof[-1] < torch.max(self.window.shape / 2):
             new_prof.append(
                 new_prof[-1] + torch.max(2 * target.pixelscale, new_prof[-1] * 0.2)
             )
         new_prof.pop()
         new_prof.pop()
         new_prof.append(torch.sqrt(torch.sum((self.window.shape / 2) ** 2)))
-        self["I(R)"].set_profile(new_prof)
+        parameters["I(R)"].set_profile(new_prof)
 
-    self["I(R)"].set_value(
-        np.zeros((segments, len(self["I(R)"].prof))), override_locked=True
+    parameters["I(R)"].set_value(
+        np.zeros((segments, len(parameters["I(R)"].prof))), override_locked=True
     )
-    self["I(R)"].set_uncertainty(
-        np.zeros((segments, len(self["I(R)"].prof))), override_locked=True
+    parameters["I(R)"].set_uncertainty(
+        np.zeros((segments, len(parameters["I(R)"].prof))), override_locked=True
     )
-    profR = self["I(R)"].prof.detach().cpu().numpy()
+    profR = parameters["I(R)"].prof.detach().cpu().numpy()
     target_area = target[self.window]
     X, Y = target_area.get_coordinate_meshgrid_torch(
-        self["center"].value[0], self["center"].value[1]
+        parameters["center"].value[0], parameters["center"].value[1]
     )
-    X, Y = self.transform_coordinates(X, Y)
-    R = self.radius_metric(X, Y).detach().cpu().numpy()
-    T = self.angular_metric(X, Y).detach().cpu().numpy()
+    X, Y = self.transform_coordinates(X, Y, target, parameters)
+    R = self.radius_metric(X, Y, target, parameters).detach().cpu().numpy()
+    T = self.angular_metric(X, Y, target, parameters).detach().cpu().numpy()
     rad_bins = [profR[0]] + list((profR[:-1] + profR[1:]) / 2) + [profR[-1] * 100]
     raveldat = target_area.data.detach().cpu().numpy().ravel()
     for s in range(segments):
         if segments % 2 == 0 and symmetric:
             angles = (T - (s * np.pi / segments)) % np.pi
             TCHOOSE = np.logical_or(
                 angles < (np.pi / segments), angles >= (np.pi * (1 - 1 / segments))
@@ -539,35 +516,33 @@
             raveldat,
             statistic=lambda d: iqr(d, rng=[16, 84]) / 2,
             bins=rad_bins,
         )[0]
         N = np.isfinite(S)
         if not np.all(N):
             S[np.logical_not(N)] = np.interp(profR[np.logical_not(N)], profR[N], S[N])
-        self["I(R)"].set_value(np.log10(np.abs(I)), override_locked=True, index=s)
-        self["I(R)"].set_uncertainty(
+        parameters["I(R)"].set_value(np.log10(np.abs(I)), override_locked=True, index=s)
+        parameters["I(R)"].set_uncertainty(
             S / (np.abs(I) * np.log(10)), override_locked=True, index=s
         )
 
 
-def spline_radial_model(self, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def spline_radial_model(self, R, image=None, parameters=None):
     return spline_torch(
         R,
-        self["I(R)"].prof,
-        self["I(R)"].value,
-        sample_image.pixelscale ** 2,
+        parameters["I(R)"].prof,
+        parameters["I(R)"].value,
+        image.pixelscale ** 2,
         extend=self.extend_profile,
     )
 
 
-def spline_iradial_model(self, i, R, sample_image=None):
-    if sample_image is None:
-        sample_image = self.target
+@default_internal
+def spline_iradial_model(self, i, R, image=None, parameters=None):
     return spline_torch(
         R,
-        self["I(R)"].prof,
-        self["I(R)"].value[i],
-        sample_image.pixelscale ** 2,
+        parameters["I(R)"].prof,
+        parameters["I(R)"].value[i],
+        image.pixelscale ** 2,
         extend=self.extend_profile,
     )
```

## autoprof/models/core_model.py

```diff
@@ -1,22 +1,24 @@
 from copy import copy
 from time import time
 import io
 from typing import Optional
+from functools import partial
 
 import torch
 import numpy as np
 import matplotlib.pyplot as plt
+import yaml
 
 from ..utils.conversions.optimization import cyclic_difference_np
 from ..utils.conversions.dict_to_hdf5 import dict_to_hdf5
 from ..utils.optimization import reduced_chi_squared
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..image import Model_Image, Window, Target_Image
-from .parameter_object import Parameter
+from .parameter_group import Parameter_Group
 from ._shared_methods import select_target, select_sample
 from .. import AP_config
 
 __all__ = ["AutoProf_Model"]
 
 
 def all_subclasses(cls):
@@ -72,187 +74,83 @@
         assert (
             ":" not in name and "|" not in name
         ), "characters '|' and ':' are reserved for internal model operations please do not include these in a model name"
         self.name = name
         AP_config.ap_logger.debug("Creating model named: {self.name}")
         self.constraints = kwargs.get("constraints", None)
         self.equality_constraints = []
-        self.parameters = {}
+        self.parameters = Parameter_Group(self.name)
         self.requires_grad = kwargs.get("requires_grad", False)
         self.target = target
         self.window = window
         self._locked = locked
         self.mask = kwargs.get("mask", None)
 
     def add_equality_constraint(self, model, parameter):
         if isinstance(parameter, (tuple, list)):
             for P in parameter:
                 self.add_equality_constraint(model, P)
             return
-        self.parameters[parameter] = model[parameter]
+        del_param = self.parameters.get_name(parameter)
+        use_param = model.parameters.get_name(parameter)
+        old_groups = del_param.groups
+        for group in old_groups:
+            group.pop_id(del_param.identity)
+            group.add_parameter(use_param)
+
         self.equality_constraints.append(parameter)
         model.equality_constraints.append(parameter)
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target, *args, **kwargs):
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
         """When this function finishes, all parameters should have numerical
         values (non None) that are reasonable estimates of the final
         values.
 
         """
         pass
 
     def make_model_image(self, window: Optional[Window] = None):
         if window is None:
             window = self.window
         else:
             window = self.window & window
         return self.target[window].model_image()
 
-    def sample(self, image=None, window=None, *args, **kwargs):
+    def sample(self, image=None, window=None, parameters=None, *args, **kwargs):
         """Calling this function should fill the given image with values
         sampled from the given model.
 
         """
         pass
 
     def negative_log_likelihood(
         self,
         parameters=None,
         as_representation=True,
         parameters_identity=None,
     ):
         if parameters is not None:
-            self.set_parameters(parameters, as_representation, parameters_identity)
+            self.parameters.set_values(
+                parameters, as_representation, parameters_identity
+            )
 
         model = self.sample()
         data = self.target[self.window]
         variance = data.variance
         if self.target.has_mask:
             mask = torch.logical_not(data.mask)
-            chi2 = torch.sum(
-                ((model - data).data ** 2 / variance)[mask]
-            ) / 2.
+            chi2 = torch.sum(((model - data).data ** 2 / variance)[mask]) / 2.0
         else:
-            chi2 = torch.sum(
-                ((model - data).data ** 2 / variance)
-            ) / 2.
-            
-        return chi2
-        
+            chi2 = torch.sum(((model - data).data ** 2 / variance)) / 2.0
 
-    def set_parameters(
-        self,
-        parameters,
-        as_representation=True,
-        parameters_identity=None,
-    ):
-        """
-        Set the parameter values for this model with a given object.
-
-        Parameters:
-            parameters: updated values for the parameters. Either as a dictionary of parameter_name: tensor pairs, or as a 1D tensor.
-            as_representation: if true the parameters are given as a representation form, if false then the parameters are given as values (see parameters for difference between representation and value)
-            parameters_identity: iterable of parameter identities if "parameters" is some subset of the full parameter tensor. The identity can be found with `parameter.identity` where `parameter` is a parameter object
-        """
-        if isinstance(parameters, dict):
-            for P in parameters:
-                if self[P].locked:
-                    continue
-                if as_representation:
-                    self[P].representation = parameters[P]
-                else:
-                    self[P].value = parameters[P]
-            return
-        # ensure parameters are a tensor
-        parameters = torch.as_tensor(
-            parameters, dtype=AP_config.ap_dtype, device=AP_config.ap_device
-        )
-        # track the order of the parameters
-        porder = self.parameter_order(parameters_identity=parameters_identity)
-
-        # If parameters are provided by identity, they are individually updated
-        if parameters_identity is not None:
-            parameters_identity = list(parameters_identity)
-            for P in porder:
-                for pid in self[P].identities:
-                    if pid in parameters_identity:
-                        if as_representation:
-                            self[P].set_representation(
-                                parameters[parameters_identity.index(pid)], identity=pid
-                            )
-                        else:
-                            self[P].set_value(
-                                parameters[parameters_identity.index(pid)], identity=pid
-                            )
-            return
-
-        # If parameters are provided as the full vector, they are added in bulk
-        start = 0
-        for P, V in zip(
-            porder,
-            self.parameter_vector_len(),
-        ):
-            if as_representation:
-                self[P].representation = parameters[start : start + V].reshape(
-                    self[P].representation.shape
-                )
-            else:
-                self[P].value = parameters[start : start + V].reshape(
-                    self[P].value.shape
-                )
-            start += V
-
-    def set_uncertainty(
-        self,
-        uncertainty,
-        as_representation=False,
-        parameters_identity=None,
-    ):
-        if isinstance(uncertainty, dict):
-            for P in uncertainty:
-                if self[P].locked:
-                    continue
-                self[P].set_uncertainty(
-                    uncertainty[P],
-                    as_representation=as_representation,
-                )
-            return
-        uncertainty = torch.as_tensor(
-            uncertainty, dtype=AP_config.ap_dtype, device=AP_config.ap_device
-        )
-        # track the order of the parameters
-        porder = self.parameter_order(parameters_identity=parameters_identity)
-
-        # If uncertainty is provided by identity, they are individually updated
-        if parameters_identity is not None:
-            parameters_identity = list(parameters_identity)
-            for P in porder:
-                for pid in self[P].identities:
-                    if pid in parameters_identity:
-                        self[P].set_uncertainty(
-                            uncertainty[parameters_identity.index(pid)],
-                            as_representation=as_representation,
-                            identity=pid,
-                        )
-            return
-
-        # If uncertainty is provided as the full vector, they are added in bulk
-        start = 0
-        for P, V in zip(
-            porder,
-            self.parameter_vector_len(),
-        ):
-            self[P].set_uncertainty(
-                uncertainty[start : start + V].reshape(self[P].representation.shape),
-                as_representation=as_representation,
-            )
-            start += V
+        return chi2
 
     def jacobian(
         self,
         parameters=None,
         as_representation=False,
         **kwargs,
     ):
@@ -338,157 +236,31 @@
         return self._locked
 
     @locked.setter
     def locked(self, val):
         assert isinstance(val, bool)
         self._locked = val
 
-    def parameter_vector_len(self, parameters_identity=None):
-        param_vec_len = []
-        for P in self.parameter_order(parameters_identity=parameters_identity):
-            if parameters_identity is None:
-                param_vec_len.append(int(np.prod(self[P].value.shape)))
-            else:
-                param_vec_len.append(
-                    sum(pid in parameters_identity for pid in self[P].identities)
-                )
-        return param_vec_len
-
-    def get_parameter_vector(self, as_representation=False, parameters_identity=None):
-        parameters = torch.zeros(
-            np.sum(self.parameter_vector_len(parameters_identity=parameters_identity)),
-            dtype=AP_config.ap_dtype,
-            device=AP_config.ap_device,
-        )
-        porder = self.parameter_order(parameters_identity=parameters_identity)
-        # If vector is requested by identity, they are individually updated
-        if parameters_identity is not None:
-            pindex = 0
-            for P in porder:
-                for pid in self[P].identities:
-                    if pid in parameters_identity:
-                        if as_representation:
-                            parameters[pindex] = self[P].get_representation(
-                                identity=pid
-                            )
-                        else:
-                            parameters[pindex] = self[P].get_value(identity=pid)
-                        pindex += 1
-            return parameters
-
-        # If the full vector is requested, they are added in bulk
-        vstart = 0
-        for P, V in zip(
-            porder,
-            self.parameter_vector_len(),
-        ):
-            if as_representation:
-                parameters[vstart : vstart + V] = self[P].representation
-            else:
-                parameters[vstart : vstart + V] = self[P].value
-            vstart += V
-        return parameters
-
-    def get_parameter_name_vector(self, parameters_identity=None):
-        parameters = []
-        porder = self.parameter_order(parameters_identity=parameters_identity)
-        # If vector is requested by identity, they are individually updated
-        if parameters_identity is not None:
-            pindex = 0
-            for P in porder:
-                for pid, nid in zip(self[P].identities, self[P].names):
-                    if pid in parameters_identity:
-                        parameters.append(nid)
-            return parameters
-
-        # If the full vector is requested, they are added in bulk
-        for P in porder:
-            parameters += list(self[P].names)
-        return parameters
-
-    def get_parameter_identity_vector(self, parameters_identity=None):
-        parameters = []
-        vstart = 0
-        for P, V in zip(
-            self.parameter_order(),
-            self.parameter_vector_len(),
-        ):
-            for pid in self[P].identities:
-                if parameters_identity is None or pid in parameters_identity:
-                    parameters.append(pid)
-            vstart += V
-        return parameters
-
-    def transform(self, in_parameters, to_representation = True, parameters_identity = None):
-        out_parameters = torch.zeros(
-            np.sum(self.parameter_vector_len(parameters_identity = parameters_identity)),
-            dtype=AP_config.ap_dtype,
-            device=AP_config.ap_device,
-        )
-        porder = self.parameter_order(parameters_identity = parameters_identity)
-        
-        # If vector is requested by identity, they are individually updated
-        if parameters_identity is not None:
-            pindex = 0
-            for P in porder:
-                for pid in self[P].identities:
-                    if pid in parameters_identity:
-                        if to_representation:
-                            out_parameters[pindex] = self[P].val_to_rep(in_parameters[pindex])
-                        else:
-                            out_parameters[pindex] = self[P].rep_to_val(in_parameters[pindex])
-                        pindex += 1
-            return out_parameters
-        
-        # If the full vector is requested, they are added in bulk
-        vstart = 0
-        for P, V in zip(
-            porder,
-            self.parameter_vector_len(),
-        ):
-            if to_representation:
-                out_parameters[vstart : vstart + V] = self[P].val_to_rep(in_parameters[vstart : vstart + V])
-            else:
-                out_parameters[vstart : vstart + V] = self[P].rep_to_val(in_parameters[vstart : vstart + V])
-            vstart += V
-        return out_parameters
-
-    def get_uncertainty_vector(self, as_representation=False):
-        uncertanty = torch.zeros(
-            np.sum(self.parameter_vector_len()),
-            dtype=AP_config.ap_dtype,
-            device=AP_config.ap_device,
-        )
-        vstart = 0
-        for P, V in zip(
-            self.parameter_order(),
-            self.parameter_vector_len(),
-        ):
-            if as_representation:
-                uncertanty[vstart : vstart + V] = self[P].uncertainty_representation
-            else:
-                uncertanty[vstart : vstart + V] = self[P].uncertainty
-            vstart += V
-        return uncertanty
+    @property
+    def parameter_order(self):
+        return tuple(P.name for P in self.parameters)
 
     def __str__(self):
         """String representation for the model."""
-        return str(self.get_state())
+        return yaml.dump(self.get_state(), indent=2)
 
     def get_state(self):
         state = {
             "name": self.name,
             "model_type": self.model_type,
         }
         return state
 
     def save(self, filename="AutoProf.yaml"):
         if filename.endswith(".yaml"):
-            import yaml
-
             state = self.get_state()
             with open(filename, "w") as f:
                 yaml.dump(state, f, indent=2)
         elif filename.endswith(".json"):
             import json
 
             state = self.get_state()
@@ -511,20 +283,16 @@
                 )
 
     @classmethod
     def load(cls, filename="AutoProf.yaml"):
         if isinstance(filename, dict):
             state = filename
         elif isinstance(filename, io.TextIOBase):
-            import yaml
-
             state = yaml.load(filename, Loader=yaml.FullLoader)
         elif filename.endswith(".yaml"):
-            import yaml
-
             with open(filename, "r") as f:
                 state = yaml.load(f, Loader=yaml.FullLoader)
         elif filename.endswith(".json"):
             import json
 
             with open(filename, "r") as f:
                 state = json.load(f)
@@ -560,25 +328,34 @@
         for model in MODELS:
             names.append(model.model_type)
         return list(sorted(names, key=lambda n: n[::-1]))
 
     def __eq__(self, other):
         return self is other
 
+    def __getitem__(self, key):
+        return self.parameters[key]
+
+    def __contains__(self, key):
+        return self.parameters.__contains__(key)
+
     @select_sample
     def __call__(
         self,
         image=None,
         parameters=None,
         as_representation=True,
         parameters_identity=None,
         window=None,
         **kwargs,
     ):
-        if parameters is not None:
-            self.set_parameters(
+        if parameters is None:
+            parameters = self.parameters
+        elif isinstance(parameters, torch.Tensor):
+            self.parameters.set_values(
                 parameters,
                 as_representation=as_representation,
                 parameters_identity=parameters_identity,
             )
+            parameters = self.parameters
 
-        return self.sample(image=image, window=window, **kwargs)
+        return self.sample(image=image, window=window, parameters=parameters, **kwargs)
```

## autoprof/models/edgeon_model.py

```diff
@@ -1,16 +1,18 @@
+from typing import Optional
+
 from scipy.stats import iqr
 import torch
 import numpy as np
 
 from .model_object import Component_Model
 from ._shared_methods import select_target
 from ..utils.initialize import isophotes
 from ..utils.angle_operations import Angle_Average
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.conversions.coordinates import (
     Rotate_Cartesian,
     Axis_Ratio_Cartesian,
     coord_to_index,
     index_to_coord,
 )
 
@@ -36,62 +38,76 @@
     }
     _parameter_order = Component_Model._parameter_order + ("PA",)
     useable = False
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
-        if self["PA"].value is not None:
+    @default_internal
+    def initialize(
+        self, target=None, parameters: Optional["Parameter_Group"] = None, **kwargs
+    ):
+        super().initialize(target=target, parameters=parameters)
+        if parameters["PA"].value is not None:
             return
         target_area = target[self.window]
         edge = np.concatenate(
             (
                 target_area.data[:, 0],
                 target_area.data[:, -1],
                 target_area.data[0, :],
                 target_area.data[-1, :],
             )
         )
         edge_average = np.median(edge)
         edge_scatter = iqr(edge, rng=(16, 84)) / 2
         icenter = coord_to_index(
-            self["center"].value[0], self["center"].value[1], target_area
+            parameters["center"].value[0], parameters["center"].value[1], target_area
         )
         iso_info = isophotes(
             target_area.data.detach().cpu().numpy() - edge_average,
             (icenter[1].detach().cpu().item(), icenter[0].detach().cpu().item()),
             threshold=3 * edge_scatter,
             pa=0.0,
             q=1.0,
             n_isophotes=15,
         )
-        self["PA"].set_value(
+        parameters["PA"].set_value(
             (
                 -Angle_Average(
                     list(iso["phase2"] for iso in iso_info[-int(len(iso_info) / 3) :])
                 )
                 / 2
             )
             % np.pi,
             override_locked=True,
         )
 
-    def transform_coordinates(self, X, Y):
-        return Rotate_Cartesian(-self["PA"].value, X, Y)
-
-    def evaluate_model(self, image, X = None, Y = None, **kwargs):
+    @default_internal
+    def transform_coordinates(self, X, Y, image=None, parameters=None):
+        return Rotate_Cartesian(-parameters["PA"].value, X, Y)
+
+    @default_internal
+    def evaluate_model(
+        self,
+        X=None,
+        Y=None,
+        image: "Image" = None,
+        parameters: "Parameter_Group" = None,
+        **kwargs,
+    ):
         if X is None:
             X, Y = image.get_coordinate_meshgrid_torch(
-                self["center"].value[0], self["center"].value[1]
+                parameters["center"].value[0], parameters["center"].value[1]
             )
-        XX, YY = self.transform_coordinates(X, Y)
+        XX, YY = self.transform_coordinates(X, Y, image=image, parameters=parameters)
 
-        return self.brightness_model(torch.abs(XX), torch.abs(YY), image)
+        return self.brightness_model(
+            torch.abs(XX), torch.abs(YY), image=image, parameters=parameters
+        )
 
 
 class Edgeon_Sech(Edgeon_Model):
     """An edgeon profile where the vertical distribution is a sech^2
     profile, subclasses define the radial profile.
 
     """
@@ -103,57 +119,63 @@
     }
     _parameter_order = Edgeon_Model._parameter_order + ("I0", "hs")
     useable = False
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
-        if (self["I0"].value is not None) and (self["hs"].value is not None):
+    @default_internal
+    def initialize(
+        self, target=None, parameters: Optional["Parameter_Group"] = None, **kwargs
+    ):
+        super().initialize(target=target, parameters=parameters)
+        if (parameters["I0"].value is not None) and (
+            parameters["hs"].value is not None
+        ):
             return
         target_area = target[self.window]
         icenter = coord_to_index(
-            self["center"].value[0], self["center"].value[1], target_area
+            parameters["center"].value[0], parameters["center"].value[1], target_area
         )
-        if self["I0"].value is None:
-            self["I0"].set_value(
+        if parameters["I0"].value is None:
+            parameters["I0"].set_value(
                 torch.log10(
                     torch.mean(
                         target_area.data[
                             int(icenter[0]) - 2 : int(icenter[0]) + 2,
                             int(icenter[1]) - 2 : int(icenter[1]) + 2,
                         ]
                     )
                     / target.pixelscale ** 2
                 ),
                 override_locked=True,
             )
-            self["I0"].set_uncertainty(
+            parameters["I0"].set_uncertainty(
                 torch.std(
                     target_area.data[
                         int(icenter[0]) - 2 : int(icenter[0]) + 2,
                         int(icenter[1]) - 2 : int(icenter[1]) + 2,
                     ]
                 )
-                / (torch.abs(self["I0"].value) * target.pixelscale ** 2),
+                / (torch.abs(parameters["I0"].value) * target.pixelscale ** 2),
                 override_locked=True,
             )
-        if self["hs"].value is None:
-            self["hs"].set_value(
+        if parameters["hs"].value is None:
+            parameters["hs"].set_value(
                 torch.max(self.window.shape) * 0.1, override_locked=True
             )
-            self["hs"].set_value(self["hs"].value / 2, override_locked=True)
+            parameters["hs"].set_value(parameters["hs"].value / 2, override_locked=True)
 
-    def brightness_model(self, X, Y, image):
+    @default_internal
+    def brightness_model(self, X, Y, image=None, parameters=None):
         return (
             (image.pixelscale ** 2)
-            * (10 ** self["I0"].value)
-            * self.radial_model(X)
-            / (torch.cosh(Y / self["hs"].value) ** 2)
+            * (10 ** parameters["I0"].value)
+            * self.radial_model(X, image=image, parameters=parameters)
+            / (torch.cosh(Y / parameters["hs"].value) ** 2)
         )
 
 
 class Edgeon_Isothermal(Edgeon_Sech):
     """A self-gravitating locally-isothermal edgeon disk. This comes from
     van der Kruit & Searle 1981.
 
@@ -165,21 +187,27 @@
     }
     _parameter_order = Edgeon_Sech._parameter_order + ("rs",)
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
-        if self["rs"].value is not None:
+    @default_internal
+    def initialize(
+        self, target=None, parameters: Optional["Parameter_Group"] = None, **kwargs
+    ):
+        super().initialize(target=target, parameters=parameters)
+        if parameters["rs"].value is not None:
             return
-        self["rs"].set_value(torch.max(self.window.shape) * 0.4, override_locked=True)
-        self["rs"].set_value(self["rs"].value / 2, override_locked=True)
+        parameters["rs"].set_value(
+            torch.max(self.window.shape) * 0.4, override_locked=True
+        )
+        parameters["rs"].set_value(parameters["rs"].value / 2, override_locked=True)
 
-    def radial_model(self, R):
-        Rscaled = torch.abs(R / self["rs"].value)
+    @default_internal
+    def radial_model(self, R, image=None, parameters=None):
+        Rscaled = torch.abs(R / parameters["rs"].value)
         return (
             Rscaled
             * torch.exp(-Rscaled)
             * torch.special.scaled_modified_bessel_k1(Rscaled)
         )
```

## autoprof/models/exponential_model.py

```diff
@@ -1,7 +1,9 @@
+from typing import Optional
+
 import torch
 import numpy as np
 from scipy.stats import iqr
 from scipy.optimize import minimize
 
 from .galaxy_model_object import Galaxy_Model
 from .warp_model import Warp_Galaxy
@@ -13,15 +15,15 @@
 from .wedge_model import Wedge_Galaxy
 from ._shared_methods import (
     parametric_initialize,
     parametric_segment_initialize,
     select_target,
 )
 from ..utils.initialize import isophotes
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.parametric_profiles import exponential_torch, exponential_np
 from ..utils.conversions.coordinates import (
     Rotate_Cartesian,
     coord_to_index,
     index_to_coord,
 )
 
@@ -68,18 +70,23 @@
     }
     _parameter_order = Galaxy_Model._parameter_order + ("Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(
+        self, target=None, parameters: Optional["Parameter_Group"] = None, **kwargs
+    ):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_exp, ("Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_exp, ("Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import exponential_radial_model as radial_model
 
 
 class Exponential_Star(Star_Model):
     """basic star model with a exponential profile for the radial light
     profile.
@@ -104,26 +111,34 @@
     }
     _parameter_order = Star_Model._parameter_order + ("Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_exp, ("Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_exp, ("Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import exponential_radial_model as radial_model
 
-    def evaluate_model(self, image):
+    @default_internal
+    def evaluate_model(self, image=None, parameters=None):
         X, Y = image.get_coordinate_meshgrid_torch(
-            self["center"].value[0], self["center"].value[1]
+            parameters["center"].value[0], parameters["center"].value[1]
+        )
+        return self.radial_model(
+            self.radius_metric(X, Y, image=image, parameters=parameters),
+            image=image,
+            parameters=parameters,
         )
-        return self.radial_model(self.radius_metric(X, Y), image)
 
 
 class Exponential_SuperEllipse(SuperEllipse_Galaxy):
     """super ellipse galaxy model with a exponential profile for the radial
     light profile.
 
     I(R) = Ie * exp(-b1(R/Re - 1))
@@ -146,18 +161,21 @@
     }
     _parameter_order = SuperEllipse_Galaxy._parameter_order + ("Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_exp, ("Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_exp, ("Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import exponential_radial_model as radial_model
 
 
 class Exponential_SuperEllipse_Warp(SuperEllipse_Warp):
     """super ellipse warp galaxy model with a exponential profile for the
     radial light profile.
@@ -182,18 +200,21 @@
     }
     _parameter_order = SuperEllipse_Warp._parameter_order + ("Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_exp, ("Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_exp, ("Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import exponential_radial_model as radial_model
 
 
 class Exponential_FourierEllipse(FourierEllipse_Galaxy):
     """fourier mode perturbations to ellipse galaxy model with an
     expoential profile for the radial light profile.
@@ -217,19 +238,22 @@
         "Re": {"units": "arcsec", "limits": (0, None)},
     }
     _parameter_order = FourierEllipse_Galaxy._parameter_order + ("Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
-    @select_target    
-    def initialize(self, target=None):
-        super().initialize(target)
+    @select_target
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_exp, ("Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_exp, ("Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import exponential_radial_model as radial_model
 
 
 class Exponential_FourierEllipse_Warp(FourierEllipse_Warp):
     """fourier mode perturbations to ellipse galaxy model with a exponential
     profile for the radial light profile.
@@ -254,18 +278,21 @@
     }
     _parameter_order = FourierEllipse_Warp._parameter_order + ("Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_exp, ("Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_exp, ("Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import exponential_radial_model as radial_model
 
 
 class Exponential_Warp(Warp_Galaxy):
     """warped coordinate galaxy model with a exponential profile for the
     radial light model.
@@ -289,19 +316,22 @@
         "Re": {"units": "arcsec", "limits": (0, None)},
     }
     _parameter_order = Warp_Galaxy._parameter_order + ("Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
-    @select_target   
-    def initialize(self, target=None):
-        super().initialize(target)
+    @select_target
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_exp, ("Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_exp, ("Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import exponential_radial_model as radial_model
 
 
 class Exponential_Ray(Ray_Galaxy):
     """ray galaxy model with a sersic profile for the radial light
     model. The functional form of the Sersic profile is defined as:
@@ -326,19 +356,26 @@
     }
     _parameter_order = Ray_Galaxy._parameter_order + ("Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_segment_initialize(
-            self, target, _wrap_exp, ("Re", "Ie"), _x0_func, self.rays
+            model=self,
+            parameters=parameters,
+            target=target,
+            prof_func=_wrap_exp,
+            params=("Re", "Ie"),
+            x0_func=_x0_func,
+            segments=self.rays,
         )
 
     from ._shared_methods import exponential_iradial_model as iradial_model
 
 
 class Exponential_Wedge(Wedge_Galaxy):
     """wedge galaxy model with a exponential profile for the radial light
@@ -364,15 +401,22 @@
     }
     _parameter_order = Wedge_Galaxy._parameter_order + ("Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_segment_initialize(
-            self, target, _wrap_exp, ("Re", "Ie"), _x0_func, self.wedges
+            model=self,
+            parameters=parameters,
+            target=target,
+            prof_func=_wrap_exp,
+            params=("Re", "Ie"),
+            x0_func=_x0_func,
+            segments=self.wedges,
         )
 
     from ._shared_methods import exponential_iradial_model as iradial_model
```

## autoprof/models/flatsky_model.py

```diff
@@ -1,12 +1,12 @@
 import numpy as np
 from scipy.stats import iqr
 import torch
 
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from .sky_model_object import Sky_Model
 from ._shared_methods import select_target
 
 __all__ = ["Flat_Sky"]
 
 
 class Flat_Sky(Sky_Model):
@@ -24,42 +24,39 @@
     }
     _parameter_order = Sky_Model._parameter_order + ("sky",)
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        if self["sky"].value is None:
-            self["sky"].set_representation(
+        if parameters["sky"].value is None:
+            parameters["sky"].set_representation(
                 np.log10(
                     torch.median(target[self.window].data) / target.pixelscale ** 2
                 ),
                 override_locked=True,
             )
-        if self["sky"].uncertainty is None:
-            self["sky"].set_uncertainty(
+        if parameters["sky"].uncertainty is None:
+            parameters["sky"].set_uncertainty(
                 (
                     (
                         iqr(
                             target[self.window].data.detach().cpu().numpy(),
                             rng=(31.731 / 2, 100 - 31.731 / 2),
                         )
                         / (2.0 * target.pixelscale.item() ** 2)
                     )
                     / np.sqrt(np.prod(self.window.shape.detach().cpu().numpy()))
                 )
-                / (10 ** self["sky"].value * np.log(10)),
+                / (10 ** parameters["sky"].value * np.log(10)),
                 override_locked=True,
             )
 
-    def evaluate_model(self, image, X = None, Y = None, **kwargs):
-        if X is None:
-            ref = image.data
-        else:
-            ref = X
+    def evaluate_model(self, X=None, Y=None, image=None, parameters=None, **kwargs):
+        ref = image.data if X is None else X
         return torch.ones_like(ref) * (
-            (10 ** self["sky"].value) * image.pixelscale ** 2
+            (10 ** parameters["sky"].value) * image.pixelscale ** 2
         )
-
```

## autoprof/models/foureirellipse_model.py

```diff
@@ -1,14 +1,15 @@
 import torch
 import numpy as np
 
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from .galaxy_model_object import Galaxy_Model
 from .warp_model import Warp_Galaxy
 from ._shared_methods import select_target
+from .. import AP_config
 
 __all__ = ["FourierEllipse_Galaxy", "FourierEllipse_Warp"]
 
 
 class FourierEllipse_Galaxy(Galaxy_Model):
     """Expanded galaxy model which includes a Fourier transformation in
     its radius metric. This allows for the expression of arbitrarily
@@ -52,54 +53,86 @@
 
     model_type = f"fourier {Galaxy_Model.model_type}"
     parameter_specs = {
         "am": {"units": "none"},
         "phim": {"units": "radians", "limits": (0, 2 * np.pi), "cyclic": True},
     }
     _parameter_order = Galaxy_Model._parameter_order + ("am", "phim")
+    modes = (1, 3, 4)
+    track_attrs = Galaxy_Model.track_attrs + ["modes"]
     useable = False
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
-        self.modes = torch.tensor(kwargs.get("modes", (1, 3, 4)))
+        self.modes = torch.tensor(
+            kwargs.get("modes", FourierEllipse_Galaxy.modes),
+            dtype=AP_config.ap_dtype,
+            device=AP_config.ap_device,
+        )
 
-    def angular_metric(self, X, Y):
+    @default_internal
+    def angular_metric(self, X, Y, image=None, parameters=None):
         return torch.atan2(Y, X)
 
-    def radius_metric(self, X, Y):
-        R = super().radius_metric(X, Y)
-        theta = self.angular_metric(X, Y)
+    @default_internal
+    def radius_metric(self, X, Y, image=None, parameters=None):
+        R = super().radius_metric(X, Y, image, parameters)
+        theta = self.angular_metric(X, Y, image, parameters)
         return R * torch.exp(
             torch.sum(
-                self["am"].value.view(len(self.modes), -1)
+                parameters["am"].value.view(len(self.modes), -1)
                 * torch.cos(
                     self.modes.view(len(self.modes), -1) * theta.view(-1)
-                    + self["phim"].value.view(len(self.modes), -1)
+                    + parameters["phim"].value.view(len(self.modes), -1)
                 ),
                 0,
             ).view(theta.shape)
         )
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
-
-        if self["am"].value is None:
-            self["am"].set_value(torch.zeros(len(self.modes)), override_locked=True)
-        if self["am"].uncertainty is None:
-            self["am"].set_uncertainty(
-                torch.tensor(0.05 * np.ones(len(self.modes))), override_locked=True
-            )
-        if self["phim"].value is None:
-            self["phim"].set_value(torch.zeros(len(self.modes)), override_locked=True)
-        if self["phim"].uncertainty is None:
-            self["phim"].set_uncertainty(
-                torch.tensor((5 * np.pi / 180) * np.ones(len(self.modes))),
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
+
+        if parameters["am"].value is None:
+            parameters["am"].set_value(
+                torch.zeros(
+                    len(self.modes),
+                    dtype=AP_config.ap_dtype,
+                    device=AP_config.ap_device,
+                ),
+                override_locked=True,
+            )
+        if parameters["am"].uncertainty is None:
+            parameters["am"].set_uncertainty(
+                torch.tensor(
+                    0.05 * np.ones(len(self.modes)),
+                    dtype=AP_config.ap_dtype,
+                    device=AP_config.ap_device,
+                ),
+                override_locked=True,
+            )
+        if parameters["phim"].value is None:
+            parameters["phim"].set_value(
+                torch.zeros(
+                    len(self.modes),
+                    dtype=AP_config.ap_dtype,
+                    device=AP_config.ap_device,
+                ),
+                override_locked=True,
+            )
+        if parameters["phim"].uncertainty is None:
+            parameters["phim"].set_uncertainty(
+                torch.tensor(
+                    (5 * np.pi / 180) * np.ones(len(self.modes)),
+                    dtype=AP_config.ap_dtype,
+                    device=AP_config.ap_device,
+                ),
                 override_locked=True,
             )
 
 
 class FourierEllipse_Warp(Warp_Galaxy):
     """Expanded warp galaxy model which includes a Fourier transformation
     in its radius metric. This allows for the expression of
@@ -143,49 +176,81 @@
 
     model_type = f"fourier {Warp_Galaxy.model_type}"
     parameter_specs = {
         "am": {"units": "none"},
         "phim": {"units": "radians", "limits": (0, 2 * np.pi), "cyclic": True},
     }
     _parameter_order = Warp_Galaxy._parameter_order + ("am", "phim")
+    modes = (1, 3, 4)
+    track_attrs = Galaxy_Model.track_attrs + ["modes"]
     useable = False
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
-        self.modes = torch.tensor(kwargs.get("modes", (1, 3, 4)))
+        self.modes = torch.tensor(
+            kwargs.get("modes", FourierEllipse_Warp.modes),
+            dtype=AP_config.ap_dtype,
+            device=AP_config.ap_device,
+        )
 
-    def angular_metric(self, X, Y):
+    @default_internal
+    def angular_metric(self, X, Y, image=None, parameters=None):
         return torch.atan2(Y, X)
 
-    def radius_metric(self, X, Y):
-        R = super().radius_metric(X, Y)
-        theta = self.angular_metric(X, Y)
+    @default_internal
+    def radius_metric(self, X, Y, image=None, parameters=None):
+        R = super().radius_metric(X, Y, image, parameters)
+        theta = self.angular_metric(X, Y, image, parameters)
         return R * torch.exp(
             torch.sum(
-                self["am"].value.view(len(self.modes), -1)
+                parameters["am"].value.view(len(self.modes), -1)
                 * torch.cos(
                     self.modes.view(len(self.modes), -1) * theta.view(-1)
-                    + self["phim"].value.view(len(self.modes), -1)
+                    + parameters["phim"].value.view(len(self.modes), -1)
                 ),
                 0,
             ).view(theta.shape)
         )
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
-
-        if self["am"].value is None:
-            self["am"].set_value(torch.zeros(len(self.modes)), override_locked=True)
-        if self["am"].uncertainty is None:
-            self["am"].set_uncertainty(
-                torch.tensor(0.05 * np.ones(len(self.modes))), override_locked=True
-            )
-        if self["phim"].value is None:
-            self["phim"].set_value(torch.zeros(len(self.modes)), override_locked=True)
-        if self["phim"].uncertainty is None:
-            self["phim"].set_uncertainty(
-                torch.tensor((5 * np.pi / 180) * np.ones(len(self.modes))),
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
+
+        if parameters["am"].value is None:
+            parameters["am"].set_value(
+                torch.zeros(
+                    len(self.modes),
+                    dtype=AP_config.ap_dtype,
+                    device=AP_config.ap_device,
+                ),
+                override_locked=True,
+            )
+        if parameters["am"].uncertainty is None:
+            parameters["am"].set_uncertainty(
+                torch.tensor(
+                    0.05 * np.ones(len(self.modes)),
+                    dtype=AP_config.ap_dtype,
+                    device=AP_config.ap_device,
+                ),
+                override_locked=True,
+            )
+        if parameters["phim"].value is None:
+            parameters["phim"].set_value(
+                torch.zeros(
+                    len(self.modes),
+                    dtype=AP_config.ap_dtype,
+                    device=AP_config.ap_device,
+                ),
+                override_locked=True,
+            )
+        if parameters["phim"].uncertainty is None:
+            parameters["phim"].set_uncertainty(
+                torch.tensor(
+                    (5 * np.pi / 180) * np.ones(len(self.modes)),
+                    dtype=AP_config.ap_dtype,
+                    device=AP_config.ap_device,
+                ),
                 override_locked=True,
             )
```

## autoprof/models/galaxy_model_object.py

```diff
@@ -1,13 +1,15 @@
+from typing import Optional
+
 import torch
 import numpy as np
 from scipy.stats import iqr
 
 from ..utils.initialize import isophotes
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.angle_operations import Angle_Average
 from ..utils.conversions.coordinates import (
     Rotate_Cartesian,
     Axis_Ratio_Cartesian,
     coord_to_index,
     index_to_coord,
 )
@@ -52,79 +54,91 @@
     }
     _parameter_order = Component_Model._parameter_order + ("q", "PA")
     useable = False
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
-        if not (self["PA"].value is None or self["q"].value is None):
+    @default_internal
+    def initialize(
+        self, target=None, parameters: Optional["Parameter_Group"] = None, **kwargs
+    ):
+        super().initialize(target=target, parameters=parameters)
+        if not (parameters["PA"].value is None or parameters["q"].value is None):
             return
         target_area = target[self.window]
         edge = np.concatenate(
             (
                 target_area.data.detach().cpu().numpy()[:, 0],
                 target_area.data.detach().cpu().numpy()[:, -1],
                 target_area.data.detach().cpu().numpy()[0, :],
                 target_area.data.detach().cpu().numpy()[-1, :],
             )
         )
         edge_average = np.median(edge)
         edge_scatter = iqr(edge, rng=(16, 84)) / 2
         icenter = coord_to_index(
-            self["center"].value[0], self["center"].value[1], target_area
+            parameters["center"].value[0], parameters["center"].value[1], target_area
         )
-        if self["PA"].value is None:
+        if parameters["PA"].value is None:
             iso_info = isophotes(
                 target_area.data.detach().cpu().numpy() - edge_average,
                 (icenter[1].detach().cpu().item(), icenter[0].detach().cpu().item()),
                 threshold=3 * edge_scatter,
                 pa=0.0,
                 q=1.0,
                 n_isophotes=15,
             )
-            self["PA"].set_value(
+            parameters["PA"].set_value(
                 (
                     -Angle_Average(
                         list(
                             iso["phase2"] for iso in iso_info[-int(len(iso_info) / 3) :]
                         )
                     )
                     / 2
                 )
                 % np.pi,
                 override_locked=True,
             )
-        if self["q"].value is None:
+        if parameters["q"].value is None:
             q_samples = np.linspace(0.1, 0.9, 15)
             iso_info = isophotes(
                 target_area.data.detach().cpu().numpy() - edge_average,
                 (icenter[1].detach().cpu().item(), icenter[0].detach().cpu().item()),
                 threshold=3 * edge_scatter,
-                pa=self["PA"].value.detach().cpu().item(),
+                pa=parameters["PA"].value.detach().cpu().item(),
                 q=q_samples,
             )
-            self["q"].set_value(
+            parameters["q"].set_value(
                 q_samples[np.argmin(list(iso["amplitude2"] for iso in iso_info))],
                 override_locked=True,
             )
 
-    def radius_metric(self, X, Y):
+    @default_internal
+    def radius_metric(self, X, Y, image=None, parameters=None):
         return torch.sqrt(
             (torch.abs(X) + 1e-8) ** 2 + (torch.abs(Y) + 1e-8) ** 2
         )  # epsilon added for numerical stability of gradient
 
-    def transform_coordinates(self, X, Y):
-        X, Y = Rotate_Cartesian(-self["PA"].value, X, Y)
+    @default_internal
+    def transform_coordinates(self, X, Y, image=None, parameters=None):
+        X, Y = Rotate_Cartesian(-parameters["PA"].value, X, Y)
         return (
             X,
-            Y / self["q"].value,
-        )  # Axis_Ratio_Cartesian(self["q"].value, X, Y, self["PA"].value, inv_scale = True)
+            Y / parameters["q"].value,
+        )
 
-    def evaluate_model(self, image, X = None, Y = None, **kwargs):
+    @default_internal
+    def evaluate_model(
+        self, X=None, Y=None, image=None, parameters: "Parameter_Group" = None, **kwargs
+    ):
         if X is None or Y is None:
             X, Y = image.get_coordinate_meshgrid_torch(
-                self["center"].value[0], self["center"].value[1]
+                parameters["center"].value[0], parameters["center"].value[1]
             )
-        XX, YY = self.transform_coordinates(X, Y)
-        return self.radial_model(self.radius_metric(XX, YY), image)
+        XX, YY = self.transform_coordinates(X, Y, image, parameters)
+        return self.radial_model(
+            self.radius_metric(XX, YY, image, parameters),
+            image=image,
+            parameters=parameters,
+        )
```

## autoprof/models/gaussian_model.py

```diff
@@ -9,15 +9,15 @@
 from .wedge_model import Wedge_Galaxy
 from .star_model_object import Star_Model
 from ._shared_methods import (
     parametric_initialize,
     parametric_segment_initialize,
     select_target,
 )
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.parametric_profiles import gaussian_torch, gaussian_np
 
 __all__ = [
     "Gaussian_Galaxy",
     "Gaussian_SuperEllipse",
     "Gaussian_SuperEllipse_Warp",
     "Gaussian_FourierEllipse",
@@ -58,18 +58,21 @@
     }
     _parameter_order = Galaxy_Model._parameter_order + ("sigma", "flux")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_gauss, ("sigma", "flux"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_gauss, ("sigma", "flux"), _x0_func
+        )
 
     from ._shared_methods import gaussian_radial_model as radial_model
 
 
 class Gaussian_SuperEllipse(SuperEllipse_Galaxy):
     """Super ellipse galaxy model with Gaussian as the radial light
     profile.The gaussian radial profile is defined as:
@@ -93,18 +96,21 @@
     }
     _parameter_order = SuperEllipse_Galaxy._parameter_order + ("sigma", "flux")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_gauss, ("sigma", "flux"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_gauss, ("sigma", "flux"), _x0_func
+        )
 
     from ._shared_methods import gaussian_radial_model as radial_model
 
 
 class Gaussian_SuperEllipse_Warp(SuperEllipse_Warp):
     """super ellipse warp galaxy model with a gaussian profile for the
     radial light profile. The gaussian radial profile is defined as:
@@ -128,18 +134,21 @@
     }
     _parameter_order = SuperEllipse_Warp._parameter_order + ("sigma", "flux")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_gauss, ("sigma", "flux"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_gauss, ("sigma", "flux"), _x0_func
+        )
 
     from ._shared_methods import gaussian_radial_model as radial_model
 
 
 class Gaussian_FourierEllipse(FourierEllipse_Galaxy):
     """fourier mode perturbations to ellipse galaxy model with a gaussian
     profile for the radial light profile. The gaussian radial profile
@@ -164,18 +173,21 @@
     }
     _parameter_order = FourierEllipse_Galaxy._parameter_order + ("sigma", "flux")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_gauss, ("sigma", "flux"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_gauss, ("sigma", "flux"), _x0_func
+        )
 
     from ._shared_methods import gaussian_radial_model as radial_model
 
 
 class Gaussian_FourierEllipse_Warp(FourierEllipse_Warp):
     """fourier mode perturbations to ellipse galaxy model with a gaussian
     profile for the radial light profile. The gaussian radial profile
@@ -200,18 +212,21 @@
     }
     _parameter_order = FourierEllipse_Warp._parameter_order + ("sigma", "flux")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_gauss, ("sigma", "flux"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_gauss, ("sigma", "flux"), _x0_func
+        )
 
     from ._shared_methods import gaussian_radial_model as radial_model
 
 
 class Gaussian_Warp(Warp_Galaxy):
     """Coordinate warped galaxy model with Gaussian as the radial light
     profile. The gaussian radial profile is defined as:
@@ -235,18 +250,21 @@
     }
     _parameter_order = Warp_Galaxy._parameter_order + ("sigma", "flux")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_gauss, ("sigma", "flux"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_gauss, ("sigma", "flux"), _x0_func
+        )
 
     from ._shared_methods import gaussian_radial_model as radial_model
 
 
 class Gaussian_Star(Star_Model):
     """Basica star model with a Gaussian as the radial light profile. The
     gaussian radial profile is defined as:
@@ -270,26 +288,31 @@
     }
     _parameter_order = Star_Model._parameter_order + ("sigma", "flux")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_gauss, ("sigma", "flux"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_gauss, ("sigma", "flux"), _x0_func
+        )
 
     from ._shared_methods import gaussian_radial_model as radial_model
 
-    def evaluate_model(self, image):
-        X, Y = image.get_coordinate_meshgrid_torch(
-            self["center"].value[0], self["center"].value[1]
-        )
-        return self.radial_model(torch.sqrt(X ** 2 + Y ** 2), image)
+    @default_internal
+    def evaluate_model(self, X=None, Y=None, image=None, parameters=None):
+        if X is None:
+            X, Y = image.get_coordinate_meshgrid_torch(
+                parameters["center"].value[0], parameters["center"].value[1]
+            )
+        return self.radial_model(torch.sqrt(X ** 2 + Y ** 2), image, parameters)
 
 
 class Gaussian_Ray(Ray_Galaxy):
     """ray galaxy model with a gaussian profile for the radial light
     model. The gaussian radial profile is defined as:
 
     I(R) = F * exp(-0.5 R^2/S^2) / sqrt(2pi*S^2)
@@ -311,19 +334,26 @@
     }
     _parameter_order = Ray_Galaxy._parameter_order + ("sigma", "flux")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_segment_initialize(
-            self, target, _wrap_gauss, ("sigma", "flux"), _x0_func, self.rays
+            model=self,
+            parameters=parameters,
+            target=target,
+            prof_func=_wrap_gauss,
+            params=("sigma", "flux"),
+            x0_func=_x0_func,
+            segments=self.rays,
         )
 
     from ._shared_methods import gaussian_iradial_model as iradial_model
 
 
 class Gaussian_Wedge(Wedge_Galaxy):
     """wedge galaxy model with a gaussian profile for the radial light
@@ -348,15 +378,22 @@
     }
     _parameter_order = Wedge_Galaxy._parameter_order + ("sigma", "flux")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_segment_initialize(
-            self, target, _wrap_gauss, ("sigma", "flux"), _x0_func, self.wedges
+            self,
+            parameters,
+            target,
+            _wrap_gauss,
+            ("sigma", "flux"),
+            _x0_func,
+            self.wedges,
         )
 
     from ._shared_methods import gaussian_iradial_model as iradial_model
```

## autoprof/models/group_model_object.py

```diff
@@ -1,24 +1,25 @@
 from copy import deepcopy
 from typing import Optional, Sequence
+from collections import OrderedDict
 
 import torch
 import numpy as np
 import matplotlib.pyplot as plt
 
 from .core_model import AutoProf_Model
 from ..image import (
     Model_Image,
     Model_Image_List,
     Target_Image,
     Image_List,
     Window,
     Window_List,
 )
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ._shared_methods import select_target
 from .. import AP_config
 
 __all__ = ["Group_Model"]
 
 
 class Group_Model(AutoProf_Model):
@@ -28,34 +29,34 @@
     summed model. This class shoould be used when describing any
     system more comlex than makes sense to represent with a single
     light distribution.
 
     Args:
         name (str): unique name for the full group model
         target (Target_Image): the target image that this group model is trying to fit to
-        model_list (Optional[Sequence[AutoProf_Model]]): list of AutoProf_Model objects which will combine for the group model
+        models (Optional[Sequence[AutoProf_Model]]): list of AutoProf_Model objects which will combine for the group model
         locked (bool): if the whole group of models should be locked
 
     """
 
     model_type = f"group {AutoProf_Model.model_type}"
     useable = True
 
     def __init__(
         self,
         name: str,
         *args,
-        model_list: Optional[Sequence[AutoProf_Model]] = None,
+        models: Optional[Sequence[AutoProf_Model]] = None,
         **kwargs,
     ):
-        super().__init__(name, *args, model_list=model_list, **kwargs)
+        super().__init__(name, *args, models=models, **kwargs)
         self._param_tuple = None
-        self.model_list = []
-        if model_list is not None:
-            self.add_model(model_list)
+        self.models = OrderedDict()
+        if models is not None:
+            self.add_model(models)
         self._psf_mode = "none"
         self.update_window()
         if "filename" in kwargs:
             self.load(kwargs["filename"])
 
     def add_model(self, model):
         """Adds a new model to the group model list. Ensures that the same
@@ -65,61 +66,44 @@
             model: a model object to add to the model list.
 
         """
         if isinstance(model, (tuple, list)):
             for mod in model:
                 self.add_model(mod)
             return
-        for mod in self.model_list:
-            if model.name == mod.name:
-                raise KeyError(
-                    f"{self.name} already has model with name {model.name}, every model must have a unique name."
-                )
+        if model.name in self.models and model is not self.models[model.name]:
+            raise KeyError(
+                f"{self.name} already has model with name {model.name}, every model must have a unique name."
+            )
 
-        self.model_list.append(model)
+        self.models[model.name] = model
+        self.parameters.add_group(model.parameters)
         self.update_window()
 
     @property
     def equality_constraints(self):
         try:
             return self._equality_constraints
         except AttributeError:
             return []
 
     @equality_constraints.setter
     def equality_constraints(self, val):
         pass
 
-    def pop_model(self, model):
-        """Removes the specified model from the group model list. Returns the
-        model object if it is found.
-
-        """
-        if isinstance(model, (tuple, list)):
-            return tuple(self.remove_model(mod) for mod in model)
-        if isinstance(model, str):
-            for sub_model in self.model_list:
-                if sub_model.name == model:
-                    model = sub_model
-                    break
-            else:
-                raise KeyError(f"Could not find {model} in {self.name} model list")
-
-        return self.model_list.pop(self.model_list.index(model))
-
     def update_window(self, include_locked: bool = False):
         """Makes a new window object which encloses all the windows of the
         sub models in this group model object.
 
         """
         if isinstance(
             self.target, Image_List
         ):  # Window_List if target is a Target_Image_List
             new_window = [None] * len(self.target.image_list)
-            for model in self.model_list:
+            for model in self.models.values():
                 if model.locked and not include_locked:
                     continue
                 if isinstance(model.target, Image_List):
                     for target, window in zip(model.target, model.window):
                         index = self.target.index(target)
                         if new_window[index] is None:
                             new_window[index] = window.copy()
@@ -129,129 +113,56 @@
                     index = self.target.index(model.target)
                     if new_window[index] is None:
                         new_window[index] = model.window.copy()
                     else:
                         new_window[index] |= model.window
                 else:
                     raise NotImplementedError(
-                        "Group_Model cannot construct a window for itself using {type(model.target)} object. Must be a Target_Image"
+                        f"Group_Model cannot construct a window for itself using {type(model.target)} object. Must be a Target_Image"
                     )
             new_window = Window_List(new_window)
         else:
             new_window = None
-            for model in self.model_list:
+            for model in self.models.values():
                 if model.locked and not include_locked:
                     continue
                 if new_window is None:
                     new_window = model.window.copy()
                 else:
                     new_window |= model.window
         self.window = new_window
 
-    def parameter_tuples_order(self, override_locked: bool = True):
-        """Constructs a list where each entry is a tuple with a unique name
-        for the parameter and the parameter object itself.
-
-        """
-        params = []
-        self._equality_constraints = []
-        for model in self.model_list:
-            if model.locked and not override_locked:
-                continue
-            for p in model.parameters:
-                if model[p].locked and not override_locked:
-                    continue
-                if p in model.equality_constraints:
-                    for k in range(len(params)):
-                        if params[k][1] is model.parameters[p]:
-                            self._equality_constraints.pop(
-                                self.equality_constraints.index(params[k][0])
-                            )
-                            params[k] = (f"{model.name}:{params[k][0]}", params[k][1])
-                            self._equality_constraints.append(params[k][0])
-                            break
-                    else:
-                        params.append((f"{model.name}|{p}", model.parameters[p]))
-                        self._equality_constraints.append(f"{model.name}|{p}")
-                else:
-                    params.append((f"{model.name}|{p}", model.parameters[p]))
-        return params
-
-    def parameter_order(
-        self, override_locked: bool = False, parameters_identity: Optional[tuple] = None
-    ):
-        """Gives the unique parameter names for this model in a repeatable
-        order. By default, locked parameters are excluded from the
-        tuple. The order of parameters will of course not be the same
-        when called with override_locked True/False.
-
-        """
-        param_tuples = self.parameter_tuples_order(override_locked=override_locked)
-        param_order = []
-        for P, M in param_tuples:
-            if parameters_identity is not None and not any(
-                pid in parameters_identity for pid in self[P].identities
-            ):
-                continue
-            param_order.append(P)
-
-        return tuple(param_order)
-
-    @property
-    def param_tuple(self):
-        """A tuple with the name of every parameter in the group model"""
-        if self._param_tuple is None:
-            self._param_tuple = self.parameter_tuples_order(override_locked=True)
-        return self._param_tuple
-
-    @property
-    def parameters(self):
-        """A dictionary in which every unique parameter appears once. This
-        includes locked parameters. For constrained parameters across
-        several models, the parameter will only appear once where the
-        names of the models are connected by ":" characters.
-
-        """
-        try:
-            return dict(P for P in self.param_tuple)
-        except AttributeError:
-            return {}
-
-    @parameters.setter
-    def parameters(self, val):
-        """You cannot set the parameters at the group model level, this
-        function exists simply to avoid raising errors when
-        intializing models.
-
-        """
-        pass
-
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target: Optional["Target_Image"] = None):
+    @default_internal
+    def initialize(
+        self, target: Optional["Target_Image"] = None, parameters=None, **kwargs
+    ):
         """
         Initialize each model in this group. Does this by iteratively initializing a model then subtracting it from a copy of the target.
 
         Args:
           target (Optional["Target_Image"]): A Target_Image instance to use as the source for initializing the model parameters on this image.
         """
         self._param_tuple = None
+        super().initialize(target=target, parameters=parameters)
 
         target_copy = target.copy()
-        for model in self.model_list:
-            model.initialize(target_copy)
-            target_copy -= model()
+        for model in self.models.values():
+            model.initialize(
+                target=target_copy, parameters=parameters.groups[model.name]
+            )
+            target_copy -= model(parameters=parameters.groups[model.name])
 
     def sample(
         self,
-        image: Optional["Model_Image"] = None,
+        image: Optional["Image"] = None,
         window: Optional[Window] = None,
-        *args,
-        **kwargs,
+        parameters: Optional["Parameter_Group"] = None,
     ):
         """Sample the group model on an image. Produces the flux values for
         each pixel associated with the models in this group. Each
         model is called individually and the results are added
         together in one larger image.
 
         Args:
@@ -260,32 +171,38 @@
         """
         self._param_tuple = None
         if image is None:
             sample_window = True
             image = self.make_model_image(window=window)
         else:
             sample_window = False
+        if parameters is None:
+            parameters = self.parameters
 
-        for model in self.model_list:
+        for model in self.models.values():
             if window is not None and isinstance(window, Window_List):
                 indices = self.target.match_indices(model.target)
                 if isinstance(indices, (tuple, list)):
                     use_window = Window_List(
                         window_list=list(window.window_list[ind] for ind in indices)
                     )
                 else:
                     use_window = window.window_list[indices]
             else:
                 use_window = window
             if sample_window:
                 # Will sample the model fit window then add to the image
-                image += model(window=use_window)
+                image += model(
+                    window=use_window, parameters=parameters.groups[model.name]
+                )
             else:
                 # Will sample the entire image
-                model(image, window=use_window)
+                model(
+                    image, window=use_window, parameters=parameters.groups[model.name]
+                )
 
         return image
 
     @torch.no_grad()
     def jacobian(
         self,
         parameters: Optional[torch.Tensor] = None,
@@ -306,30 +223,30 @@
 
         """
         if window is None:
             window = self.window
         self._param_tuple = None
 
         if parameters is not None:
-            self.set_parameters(
+            self.parameters.set_values(
                 parameters,
                 as_representation=as_representation,
                 parameters_identity=parameters_identity,
             )
 
         if pass_jacobian is None:
             jac_img = self.target[window].jacobian_image(
-                parameters=self.get_parameter_identity_vector(
+                parameters=self.parameters.get_identity_vector(
                     parameters_identity=parameters_identity,
                 )
             )
         else:
             jac_img = pass_jacobian
 
-        for model in self.model_list:
+        for model in self.models.values():
             if isinstance(model, Group_Model):
                 model.jacobian(
                     as_representation=as_representation,
                     parameters_identity=parameters_identity,
                     pass_jacobian=jac_img,
                     window=window,
                 )
@@ -339,66 +256,48 @@
                     parameters_identity=parameters_identity,
                     pass_jacobian=jac_img,
                     window=window,
                 )
 
         return jac_img
 
-    def __getitem__(self, key):
-        try:
-            return self.parameters[key]
-        except KeyError:
-            pass
-
-        if isinstance(key, str) and "|" in key:
-            model_name = key[: key.find("|")].split(":")
-            for model in self.model_list:
-                if model.name in model_name:
-                    return model[key[key.find("|") + 1 :]]
-        elif isinstance(key, str):
-            for model in self.model_list:
-                if model.name == key:
-                    return model
-
-        raise KeyError(f"{key} not in {self.name}. {str(self)}")
-
     def __iter__(self):
-        return (mod for mod in self.model_list)
+        return (mod for mod in self.models.values())
 
     @property
     def psf_mode(self):
         return self._psf_mode
 
     @psf_mode.setter
     def psf_mode(self, value):
         self._psf_mode = value
-        for model in self.model_list:
+        for model in self.models.values():
             model.psf_mode = value
 
     def get_state(self):
         """Returns a dictionary with information about the state of the model
         and its parameters.
 
         """
         state = super().get_state()
         if "models" not in state:
             state["models"] = {}
-        for model in self.model_list:
+        for model in self.models.values():
             state["models"][model.name] = model.get_state()
         return state
 
     def load(self, filename="AutoProf.yaml"):
         """Loads an AutoProf state file and updates this model with the
         loaded parameters.
 
         """
         state = AutoProf_Model.load(filename)
         self.name = state["name"]
         for model in state["models"]:
-            for own_model in self.model_list:
+            for own_model in self.models.values():
                 if model == own_model.name:
                     own_model.load(state["models"][model])
                     break
             else:
                 self.add_model(
                     AutoProf_Model(
                         name=model, filename=state["models"][model], target=self.target
```

## autoprof/models/model_object.py

```diff
@@ -5,17 +5,22 @@
 from torch.autograd.functional import jacobian
 import numpy as np
 import torch
 
 from .core_model import AutoProf_Model
 from ..image import Model_Image, Window, PSF_Image
 from .parameter_object import Parameter
+from .parameter_group import Parameter_Group
 from ..utils.initialize import center_of_mass
-from ..utils.decorators import ignore_numpy_warnings
-from ..utils.operations import fft_convolve_torch, fft_convolve_multi_torch, selective_integrate
+from ..utils.decorators import ignore_numpy_warnings, default_internal
+from ..utils.operations import (
+    fft_convolve_torch,
+    fft_convolve_multi_torch,
+    selective_integrate,
+)
 from ..utils.interpolate import _shift_Lanczos_kernel_torch
 from ..utils.conversions.coordinates import coord_to_index, index_to_coord
 from ._shared_methods import select_target
 from .. import AP_config
 
 __all__ = ["Component_Model"]
 
@@ -61,65 +66,67 @@
     psf_mode = "none"  # none, window/full
     # size in pixels of the PSF convolution box
     psf_window_size = 50
     # Integration scope for model
     integrate_mode = "threshold"  # none, window, threshold
 
     # Size of the window in which to perform integration (window mode)
-    integrate_window_size = 10 
+    integrate_window_size = 10
     # Number of pixels on one axis by which to supersample (window mode)
-    integrate_factor = 3  
+    integrate_factor = 3
     # Relative size of windows between recursion levels (2 means each window will be half the size of the previous one, window mode)
-    integrate_recursion_factor = 2  
+    integrate_recursion_factor = 2
     # Number of recursion cycles to apply when integrating (window or threshold mode)
-    integrate_recursion_depth = 3  
+    integrate_recursion_depth = 3
     # Threshold for triggering pixel integration (threshold mode)
-    integrate_threshold = 1e-2 
+    integrate_threshold = 1e-2
 
     # Maximum size of parameter list before jacobian will be broken into smaller chunks, this is helpful for limiting the memory requirements to build a model, lower jacobian_chunksize is slower but uses less memory
-    jacobian_chunksize = 10 
+    jacobian_chunksize = 10
 
     # Parameters which are treated specially by the model object and should not be updated directly when initializing
     special_kwargs = ["parameters", "filename", "model_type"]
+    track_attrs = [
+        "psf_mode",
+        "psf_window_size",
+        "integrate_mode",
+        "integrate_window_size",
+        "integrate_factor",
+        "integrate_recursion_factor",
+        "integrate_recursion_depth",
+        "integrate_threshold",
+        "jacobian_chunksize",
+    ]
     useable = False
 
     def __init__(self, name, *args, **kwargs):
         super().__init__(name, *args, **kwargs)
 
         self.psf = None
-        
+
         # Set any user defined attributes for the model
         for kwarg in kwargs:  # fixme move to core model?
             # Skip parameters with special behaviour
             if kwarg in self.special_kwargs:
                 continue
             # Set the model parameter
             setattr(self, kwarg, kwargs[kwarg])
 
+        # If loading from a file, get model configuration then exit __init__
+        if "filename" in kwargs:
+            self.load(kwargs["filename"])
+            return
+
         self.parameter_specs = self.build_parameter_specs(
             kwargs.get("parameters", None)
         )
         with torch.no_grad():
             self.build_parameters()
             if isinstance(kwargs.get("parameters", None), torch.Tensor):
-                self.set_parameters(kwargs["parameters"])
-
-        if "filename" in kwargs:
-            self.load(kwargs["filename"])
-
-    @property
-    def parameters(self):
-        try:
-            return self._parameters
-        except AttributeError:
-            return {}
-
-    @parameters.setter
-    def parameters(self, val):
-        self._parameters = val
+                self.parameters.set_values(kwargs["parameters"])
 
     @property
     def psf(self):
         if self._psf is None:
             return self.target.psf
         return self._psf
 
@@ -128,62 +135,55 @@
         if val is None:
             self._psf = None
         elif isinstance(val, PSF_Image):
             self._psf = val
         else:
             self._psf = PSF_Image(
                 val,
-                pixelscale = self.target.pixelscale,
-                band = self.target.band,
+                pixelscale=self.target.pixelscale,
+                band=self.target.band,
             )
 
-    def parameter_order(self, parameters_identity: Optional[tuple] = None):
-        """Returns a tuple of names of the parameters in their set order."""
-        param_order = tuple()
-        for P in self.__class__._parameter_order:
-            if self[P].locked:
-                continue
-            if parameters_identity is not None and not any(
-                pid in parameters_identity for pid in self[P].identities
-            ):
-                continue
-            param_order = param_order + (P,)
-        return param_order
-
     # Initialization functions
     ######################################################################
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target: Optional["Target_Image"] = None):
+    @default_internal
+    def initialize(
+        self,
+        target: Optional["Target_Image"] = None,
+        parameters: Optional[Parameter_Group] = None,
+        **kwargs,
+    ):
         """Determine initial values for the center coordinates. This is done
         with a local center of mass search which iterates by finding
         the center of light in a window, then iteratively updates
         until the iterations move by less than a pixel.
 
         Args:
           target (Optional[Target_Image]): A target image object to use as a reference when setting parameter values
 
         """
-        super().initialize(target)
+        super().initialize(target=target, parameters=parameters)
         # Get the sub-image area corresponding to the model image
         target_area = target[self.window]
 
         # Use center of window if a center hasn't been set yet
-        if self["center"].value is None:
-            self["center"].set_value(self.window.center, override_locked=True)
+        if parameters["center"].value is None:
+            parameters["center"].set_value(self.window.center, override_locked=True)
         else:
             return
 
-        if self["center"].locked:
+        if parameters["center"].locked:
             return
 
         # Convert center coordinates to target area array indices
         init_icenter = coord_to_index(
-            self["center"].value[0], self["center"].value[1], target_area
+            parameters["center"].value[0], parameters["center"].value[1], target_area
         )
         # Compute center of mass in window
         COM = center_of_mass(
             (
                 init_icenter[0].detach().cpu().item(),
                 init_icenter[1].detach().cpu().item(),
             ),
@@ -193,184 +193,217 @@
             np.array(COM) >= np.array(target_area.data.shape)
         ):
             AP_config.ap_logger.warning("center of mass failed, using center of window")
             return
         # Convert center of mass indices to coordinates
         COM_center = index_to_coord(COM[0], COM[1], target_area)
         # Set the new coordinates as the model center
-        self["center"].value = COM_center
+        parameters["center"].value = COM_center
 
     # Fit loop functions
     ######################################################################
-    def evaluate_model(self, image: Union["Image", "Image_Header"], X: Optional[torch.Tensor] = None, Y: Optional[torch.Tensor] = None, **kwargs):
+    def evaluate_model(
+        self,
+        X: Optional[torch.Tensor] = None,
+        Y: Optional[torch.Tensor] = None,
+        image: Optional["Image"] = None,
+        parameters: "Parameter_Group" = None,
+        **kwargs,
+    ):
         """Evaluate the model on every pixel in the given image. The
         basemodel object simply returns zeros, this function should be
         overloaded by subclasses.
 
         Args:
           image (Image): The image defining the set of pixels on which to evaluate the model
 
         """
         if X is None or Y is None:
             X, Y = image.get_coordinate_meshgrid_torch(
-                self["center"].value[0], self["center"].value[1]
+                parameters["center"].value[0], parameters["center"].value[1]
             )
         return torch.zeros_like(X)  # do nothing in base model
 
     def sample(
         self,
         image: Optional["Image"] = None,
         window: Optional[Window] = None,
+        parameters: Optional[Parameter_Group] = None,
     ):
         """Evaluate the model on the space covered by an image object. This
         function properly calls integration methods and PSF
         convolution. This should not be overloaded except in special
         cases.
 
         This function is designed to compute the model on a given
         image or within a specified window. It takes care of sub-pixel
         sampling, recursive integration for high curvature regions,
         PSF convolution, and proper alignment of the computed model
         with the original pixel grid. The final model is then added to
         the requested image.
 
         Args:
-          image (Optional[Image]): An AutoProf Image object (likely a Model_Image) 
-                                     on which to evaluate the model values. If not 
+          image (Optional[Image]): An AutoProf Image object (likely a Model_Image)
+                                     on which to evaluate the model values. If not
                                      provided, a new Model_Image object will be created.
-          window (Optional[Window]): A window within which to evaluate the model. 
-                                   Should only be used if a subset of the full image 
-                                   is needed. If not provided, the entire image will 
+          window (Optional[Window]): A window within which to evaluate the model.
+                                   Should only be used if a subset of the full image
+                                   is needed. If not provided, the entire image will
                                    be used.
 
         Returns:
           Image: The image with the computed model values.
 
         """
+
         # Image on which to evaluate model
         if image is None:
             image = self.make_model_image(window=window)
 
         # Window within which to evaluate model
         if window is None:
             working_window = image.window.copy()
         else:
-            working_window = window.copy() & image.window
+            working_window = window.copy()
+
+        # Parameters with which to evaluate the model
+        if parameters is None:
+            parameters = self.parameters
 
         if "window" in self.psf_mode:
             raise NotImplementedError("PSF convolution in sub-window not available yet")
 
         if "full" in self.psf_mode:
             # Add border for psf convolution edge effects, will be cropped out later
             working_window += self.psf.psf_border
             # Determine the pixels scale at which to evalaute, this is smaller if the PSF is upscaled
             working_pixelscale = image.pixelscale / self.psf.psf_upscale
             # Sub pixel shift to align the model with the center of a pixel
             align = self.target.pixel_center_alignment()
             center_shift = (
-                self["center"].value
+                parameters["center"].value
                 - (
-                    torch.round(self["center"].value / working_pixelscale - align)
+                    torch.round(parameters["center"].value / working_pixelscale - align)
                     + align
                 )
                 * working_pixelscale
             ).detach()
             working_window.shift_origin(center_shift)
             # Make the image object to which the samples will be tracked
             working_image = Model_Image(
                 pixelscale=working_pixelscale, window=working_window
             )
             # Evaluate the model at the current resolution
-            working_image.data += self.evaluate_model(image = working_image)
+            working_image.data += self.evaluate_model(
+                image=working_image, parameters=parameters
+            )
             # If needed, super-resolve the image in areas of high curvature so pixels are properly sampled
             if self.integrate_mode == "none":
                 pass
             elif self.integrate_mode == "threshold":
-                X, Y = working_image.get_coordinate_meshgrid_torch(self["center"].value[0], self["center"].value[1])
+                X, Y = working_image.get_coordinate_meshgrid_torch(
+                    parameters["center"].value[0], parameters["center"].value[1]
+                )
                 selective_integrate(
-                    X = X,
-                    Y = Y,
-                    data = working_image.data,
-                    image_header = working_image.header,
-                    eval_brightness = self.evaluate_model,
-                    max_depth = self.integrate_recursion_depth,
-                    integrate_threshold = self.integrate_threshold,
+                    X=X,
+                    Y=Y,
+                    data=working_image.data,
+                    image_header=working_image.header,
+                    eval_brightness=self.evaluate_model,
+                    eval_parameters=parameters,
+                    max_depth=self.integrate_recursion_depth,
+                    integrate_threshold=self.integrate_threshold,
                 )
-            elif self.integrate_mode == "window":                
+            elif self.integrate_mode == "window":
                 self.window_integrate(
                     working_image,
+                    parameters,
                     self.integrate_window(working_image, "center"),
                     self.integrate_recursion_depth,
                 )
             else:
-                raise ValueError(f"{self.name} has unknown integration mode: {self.integrate_mode}")
+                raise ValueError(
+                    f"{self.name} has unknown integration mode: {self.integrate_mode}"
+                )
             # Convolve the PSF
             LL = _shift_Lanczos_kernel_torch(
                 -center_shift[0] / working_image.pixelscale,
                 -center_shift[1] / working_image.pixelscale,
                 3,
                 AP_config.ap_dtype,
                 AP_config.ap_device,
             )
             shift_psf = torch.nn.functional.conv2d(
                 self.psf.data.view(1, 1, *self.psf.data.shape),
                 LL.view(1, 1, *LL.shape),
                 padding="same",
-            )[0][0]
+            ).squeeze()
             working_image.data = fft_convolve_torch(
                 working_image.data, shift_psf / torch.sum(shift_psf), img_prepadded=True
             )
             # Shift image back to align with original pixel grid
             working_image.window.shift_origin(-center_shift)
             # Add the sampled/integrated/convolved pixels to the requested image
             working_image = working_image.reduce(self.psf.psf_upscale).crop(
                 self.psf.psf_border_int
             )
             if self.mask is not None:
                 working_image.data = working_image.data * torch.logical_not(self.mask)
             image += working_image
-            
+
         else:
             # Create an image to store pixel samples
             working_image = Model_Image(
                 pixelscale=image.pixelscale, window=working_window
             )
             # Evaluate the model on the image
-            working_image.data += self.evaluate_model(image = working_image)
+            working_image.data += self.evaluate_model(
+                image=working_image, parameters=parameters
+            )
             # Super-resolve and integrate where needed
             if self.integrate_mode == "none":
                 pass
             elif self.integrate_mode == "threshold":
-                X, Y = working_image.get_coordinate_meshgrid_torch(self["center"].value[0], self["center"].value[1])
+                X, Y = working_image.get_coordinate_meshgrid_torch(
+                    parameters["center"].value[0], parameters["center"].value[1]
+                )
                 selective_integrate(
-                    X = X,
-                    Y = Y,
-                    data = working_image.data,
-                    image_header = working_image.header,
-                    eval_brightness = self.evaluate_model,
-                    max_depth = self.integrate_recursion_depth,
-                    integrate_threshold = self.integrate_threshold,
+                    X=X,
+                    Y=Y,
+                    data=working_image.data,
+                    image_header=working_image.header,
+                    eval_brightness=self.evaluate_model,
+                    eval_parameters=parameters,
+                    max_depth=self.integrate_recursion_depth,
+                    integrate_threshold=self.integrate_threshold,
                 )
             elif self.integrate_mode == "window":
                 self.window_integrate(
                     working_image,
+                    parameters,
                     self.integrate_window(working_image, "pixel"),
                     self.integrate_recursion_depth,
                 )
             else:
-                raise ValueError(f"{self.name} has unknown integration mode: {self.integrate_mode}")
+                raise ValueError(
+                    f"{self.name} has unknown integration mode: {self.integrate_mode}"
+                )
             # Add the sampled/integrated pixels to the requested image
             if self.mask is not None:
                 working_image.data = working_image.data * torch.logical_not(self.mask)
             image += working_image
 
         return image
 
     def window_integrate(
-        self, working_image: "Image", window: Window, depth: int = 2
+        self,
+        working_image: "Image",
+        parameters: Parameter_Group,
+        window: Window,
+        depth: int = 2,
     ):
         """Sample the model at a higher resolution than the given image, then
         integrate the super resolution up to the image resolution.
 
         This method improves the accuracy of the model evaluation by
         evaluating it at a finer resolution and integrating the
         results back to the original resolution. It recursively
@@ -405,15 +438,15 @@
         # Determine the upsampled pixelscale
         integrate_pixelscale = working_image.pixelscale / self.integrate_factor
         # Build an image to hold the integration data
         integrate_image = Model_Image(
             pixelscale=integrate_pixelscale, window=working_window
         )
         # Evaluate the model at the fine sampling points
-        integrate_image.data = self.evaluate_model(integrate_image)
+        integrate_image.data = self.evaluate_model(integrate_image, parameters)
 
         # If needed, recursively evaluates smaller windows
         recursive_shape = (
             window.shape / integrate_pixelscale
         )  # get the number of pixels across the integrate window
         recursive_shape = torch.round(
             recursive_shape / self.integrate_recursion_factor
@@ -431,14 +464,15 @@
             + 1
             - (recursive_shape % 2)
             + 1
             - window_align.to(dtype=torch.int32)
         ) * integrate_pixelscale  # ensure shape pairity is matched during recursion
         self.window_integrate(
             integrate_image,
+            parameters,
             Window(
                 center=window.center,
                 shape=recursive_shape,
             ),
             depth=depth - 1,
         )
         # Replace the image data where the integration has been done
@@ -478,71 +512,78 @@
           Jacobian_Image: A Jacobian_Image object containing the computed Jacobian matrix.
 
         """
         if window is None:
             window = self.window
         else:
             window = self.window & window
-            
+
         # skip jacobian calculation if no parameters match criteria
-        porder = self.parameter_order(parameters_identity=parameters_identity)
+        porder = self.parameters.order(parameters_identity=parameters_identity)
         if len(porder) == 0 or window.overlap_frac(self.window) <= 0:
             return self.target[window].jacobian_image()
 
         # Set the parameters if provided and check the size of the parameter list
         dochunk = False
         if parameters is not None:
             if len(parameters) > self.jacobian_chunksize:
                 dochunk = True
-            self.set_parameters(
+            self.parameters.set_values(
                 parameters,
                 as_representation=as_representation,
                 parameters_identity=parameters_identity,
             )
         else:
-            if len(self.get_parameter_identity_vector(parameters_identity=parameters_identity)) > self.jacobian_chunksize:
+            if (
+                len(
+                    self.parameters.get_identity_vector(
+                        parameters_identity=parameters_identity
+                    )
+                )
+                > self.jacobian_chunksize
+            ):
                 dochunk = True
 
         # If the parameter list is too large, apply the chunk jacobian analysis
         if dochunk:
             return self._chunk_jacobian(
-                as_representation = as_representation,
-                parameters_identity = parameters_identity,
-                window = window,
+                as_representation=as_representation,
+                parameters_identity=parameters_identity,
+                window=window,
                 **kwargs,
-            )            
+            )
 
         # Store the parameter identities
         if parameters_identity is None:
             pids = None
         else:
-            pids = self.get_parameter_identity_vector(
+            pids = self.parameters.get_identity_vector(
                 parameters_identity=parameters_identity,
             )
         # Compute the jacobian
         full_jac = jacobian(
             lambda P: self(
                 image=None,
                 parameters=P,
                 as_representation=as_representation,
                 parameters_identity=pids,
                 window=window,
             ).data,
-            self.get_parameter_vector(
+            self.parameters.get_vector(
                 as_representation=as_representation,
                 parameters_identity=parameters_identity,
             ).detach(),
             strategy="forward-mode",
             vectorize=True,
             create_graph=False,
         )
 
         # Store the jacobian as a Jacobian_Image object
         jac_img = self.target[window].jacobian_image(
-            parameters=self.get_parameter_identity_vector(
+            parameters=self.parameters.get_identity_vector(
                 parameters_identity=parameters_identity,
             ),
             data=full_jac,
         )
         return jac_img
 
     @torch.no_grad()
@@ -561,50 +602,53 @@
         `self.jacobian_chunksize` evaluates the Jacobian only for
         those, it then builds up the full Jacobian as a separate
         tensor. This is for internal use and should be called by the
         `self.jacobian` function when appropriate.
 
         """
 
-        pids = self.get_parameter_identity_vector(
+        pids = self.parameters.get_identity_vector(
             parameters_identity=parameters_identity,
         )
         jac_img = self.target[window].jacobian_image(
             parameters=pids,
         )
-        
-        for ichunk in range(0,len(pids),self.jacobian_chunksize):
+
+        for ichunk in range(0, len(pids), self.jacobian_chunksize):
             jac_img += self.jacobian(
-                parameters = None,
-                as_representation = as_representation,
-                parameters_identity = pids[ichunk:ichunk + self.jacobian_chunksize],
-                window = window,
+                parameters=None,
+                as_representation=as_representation,
+                parameters_identity=pids[ichunk : ichunk + self.jacobian_chunksize],
+                window=window,
                 **kwargs,
             )
-            
+
         return jac_img
-        
 
     def get_state(self):
         """Returns a dictionary with a record of the current state of the
         model.
 
         Specifically, the current parameter settings and the
         window for this model. From this information it is possible
         for the model to re-build itself lated when loading from
         disk. Note that the target image is not saved, this must be
         reset when loading the model.
 
         """
         state = super().get_state()
         state["window"] = self.window.get_state()
+        state["parameter_order"] = list(self.parameter_order)
         if "parameters" not in state:
             state["parameters"] = {}
         for P in self.parameters:
-            state["parameters"][P] = self[P].get_state()
+            state["parameters"][P.name] = P.get_state()
+        for key in self.track_attrs:
+            if getattr(self, key) != getattr(self.__class__, key):
+                state[key] = getattr(self, key)
         return state
 
     def load(self, filename: Union[str, dict, io.TextIOBase] = "AutoProf.yaml"):
         """Used to load the model from a saved state.
 
         Sets the model window to the saved value and updates all
         parameters with the saved information. This overrides the
@@ -613,20 +657,21 @@
         Args:
           filename: The source from which to load the model parameters. Can be a string (the name of the file on disc), a dictionary (formatted as if from self.get_state), or an io.TextIOBase (a file stream to load the file from).
 
         """
         state = AutoProf_Model.load(filename)
         self.name = state["name"]
         self.window = Window(**state["window"])
-        for key in state["parameters"]:
-            self[key].update_state(state["parameters"][key])
-            self[key].to(dtype=AP_config.ap_dtype, device=AP_config.ap_device)
+        for key in self.track_attrs:
+            if key in state:
+                setattr(self, key, state[key])
+        self.parameters = Parameter_Group(self.name)
+        for P in state["parameter_order"]:
+            self.parameters.add_parameter(Parameter(**state["parameters"][P]))
+        self.parameters.to(dtype=AP_config.ap_dtype, device=AP_config.ap_device)
         return state
 
     # Extra background methods for the basemodel
     ######################################################################
     from ._model_methods import integrate_window
     from ._model_methods import build_parameter_specs
     from ._model_methods import build_parameters
-    from ._model_methods import __getitem__
-    from ._model_methods import __contains__
-    from ._model_methods import __str__
```

## autoprof/models/moffat_model.py

```diff
@@ -1,14 +1,14 @@
 import torch
 import numpy as np
 
 from .galaxy_model_object import Galaxy_Model
 from .star_model_object import Star_Model
 from ._shared_methods import parametric_initialize, select_target
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.parametric_profiles import moffat_np
 
 __all__ = ["Moffat_Galaxy", "Moffat_Star"]
 
 
 def _x0_func(model_params, R, F):
     return 2.0, R[4], F[0]
@@ -44,18 +44,21 @@
     }
     _parameter_order = Galaxy_Model._parameter_order + ("n", "Rd", "I0")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_moffat, ("n", "Rd", "I0"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_moffat, ("n", "Rd", "I0"), _x0_func
+        )
 
     from ._shared_methods import moffat_radial_model as radial_model
 
 
 class Moffat_Star(Star_Model):
     """basic star model with a Moffat profile for the radial light
     profile. The functional form of the Moffat profile is defined as:
@@ -82,19 +85,27 @@
     }
     _parameter_order = Star_Model._parameter_order + ("n", "Rd", "I0")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_moffat, ("n", "Rd", "I0"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_moffat, ("n", "Rd", "I0"), _x0_func
+        )
 
     from ._shared_methods import moffat_radial_model as radial_model
 
-    def evaluate_model(self, image):
-        X, Y = image.get_coordinate_meshgrid_torch(
-            self["center"].value[0], self["center"].value[1]
+    def evaluate_model(self, X=None, Y=None, image=None, parameters=None):
+        if X is None:
+            X, Y = image.get_coordinate_meshgrid_torch(
+                parameters["center"].value[0], parameters["center"].value[1]
+            )
+        return self.radial_model(
+            self.radius_metric(X, Y, image=image, parameters=parameters),
+            image=image,
+            parameters=parameters,
         )
-        return self.radial_model(self.radius_metric(X, Y), image)
```

## autoprof/models/nuker_model.py

```diff
@@ -9,15 +9,15 @@
 from .superellipse_model import SuperEllipse_Galaxy, SuperEllipse_Warp
 from .foureirellipse_model import FourierEllipse_Galaxy, FourierEllipse_Warp
 from ._shared_methods import (
     parametric_initialize,
     parametric_segment_initialize,
     select_target,
 )
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.parametric_profiles import nuker_np
 
 __all__ = [
     "Nuker_Galaxy",
     "Nuker_Star",
     "Nuker_SuperEllipse",
     "Nuker_SuperEllipse_Warp",
@@ -73,25 +73,29 @@
         "gamma",
     )
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_initialize(
-            self, target, _wrap_nuker, ("Rb", "Ib", "alpha", "beta", "gamma"), _x0_func
+            self,
+            parameters,
+            target,
+            _wrap_nuker,
+            ("Rb", "Ib", "alpha", "beta", "gamma"),
+            _x0_func,
         )
 
     from ._shared_methods import nuker_radial_model as radial_model
 
-    # from ._shared_methods import nuker_initialize as initialize
-
 
 class Nuker_Star(Star_Model):
     """basic star model with a Nuker profile for the radial light
     profile. The functional form of the Nuker profile is defined as:
 
     I(R) = Ib * 2^((beta-gamma)/alpha) * (R / Rb)^(-gamma) * (1 + (R/Rb)^alpha)^((gamma - beta)/alpha)
 
@@ -126,28 +130,40 @@
         "gamma",
     )
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_initialize(
-            self, target, _wrap_nuker, ("Rb", "Ib", "alpha", "beta", "gamma"), _x0_func
+            self,
+            parameters,
+            target,
+            _wrap_nuker,
+            ("Rb", "Ib", "alpha", "beta", "gamma"),
+            _x0_func,
         )
 
     from ._shared_methods import nuker_radial_model as radial_model
 
-    def evaluate_model(self, image):
-        X, Y = image.get_coordinate_meshgrid_torch(
-            self["center"].value[0], self["center"].value[1]
+    @default_internal
+    def evaluate_model(self, X=None, Y=None, image=None, parameters=None):
+        if X is None:
+            X, Y = image.get_coordinate_meshgrid_torch(
+                parameters["center"].value[0], parameters["center"].value[1]
+            )
+        return self.radial_model(
+            self.radius_metric(X, Y, image=image, parameters=parameters),
+            image=image,
+            parameters=parameters,
         )
-        return self.radial_model(self.radius_metric(X, Y), image)
 
 
 class Nuker_SuperEllipse(SuperEllipse_Galaxy):
     """super ellipse galaxy model with a Nuker profile for the radial
     light profile. The functional form of the Nuker profile is defined as:
 
     I(R) = Ib * 2^((beta-gamma)/alpha) * (R / Rb)^(-gamma) * (1 + (R/Rb)^alpha)^((gamma - beta)/alpha)
@@ -183,19 +199,25 @@
         "gamma",
     )
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_initialize(
-            self, target, _wrap_nuker, ("Rb", "Ib", "alpha", "beta", "gamma"), _x0_func
+            self,
+            parameters,
+            target,
+            _wrap_nuker,
+            ("Rb", "Ib", "alpha", "beta", "gamma"),
+            _x0_func,
         )
 
     from ._shared_methods import nuker_radial_model as radial_model
 
 
 class Nuker_SuperEllipse_Warp(SuperEllipse_Warp):
     """super ellipse warp galaxy model with a Nuker profile for the
@@ -236,19 +258,25 @@
         "gamma",
     )
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_initialize(
-            self, target, _wrap_nuker, ("Rb", "Ib", "alpha", "beta", "gamma"), _x0_func
+            self,
+            parameters,
+            target,
+            _wrap_nuker,
+            ("Rb", "Ib", "alpha", "beta", "gamma"),
+            _x0_func,
         )
 
     from ._shared_methods import nuker_radial_model as radial_model
 
 
 class Nuker_FourierEllipse(FourierEllipse_Galaxy):
     """fourier mode perturbations to ellipse galaxy model with a Nuker
@@ -288,19 +316,25 @@
         "gamma",
     )
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_initialize(
-            self, target, _wrap_nuker, ("Rb", "Ib", "alpha", "beta", "gamma"), _x0_func
+            self,
+            parameters,
+            target,
+            _wrap_nuker,
+            ("Rb", "Ib", "alpha", "beta", "gamma"),
+            _x0_func,
         )
 
     from ._shared_methods import nuker_radial_model as radial_model
 
 
 class Nuker_FourierEllipse_Warp(FourierEllipse_Warp):
     """fourier mode perturbations to ellipse galaxy model with a Nuker
@@ -340,19 +374,25 @@
         "gamma",
     )
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_initialize(
-            self, target, _wrap_nuker, ("Rb", "Ib", "alpha", "beta", "gamma"), _x0_func
+            self,
+            parameters,
+            target,
+            _wrap_nuker,
+            ("Rb", "Ib", "alpha", "beta", "gamma"),
+            _x0_func,
         )
 
     from ._shared_methods import nuker_radial_model as radial_model
 
 
 class Nuker_Warp(Warp_Galaxy):
     """warped coordinate galaxy model with a Nuker profile for the radial
@@ -392,19 +432,25 @@
         "gamma",
     )
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_initialize(
-            self, target, _wrap_nuker, ("Rb", "Ib", "alpha", "beta", "gamma"), _x0_func
+            self,
+            parameters,
+            target,
+            _wrap_nuker,
+            ("Rb", "Ib", "alpha", "beta", "gamma"),
+            _x0_func,
         )
 
     from ._shared_methods import nuker_radial_model as radial_model
 
 
 class Nuker_Ray(Ray_Galaxy):
     """ray galaxy model with a nuker profile for the radial light
@@ -443,24 +489,26 @@
         "gamma",
     )
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_segment_initialize(
-            self,
-            target,
-            _wrap_nuker,
-            ("Rb", "Ib", "alpha", "beta", "gamma"),
-            _x0_func,
-            self.rays,
+            model=self,
+            parameters=parameters,
+            target=target,
+            prof_func=_wrap_nuker,
+            params=("Rb", "Ib", "alpha", "beta", "gamma"),
+            x0_func=_x0_func,
+            segments=self.rays,
         )
 
     from ._shared_methods import nuker_iradial_model as iradial_model
 
 
 class Nuker_Wedge(Wedge_Galaxy):
     """wedge galaxy model with a nuker profile for the radial light
@@ -499,20 +547,22 @@
         "gamma",
     )
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_segment_initialize(
-            self,
-            target,
-            _wrap_nuker,
-            ("Rb", "Ib", "alpha", "beta", "gamma"),
-            _x0_func,
-            self.wedges,
+            model=self,
+            parameters=parameters,
+            target=target,
+            prof_func=_wrap_nuker,
+            params=("Rb", "Ib", "alpha", "beta", "gamma"),
+            x0_func=_x0_func,
+            segments=self.wedges,
         )
 
     from ._shared_methods import nuker_iradial_model as iradial_model
```

## autoprof/models/parameter_object.py

```diff
@@ -1,11 +1,11 @@
 from typing import Optional
+from copy import deepcopy
 
 import torch
-import numpy as np
 
 from ..utils.conversions.optimization import (
     boundaries,
     inv_boundaries,
     d_boundaries_dval,
     d_inv_boundaries_dval,
     cyclic_boundaries,
@@ -39,32 +39,64 @@
         uncertainty: 1 sigma uncertainty on the value of the parameter [float]
         limits: tuple of values specifying the valid range for this parameter, use None to mean no limit [tuple: (float, float), (float, None), (None, float), None]
         cyclic: boolean indicating if the parameter is cyclically defined. Note that cyclic parameters must specify limits [bool]
         locked: boolean indicating if the parameter should have a fixed value [bool]
         units: units for the value of the parameter. [str]
     """
 
+    identity_list = []
+
     def __init__(self, name, value=None, **kwargs):
         self.name = name
-        self.identity = str(id(self))
+        if "identity" in kwargs:
+            self._identity = kwargs["identity"]
+        else:
+            self.identity = str(id(self))
         self._prof = None
         self._representation = None
         self.limits = kwargs.get("limits", None)
         self.cyclic = kwargs.get("cyclic", False)
         self.locked = kwargs.get("locked", False)
         self._representation = None
         self.set_value(value, override_locked=True)
-        self.requires_grad = kwargs.get("requires_grad", False)
         self.units = kwargs.get("units", "none")
         self._uncertainty = None
         self.uncertainty = kwargs.get("uncertainty", None)
         self.set_profile(kwargs.get("prof", None))
+        self.groups = kwargs.get("groups", set())
         self.to()
 
     @property
+    def identity(self):
+        return self._identity
+
+    @identity.setter
+    def identity(self, val):
+        if val in Parameter.identity_list:
+            c = 1
+            while f"{val}c{c}" in Parameter.identity_list:
+                c += 1
+            val = f"{val}c{c}"
+        self._identity = val
+        Parameter.identity_list.append(val)
+
+    def copy(self):
+        return Parameter(
+            name=self.name,
+            value=self.value.clone(),
+            limits=self.limits,
+            cyclic=self.cyclic,
+            locked=self.locked,
+            units=self.units,
+            uncertainty=self.uncertainty,
+            prof=self.prof,
+            groups=self.groups,
+        )
+
+    @property
     def representation(self):
         """The representation is the stored number (or tensor of numbers) for
         this parameter, it is what the optimizer sees and is defined
         in the range (-inf,+inf). This makes it well behaved during
         optimization. This is stored as a pytorch tensor which can
         track gradients.
 
@@ -171,32 +203,18 @@
         Calls the uncertainty setting method, preserving locked behaviour.
         """
         self.set_uncertainty(unc, as_representation=True)
 
     @property
     def prof(self):
         return self._prof
+
     @prof.setter
     def prof(self, val):
         self.set_profile(val)
-        
-    @property
-    def requires_grad(self):
-        if self._representation is None:
-            return False
-        return self._representation.requires_grad
-
-    @requires_grad.setter
-    def requires_grad(self, val):
-        assert isinstance(val, bool)
-        if self._representation is not None and not (
-            self._representation.requires_grad is val
-        ):
-            self._representation = self._representation.detach()
-            self._representation.requires_grad = val
 
     @property
     def grad(self):
         """Returns the gradient for the representation of this parameter, if
         available.
 
         """
@@ -245,21 +263,21 @@
 
     def rep_to_val(self, rep):
         if self.cyclic:
             return cyclic_boundaries(rep, self.limits)
         if self.limits is None:
             return rep
         return inv_boundaries(rep, self.limits)
-    
+
     def val_to_rep(self, val):
         if self.cyclic:
             return cyclic_boundaries(val, self.limits)
         if self.limits is None:
             return val
-        return boundaries(val, self.limits)    
+        return boundaries(val, self.limits)
 
     def get_uncertainty(self, index=None, identity=None):
         if self._uncertainty is None:
             return None
 
         # Ensure the shape of uncertinty matches the value
         if (
@@ -411,14 +429,15 @@
     def get_state(self):
         """Return the values representing the current state of the parameter,
         this can be used to re-load the state later from memory.
 
         """
         state = {
             "name": self.name,
+            "identity": self.identity,
         }
         if self.value is not None:
             state["value"] = self.value.detach().cpu().numpy().tolist()
         if self.units is not None:
             state["units"] = self.units
         if self.uncertainty is not None:
             state["uncertainty"] = self.uncertainty.detach().cpu().numpy().tolist()
@@ -447,20 +466,21 @@
         if prof is None:
             self._prof = None
             return
         self._prof = torch.as_tensor(
             prof, dtype=AP_config.ap_dtype, device=AP_config.ap_device
         )
 
-    def update_state(self, state):
+    def set_state(self, state):
         """Update the state of the parameter given a state variable whcih
         holds all information about a variable.
 
         """
         self.name = state["name"]
+        self._identity = state["identity"]
         self.units = state.get("units", None)
         self.limits = state.get("limits", None)
         self.cyclic = state.get("cyclic", False)
         self.uncertainty = state.get("uncertainty", None)
         self.value = state.get("value", None)
         self.locked = state.get("locked", False)
         self.prof = state.get("prof", None)
```

## autoprof/models/planesky_model.py

```diff
@@ -1,14 +1,14 @@
 import numpy as np
 from scipy.stats import iqr
 import torch
 
 from .sky_model_object import Sky_Model
 from ._shared_methods import select_target
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 
 __all__ = ["Plane_Sky"]
 
 
 class Plane_Sky(Sky_Model):
     """Sky background model using a tilted plane for the sky flux. The brightness for each pixel is defined as:
 
@@ -31,38 +31,40 @@
     }
     _parameter_order = Sky_Model._parameter_order + ("sky", "delta")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        if self["sky"].value is None:
-            self["sky"].set_value(
+        if parameters["sky"].value is None:
+            parameters["sky"].set_value(
                 np.median(target[self.window].data) / target.pixelscale ** 2,
                 override_locked=True,
             )
-        if self["sky"].uncertainty is None:
-            self["sky"].set_uncertainty(
+        if parameters["sky"].uncertainty is None:
+            parameters["sky"].set_uncertainty(
                 (
                     iqr(target[self.window].data, rng=(31.731 / 2, 100 - 31.731 / 2))
                     / (2.0 * target.pixelscale ** 2)
                 )
                 / np.sqrt(np.prod(self.window.shape.detach().cpu().numpy())),
                 override_locked=True,
             )
-        if self["delta"].value is None:
-            self["delta"].set_value([0.0, 0.0], override_locked=True)
-            self["delta"].set_uncertainty([0.1, 0.1], override_locked=True)
-
-    def evaluate_model(self, image, X = None, Y = None, **kwargs):
-        if X is None or Y is None:
+        if parameters["delta"].value is None:
+            parameters["delta"].set_value([0.0, 0.0], override_locked=True)
+            parameters["delta"].set_uncertainty([0.1, 0.1], override_locked=True)
+
+    @default_internal
+    def evaluate_model(self, X=None, Y=None, image=None, parameters=None, **kwargs):
+        if X is None:
             X, Y = image.get_coordinate_meshgrid_torch(
-                self["center"].value[0], self["center"].value[1]
+                parameters["center"].value[0], parameters["center"].value[1]
             )
         return (
-            (self["sky"].value * image.pixelscale ** 2)
-            + X * self["delta"].value[0]
-            + Y * self["delta"].value[1]
+            (parameters["sky"].value * image.pixelscale ** 2)
+            + X * parameters["delta"].value[0]
+            + Y * parameters["delta"].value[1]
         )
```

## autoprof/models/psf_model.py

```diff
@@ -1,12 +1,12 @@
 import torch
 
 from .star_model_object import Star_Model
 from ..image import Model_Image
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.interpolate import _shift_Lanczos_kernel_torch
 from ._shared_methods import select_target
 from .. import AP_config
 
 __all__ = ["PSF_Star"]
 
 
@@ -39,37 +39,40 @@
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         # fixme, model already has PSF interface, those can just be merged
         if "psf" in kwargs:
             self.psf_model = kwargs["psf"]
         else:
             self.psf_model = Model_Image(
-                data=torch.clone(self.psf.data), pixelscale=self.psf.pixelscale,
+                data=torch.clone(self.psf.data),
+                pixelscale=self.psf.pixelscale,
             )
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
         target_area = target[self.window]
-        if self["flux"].value is None:
-            self["flux"].set_value(
+        if parameters["flux"].value is None:
+            parameters["flux"].set_value(
                 torch.log10(
                     torch.abs(torch.sum(target_area.data)) / target_area.pixelscale ** 2
                 ),
                 override_locked=True,
             )
-        if self["flux"].uncertainty is None:
-            self["flux"].set_uncertainty(
-                torch.abs(self["flux"].value) * 1e-2, override_locked=True
+        if parameters["flux"].uncertainty is None:
+            parameters["flux"].set_uncertainty(
+                torch.abs(parameters["flux"].value) * 1e-2, override_locked=True
             )
 
-    def evaluate_model(self, image, X = None, Y = None, **kwargs):
-        new_origin = self["center"].value - self.psf_model.shape / 2
+    @default_internal
+    def evaluate_model(self, X=None, Y=None, image=None, parameters=None, **kwargs):
+        new_origin = parameters["center"].value - self.psf_model.shape / 2
         pixel_origin = torch.round(new_origin / image.pixelscale) * image.pixelscale
         pixel_shift = (
             new_origin / image.pixelscale - pixel_origin / image.pixelscale
         ) * image.pixelscale
         LL = _shift_Lanczos_kernel_torch(
             -pixel_shift[0] / image.pixelscale,
             -pixel_shift[1] / image.pixelscale,
@@ -77,15 +80,15 @@
             AP_config.ap_dtype,
             AP_config.ap_device,
         )
         psf = Model_Image(
             data=torch.nn.functional.conv2d(
                 (
                     torch.clone(self.psf_model.data)
-                    * ((10 ** self["flux"].value) * image.pixelscale ** 2)
+                    * ((10 ** parameters["flux"].value) * image.pixelscale ** 2)
                 ).view(1, 1, *self.psf_model.data.shape),
                 LL.view(1, 1, *LL.shape),
                 padding="same",
             )[0][0],
             origin=pixel_origin - pixel_shift,
             pixelscale=self.psf_model.pixelscale,
         )
```

## autoprof/models/ray_model.py

```diff
@@ -1,14 +1,14 @@
 import numpy as np
 import torch
 
 from .galaxy_model_object import Galaxy_Model
 from .parameter_object import Parameter
 from ..utils.interpolate import cubic_spline_torch
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.conversions.coordinates import Axis_Ratio_Cartesian
 
 __all__ = ["Ray_Galaxy"]
 
 
 class Ray_Galaxy(Galaxy_Model):
     """Variant of a galaxy model which defines multiple radial models
@@ -30,25 +30,29 @@
     when instantiating the ray model: "rays" which is an integer for
     the number of rays.
 
     """
 
     model_type = f"ray {Galaxy_Model.model_type}"
     special_kwargs = Galaxy_Model.special_kwargs + ["rays"]
+    rays = 2
+    track_attrs = Galaxy_Model.track_attrs + ["rays"]
     useable = False
 
     def __init__(self, *args, **kwargs):
         self.symmetric_rays = True
         super().__init__(*args, **kwargs)
-        self.rays = kwargs.get("rays", 2)
+        self.rays = kwargs.get("rays", Ray_Galaxy.rays)
 
-    def angular_metric(self, X, Y):
+    @default_internal
+    def angular_metric(self, X, Y, image=None, parameters=None):
         return torch.atan2(Y, X)
 
-    def polar_model(self, R, T, image):
+    @default_internal
+    def polar_model(self, R, T, image=None, parameters=None):
         model = torch.zeros_like(R)
         if self.rays % 2 == 0 and self.symmetric_rays:
             for r in range(self.rays):
                 angles = (T - (r * np.pi / self.rays)) % np.pi
                 indices = torch.logical_or(
                     angles < (np.pi / self.rays),
                     angles >= (np.pi * (1 - 1 / self.rays)),
@@ -87,20 +91,23 @@
                     angles < (2 * np.pi / self.rays),
                     angles >= (np.pi * (2 - 1 / self.rays)),
                 )
                 weight = (torch.cos(angles[indices] * self.rays) + 1) / 2
                 model[indices] += weight * self.iradial_model(r, R[indices], image)
         return model
 
-    def evaluate_model(self, image, X = None, Y = None, **kwargs):
-        if X is None or Y is None:
+    def evaluate_model(self, X=None, Y=None, image=None, parameters=None, **kwargs):
+        if X is None:
             X, Y = image.get_coordinate_meshgrid_torch(
-                self["center"].value[0], self["center"].value[1]
+                parameters["center"].value[0], parameters["center"].value[1]
             )
-        XX, YY = self.transform_coordinates(X, Y)
+        XX, YY = self.transform_coordinates(X, Y, image, parameters)
 
         return self.polar_model(
-            self.radius_metric(XX, YY), self.angular_metric(XX, YY), image
+            self.radius_metric(XX, YY, image=image, parameters=parameters),
+            self.angular_metric(XX, YY, image=image, parameters=parameters),
+            image=image,
+            parameters=parameters,
         )
 
 
 # class SingleRay_Galaxy(Galaxy_Model):
```

## autoprof/models/sersic_model.py

```diff
@@ -11,15 +11,15 @@
 from .superellipse_model import SuperEllipse_Galaxy, SuperEllipse_Warp
 from .foureirellipse_model import FourierEllipse_Galaxy, FourierEllipse_Warp
 from ._shared_methods import (
     parametric_initialize,
     parametric_segment_initialize,
     select_target,
 )
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ..utils.initialize import isophotes
 from ..utils.parametric_profiles import sersic_torch, sersic_np
 from ..utils.conversions.coordinates import (
     Rotate_Cartesian,
     coord_to_index,
     index_to_coord,
 )
@@ -72,18 +72,21 @@
     }
     _parameter_order = Galaxy_Model._parameter_order + ("n", "Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import sersic_radial_model as radial_model
 
 
 class Sersic_Star(Star_Model):
     """basic star model with a sersic profile for the radial light
     profile. The functional form of the Sersic profile is defined as:
@@ -111,26 +114,35 @@
     }
     _parameter_order = Star_Model._parameter_order + ("n", "Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import sersic_radial_model as radial_model
 
-    def evaluate_model(self, image):
-        X, Y = image.get_coordinate_meshgrid_torch(
-            self["center"].value[0], self["center"].value[1]
+    @default_internal
+    def evaluate_model(self, X=None, Y=None, image=None, parameters=None):
+        if X is None:
+            X, Y = image.get_coordinate_meshgrid_torch(
+                parameters["center"].value[0], parameters["center"].value[1]
+            )
+        return self.radial_model(
+            self.radius_metric(X, Y, image=image, parameters=parameters),
+            image=image,
+            parameters=parameters,
         )
-        return self.radial_model(self.radius_metric(X, Y), image)
 
 
 class Sersic_SuperEllipse(SuperEllipse_Galaxy):
     """super ellipse galaxy model with a sersic profile for the radial
     light profile. The functional form of the Sersic profile is defined as:
 
     I(R) = Ie * exp(- bn((R/Re)^(1/n) - 1))
@@ -156,18 +168,21 @@
     }
     _parameter_order = SuperEllipse_Galaxy._parameter_order + ("n", "Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import sersic_radial_model as radial_model
 
 
 class Sersic_SuperEllipse_Warp(SuperEllipse_Warp):
     """super ellipse warp galaxy model with a sersic profile for the
     radial light profile. The functional form of the Sersic profile is
@@ -196,18 +211,21 @@
     }
     _parameter_order = SuperEllipse_Warp._parameter_order + ("n", "Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import sersic_radial_model as radial_model
 
 
 class Sersic_FourierEllipse(FourierEllipse_Galaxy):
     """fourier mode perturbations to ellipse galaxy model with a sersic
     profile for the radial light profile. The functional form of the
@@ -236,18 +254,21 @@
     }
     _parameter_order = FourierEllipse_Galaxy._parameter_order + ("n", "Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import sersic_radial_model as radial_model
 
 
 class Sersic_FourierEllipse_Warp(FourierEllipse_Warp):
     """fourier mode perturbations to ellipse galaxy model with a sersic
     profile for the radial light profile. The functional form of the
@@ -276,18 +297,21 @@
     }
     _parameter_order = FourierEllipse_Warp._parameter_order + ("n", "Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import sersic_radial_model as radial_model
 
 
 class Sersic_Warp(Warp_Galaxy):
     """warped coordinate galaxy model with a sersic profile for the radial
     light model. The functional form of the Sersic profile is defined
@@ -316,18 +340,21 @@
     }
     _parameter_order = Warp_Galaxy._parameter_order + ("n", "Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
-        parametric_initialize(self, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func)
+        parametric_initialize(
+            self, parameters, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func
+        )
 
     from ._shared_methods import sersic_radial_model as radial_model
 
 
 class Sersic_Ray(Ray_Galaxy):
     """ray galaxy model with a sersic profile for the radial light
     model. The functional form of the Sersic profile is defined as:
@@ -355,19 +382,26 @@
     }
     _parameter_order = Ray_Galaxy._parameter_order + ("n", "Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_segment_initialize(
-            self, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func, self.rays
+            model=self,
+            target=target,
+            parameters=parameters,
+            prof_func=_wrap_sersic,
+            params=("n", "Re", "Ie"),
+            x0_func=_x0_func,
+            segments=self.rays,
         )
 
     from ._shared_methods import sersic_iradial_model as iradial_model
 
 
 class Sersic_Wedge(Wedge_Galaxy):
     """wedge galaxy model with a sersic profile for the radial light
@@ -396,15 +430,22 @@
     }
     _parameter_order = Wedge_Galaxy._parameter_order + ("n", "Re", "Ie")
     useable = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         parametric_segment_initialize(
-            self, target, _wrap_sersic, ("n", "Re", "Ie"), _x0_func, self.wedges
+            model=self,
+            parameters=parameters,
+            target=target,
+            prof_func=_wrap_sersic,
+            params=("n", "Re", "Ie"),
+            x0_func=_x0_func,
+            segments=self.wedges,
         )
 
     from ._shared_methods import sersic_iradial_model as iradial_model
```

## autoprof/models/spline_model.py

```diff
@@ -5,15 +5,15 @@
 from .warp_model import Warp_Galaxy
 from .superellipse_model import SuperEllipse_Galaxy, SuperEllipse_Warp
 from .foureirellipse_model import FourierEllipse_Galaxy, FourierEllipse_Warp
 from .star_model_object import Star_Model
 from .ray_model import Ray_Galaxy
 from .wedge_model import Wedge_Galaxy
 from ._shared_methods import spline_segment_initialize, select_target
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 
 __all__ = [
     "Spline_Galaxy",
     "Spline_Star",
     "Spline_Warp",
     "Spline_SuperEllipse",
     "Spline_FourierEllipse",
@@ -75,15 +75,16 @@
     parameter_specs = {
         "I(R)": {"units": "log10(flux/arcsec^2)"},
     }
     _parameter_order = Star_Model._parameter_order + ("I(R)",)
     useable = True
     extend_profile = True
 
-    def transform_coordinates(self, X, Y):
+    @default_internal
+    def transform_coordinates(self, X=None, Y=None, image=None, parameters=None):
         return X, Y
 
     from ._shared_methods import spline_initialize as initialize
     from ._shared_methods import spline_radial_model as radial_model
 
 
 class Spline_Warp(Warp_Galaxy):
@@ -197,19 +198,24 @@
     _parameter_order = Ray_Galaxy._parameter_order + ("I(R)",)
     useable = True
     extend_profile = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         spline_segment_initialize(
-            self, target, segments=self.rays, symmetric=self.symmetric_rays
+            self,
+            target=target,
+            parameters=parameters,
+            segments=self.rays,
+            symmetric=self.symmetric_rays,
         )
 
     from ._shared_methods import spline_iradial_model as iradial_model
 
 
 class Spline_Wedge(Wedge_Galaxy):
     """wedge galaxy model with a spline light profile. The light
@@ -235,19 +241,24 @@
     _parameter_order = Wedge_Galaxy._parameter_order + ("I(R)",)
     useable = True
     extend_profile = True
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         spline_segment_initialize(
-            self, target, segments=self.wedges, symmetric=self.symmetric_wedges
+            self,
+            target=target,
+            parameters=parameters,
+            segments=self.wedges,
+            symmetric=self.symmetric_wedges,
         )
 
     from ._shared_methods import spline_iradial_model as iradial_model
 
 
 # Third Order
 ######################################################################
```

## autoprof/models/star_model_object.py

```diff
@@ -1,10 +1,13 @@
-from .model_object import Component_Model
 import torch
 
+from .model_object import Component_Model
+from ..utils.decorators import default_internal
+
+
 __all__ = ["Star_Model"]
 
 
 class Star_Model(Component_Model):
     """Prototype star model, to be subclassed by other star models which
     define specific behavior. Mostly this just requires that no
     standard PSF convolution is applied to this model as that is to be
@@ -14,15 +17,16 @@
     already been done when constructing the PSF.
 
     """
 
     model_type = f"star {Component_Model.model_type}"
     useable = False
 
-    def radius_metric(self, X, Y):
+    @default_internal
+    def radius_metric(self, X, Y, image=None, parameters=None):
         return torch.sqrt(
             (torch.abs(X) + 1e-8) ** 2 + (torch.abs(Y) + 1e-8) ** 2
         )  # epsilon added for numerical stability of gradient
 
     @property
     def psf_mode(self):
         return "none"
```

## autoprof/models/superellipse_model.py

```diff
@@ -1,12 +1,13 @@
 import torch
 import numpy as np
 
 from .galaxy_model_object import Galaxy_Model
 from .warp_model import Warp_Galaxy
+from ..utils.decorators import default_internal
 
 __all__ = ["SuperEllipse_Galaxy", "SuperEllipse_Warp"]
 
 
 class SuperEllipse_Galaxy(Galaxy_Model):
     """Expanded galaxy model which includes a superellipse transformation
     in its radius metric. This allows for the expression of "boxy" and
@@ -30,19 +31,20 @@
     model_type = f"superellipse {Galaxy_Model.model_type}"
     parameter_specs = {
         "C0": {"units": "C-2", "value": 0.0, "uncertainty": 1e-2, "limits": (-2, None)},
     }
     _parameter_order = Galaxy_Model._parameter_order + ("C0",)
     useable = False
 
-    def radius_metric(self, X, Y):
+    @default_internal
+    def radius_metric(self, X, Y, image=None, parameters=None):
         return torch.pow(
-            torch.pow(torch.abs(X) + 1e-6, self["C0"].value + 2.0)
-            + torch.pow(torch.abs(Y) + 1e-6, self["C0"].value + 2.0),
-            1.0 / (self["C0"].value + 2.0),
+            torch.pow(torch.abs(X) + 1e-8, parameters["C0"].value + 2.0)
+            + torch.pow(torch.abs(Y) + 1e-8, parameters["C0"].value + 2.0),
+            1.0 / (parameters["C0"].value + 2.0),
         )  # epsilon added for numerical stability of gradient
 
 
 class SuperEllipse_Warp(Warp_Galaxy):
     """Expanded warp model which includes a superellipse transformation
     in its radius metric. This allows for the expression of "boxy" and
     "disky" isophotes instead of pure ellipses. This is a common
@@ -66,13 +68,14 @@
     model_type = f"superellipse {Warp_Galaxy.model_type}"
     parameter_specs = {
         "C0": {"units": "C-2", "value": 0.0, "uncertainty": 1e-2, "limits": (-2, None)},
     }
     _parameter_order = Warp_Galaxy._parameter_order + ("C0",)
     useable = False
 
-    def radius_metric(self, X, Y):
+    @default_internal
+    def radius_metric(self, X, Y, image=None, parameters=None):
         return torch.pow(
-            torch.pow(torch.abs(X) + 1e-6, self["C0"].value + 2.0)
-            + torch.pow(torch.abs(Y) + 1e-6, self["C0"].value + 2.0),
-            1.0 / (self["C0"].value + 2.0),
+            torch.pow(torch.abs(X) + 1e-8, parameters["C0"].value + 2.0)
+            + torch.pow(torch.abs(Y) + 1e-8, parameters["C0"].value + 2.0),
+            1.0 / (parameters["C0"].value + 2.0),
         )  # epsilon added for numerical stability of gradient
```

## autoprof/models/warp_model.py

```diff
@@ -1,15 +1,15 @@
 import numpy as np
 import torch
 from scipy.stats import iqr, binned_statistic, binned_statistic_2d
 
 from .galaxy_model_object import Galaxy_Model
 from ..utils.interpolate import cubic_spline_torch
 from ..utils.conversions.coordinates import Axis_Ratio_Cartesian, Rotate_Cartesian
-from ..utils.decorators import ignore_numpy_warnings
+from ..utils.decorators import ignore_numpy_warnings, default_internal
 from ._shared_methods import select_target
 
 __all__ = ["Warp_Galaxy"]
 
 
 class Warp_Galaxy(Galaxy_Model):
     """Galaxy model which includes radially varrying PA and q
@@ -49,63 +49,65 @@
     }
     _parameter_order = Galaxy_Model._parameter_order + ("q(R)", "PA(R)")
     useable = False
 
     @torch.no_grad()
     @ignore_numpy_warnings
     @select_target
-    def initialize(self, target=None):
-        super().initialize(target)
+    @default_internal
+    def initialize(self, target=None, parameters=None, **kwargs):
+        super().initialize(target=target, parameters=parameters)
 
         # create the PA(R) and q(R) profile radii if needed
         for prof_param in ["PA(R)", "q(R)"]:
-            if self[prof_param].prof is None:
-                if self[prof_param].value is None:  # from scratch
+            if parameters[prof_param].prof is None:
+                if parameters[prof_param].value is None:  # from scratch
                     new_prof = [0, 2 * target.pixelscale]
                     while new_prof[-1] < torch.min(self.window.shape / 2):
                         new_prof.append(
                             new_prof[-1]
                             + torch.max(2 * target.pixelscale, new_prof[-1] * 0.2)
                         )
                     new_prof.pop()
                     new_prof.pop()
                     new_prof.append(torch.sqrt(torch.sum((self.window.shape / 2) ** 2)))
-                    self[prof_param].set_profile(new_prof)
+                    parameters[prof_param].set_profile(new_prof)
                 else:  # matching length of a provided profile
                     # create logarithmically spaced profile radii
                     new_prof = [0] + list(
                         np.logspace(
                             np.log10(2 * target.pixelscale),
                             np.log10(torch.max(self.window.shape / 2).item()),
-                            len(self[prof_param].value) - 1,
+                            len(parameters[prof_param].value) - 1,
                         )
                     )
                     # ensure no step is smaller than a pixelscale
                     for i in range(1, len(new_prof)):
                         if new_prof[i] - new_prof[i - 1] < target.pixelscale.item():
                             new_prof[i] = new_prof[i - 1] + target.pixelscale.item()
-                    self[prof_param].set_profile(new_prof)
+                    parameters[prof_param].set_profile(new_prof)
 
-        if not (self["PA(R)"].value is None or self["q(R)"].value is None):
+        if not (parameters["PA(R)"].value is None or parameters["q(R)"].value is None):
             return
 
-        if self["PA(R)"].value is None:
-            self["PA(R)"].set_value(
-                np.zeros(len(self["PA(R)"].prof)), override_locked=True
+        if parameters["PA(R)"].value is None:
+            parameters["PA(R)"].set_value(
+                np.zeros(len(parameters["PA(R)"].prof)), override_locked=True
             )
 
-        if self["q(R)"].value is None:
-            self["q(R)"].set_value(
-                np.ones(len(self["q(R)"].prof)) * 0.9, override_locked=True
+        if parameters["q(R)"].value is None:
+            parameters["q(R)"].set_value(
+                np.ones(len(parameters["q(R)"].prof)) * 0.9, override_locked=True
             )
 
-    def transform_coordinates(self, X, Y):
-        X, Y = super().transform_coordinates(X, Y)
-        R = self.radius_metric(X, Y)
+    @default_internal
+    def transform_coordinates(self, X, Y, image=None, parameters=None):
+        X, Y = super().transform_coordinates(X, Y, image, parameters)
+        R = self.radius_metric(X, Y, image, parameters)
         PA = cubic_spline_torch(
-            self["PA(R)"].prof, -self["PA(R)"].value, R.view(-1)
+            parameters["PA(R)"].prof, -parameters["PA(R)"].value, R.view(-1)
+        ).view(*R.shape)
+        q = cubic_spline_torch(
+            parameters["q(R)"].prof, parameters["q(R)"].value, R.view(-1)
         ).view(*R.shape)
-        q = cubic_spline_torch(self["q(R)"].prof, self["q(R)"].value, R.view(-1)).view(
-            *R.shape
-        )
         X, Y = Rotate_Cartesian(PA, X, Y)
         return X, Y / q
```

## autoprof/models/wedge_model.py

```diff
@@ -1,14 +1,15 @@
 import numpy as np
 import torch
 
 from .galaxy_model_object import Galaxy_Model
 from .parameter_object import Parameter
 from ..utils.interpolate import cubic_spline_torch
 from ..utils.conversions.coordinates import Axis_Ratio_Cartesian
+from ..utils.decorators import default_internal
 
 __all__ = ["Wedge_Galaxy"]
 
 
 class Wedge_Galaxy(Galaxy_Model):
     """Variant of the ray model where no smooth transition is performed
     between regions as a function of theta, instead there is a sharp
@@ -23,61 +24,69 @@
     of the wedge model which is "wedges" or the number of wedges in
     the model.
 
     """
 
     model_type = f"wedge {Galaxy_Model.model_type}"
     special_kwargs = Galaxy_Model.special_kwargs + ["wedges"]
+    wedges = 2
+    track_attrs = Galaxy_Model.track_attrs + ["wedges"]
     useable = False
 
     def __init__(self, *args, **kwargs):
         self.symmetric_wedges = True
         super().__init__(*args, **kwargs)
         self.wedges = kwargs.get("wedges", 2)
 
-    def angular_metric(self, X, Y):
+    @default_internal
+    def angular_metric(self, X, Y, image=None, parameters=None):
         return torch.atan2(Y, X)
 
-    def polar_model(self, R, T, image):
+    @default_internal
+    def polar_model(self, R, T, image=None, parameters=None):
         model = torch.zeros_like(R)
         if self.wedges % 2 == 0 and self.symmetric_wedges:
             for w in range(self.wedges):
                 angles = (T - (w * np.pi / self.wedges)) % np.pi
                 indices = torch.logical_or(
                     angles < (np.pi / (2 * self.wedges)),
                     angles >= (np.pi * (1 - 1 / (2 * self.wedges))),
                 )
-                model[indices] += self.iradial_model(w, R[indices], image)
+                model[indices] += self.iradial_model(w, R[indices], image, parameters)
         elif self.wedges % 2 == 1 and self.symmetric_wedges:
             for w in range(self.wedges):
                 angles = (T - (w * np.pi / self.wedges)) % (2 * np.pi)
                 indices = torch.logical_or(
                     angles < (np.pi / (2 * self.wedges)),
                     angles >= (np.pi * (2 - 1 / (2 * self.wedges))),
                 )
-                model[indices] += self.iradial_model(w, R[indices], image)
+                model[indices] += self.iradial_model(w, R[indices], image, parameters)
                 angles = (T - (np.pi + w * np.pi / self.wedges)) % (2 * np.pi)
                 indices = torch.logical_or(
                     angles < (np.pi / (2 * self.wedges)),
                     angles >= (np.pi * (2 - 1 / (2 * self.wedges))),
                 )
-                model[indices] += self.iradial_model(w, R[indices], image)
+                model[indices] += self.iradial_model(w, R[indices], image, parameters)
         else:
             for w in range(self.wedges):
                 angles = (T - (w * 2 * np.pi / self.wedges)) % (2 * np.pi)
                 indices = torch.logical_or(
                     angles < (np.pi / self.wedges),
                     angles >= (np.pi * (2 - 1 / self.wedges)),
                 )
-                model[indices] += self.iradial_model(w, R[indices], image)
+                model[indices] += self.iradial_model(w, R[indices], image, parameters)
         return model
 
-    def evaluate_model(self, image, X = None, Y = None, **kwargs):
-        if X is None or Y is None:
+    @default_internal
+    def evaluate_model(self, X=None, Y=None, image=None, parameters=None, **kwargs):
+        if X is None:
             X, Y = image.get_coordinate_meshgrid_torch(
-                self["center"].value[0], self["center"].value[1]
+                parameters["center"].value[0], parameters["center"].value[1]
             )
-        XX, YY = self.transform_coordinates(X, Y)
+        XX, YY = self.transform_coordinates(X, Y, image, parameters)
 
         return self.polar_model(
-            self.radius_metric(XX, YY), self.angular_metric(XX, YY), image
+            self.radius_metric(XX, YY, image=image, parameters=parameters),
+            self.angular_metric(XX, YY, image=image, parameters=parameters),
+            image=image,
+            parameters=parameters,
         )
```

## autoprof/plots/image.py

```diff
@@ -59,15 +59,23 @@
     )
 
     return fig, ax
 
 
 @torch.no_grad()
 def model_image(
-        fig, ax, model, sample_image=None, window=None, target=None, showcbar=True, target_mask=False, **kwargs
+    fig,
+    ax,
+    model,
+    sample_image=None,
+    window=None,
+    target=None,
+    showcbar=True,
+    target_mask=False,
+    **kwargs,
 ):
     if sample_image is None:
         sample_image = model.make_model_image()
         sample_image = model(sample_image)
     if target is None:
         target = model.target
     if window is None:
@@ -181,28 +189,30 @@
         **imshow_kwargs,
     )
     if showcbar:
         if normalize_residuals:
             default_label = f"tan$^{{-1}}$((Target - {model.name}) / $\\sigma$)"
         else:
             default_label = f"tan$^{{-1}}$(Target - {model.name})"
-        clb = fig.colorbar(im, ax=ax, label=default_label if clb_label is None else clb_label)
+        clb = fig.colorbar(
+            im, ax=ax, label=default_label if clb_label is None else clb_label
+        )
         clb.ax.set_yticks([])
         clb.ax.set_yticklabels([])
     return fig, ax
 
 
 def model_window(fig, ax, model, rectangle_linewidth=2, **kwargs):
     if isinstance(ax, np.ndarray):
         for axitem in ax:
             model_window(fig, axitem, model, **kwargs)
         return fig, ax
 
     if isinstance(model, Group_Model):
-        for m in model.model_list:
+        for m in model.models.values():
             ax.add_patch(
                 Rectangle(
                     xy=(m.window.origin[0], m.window.origin[1]),
                     width=m.window.shape[0],
                     height=m.window.shape[1],
                     fill=False,
                     linewidth=rectangle_linewidth,
```

## autoprof/plots/profile.py

```diff
@@ -24,15 +24,15 @@
     ax,
     model,
     rad_unit="arcsec",
     extend_profile=1.0,
     R0=0.0,
     resolution=1000,
     doassert=True,
-    plot_kwargs = {},
+    plot_kwargs={},
 ):
     xx = torch.linspace(
         R0,
         torch.max(model.window.shape / 2) * extend_profile,
         int(resolution),
         dtype=AP_config.ap_dtype,
         device=AP_config.ap_device,
```

## autoprof/plots/visuals.py

```diff
@@ -23,17 +23,274 @@
 #     "#477641",  # "#345830",
 #     "#5D986D",  # "#4A7856",
 #     "#88BF9E",  # "#6FB28A",
 #     "#94ECBE",
 #     "#FFFFFF",
 # ]
 
-#grad_list = np.load(os.path.join(os.path.dirname(os.path.abspath(__file__)), "rgb_colours.npy"))
+# grad_list = np.load(os.path.join(os.path.dirname(os.path.abspath(__file__)), "rgb_colours.npy"))
 # not proud of this but it works
-grad_list = [[0.02352941176470601, 0.05490196078431372, 0.03137254901960787], [0.025423221664412132, 0.057920953380312966, 0.033516620406216086], [0.027376785284830882, 0.06093685701603565, 0.035720426678078974], [0.02938891743876659, 0.0639504745699993, 0.03798295006291389], [0.03145841869575705, 0.06696255038243151, 0.04030317185736432], [0.033584075048444885, 0.06997377604547542, 0.04260833195845542], [0.03576465765226276, 0.07298479546414544, 0.044888919486002675], [0.03799892263356237, 0.0759962092973116, 0.0471477168479796], [0.04028561096212802, 0.07900857886908796, 0.049385189300118405], [0.04255435348091496, 0.08202242962578685, 0.05160177112762838], [0.04479522750797262, 0.0850382542012795, 0.053797868796876404], [0.047011290960205, 0.08805651514356005, 0.05597386374386699], [0.04920301153517722, 0.09107764734708199, 0.05813011485045571], [0.05137081101697757, 0.09410206022865564, 0.06026696065107289], [0.05351507020340438, 0.09713013967907827, 0.062384721306060466], [0.05563613318418619, 0.1001622498180042, 0.06448370037222773], [0.057734311075703586, 0.10319873457564618, 0.06656418639667772], [0.0598098852979892, 0.10623991912163352, 0.0686264543561699], [0.06186311046428467, 0.10928611115857814, 0.07067076696111699], [0.06389421694104419, 0.11233760209556845, 0.07269737584065203], [0.06590341312637987, 0.11539466811482368, 0.07470652262295904], [0.06789088748697142, 0.11845757114304345, 0.07669843992315992], [0.06985681038697011, 0.12152655973754478, 0.07867335224943414], [0.07180133573715267, 0.12460186989603428, 0.08063147683667268], [0.07372460248826435, 0.12768372579779083, 0.08257302441578668], [0.07562673598889558, 0.13077234048311664, 0.08449819992578214], [0.07750784922530482, 0.1338679164771084, 0.0864072031748393], [0.0793680439581338, 0.13697064636311304, 0.08830022945588598], [0.08120741176889373, 0.14008071331062474, 0.0901774701215026], [0.08302603502740363, 0.1431982915618533, 0.09203911312243368], [0.08482398778987404, 0.14632354688073884, 0.0938853435134896], [0.08660133663613406, 0.14945663696777384, 0.09571634393019346], [0.08835814145343088, 0.15259771184365092, 0.0975322950391592], [0.09009445617335096, 0.15574691420443426, 0.09933337596485287], [0.09181032946766504, 0.1589043797506794, 0.10111976469511005], [0.09350580540821188, 0.16207023749268656, 0.1028916384675223], [0.0951809240954313, 0.16524461003384922, 0.1046491741385914], [0.09683572225960263, 0.1684276138338816, 0.10639254853734492], [0.09847023383851092, 0.17161935945352033, 0.10812193880494256], [0.10008449053481877, 0.17481995178216395, 0.10983752272163866], [0.10167852235616967, 0.1780294902497653, 0.11153947902233724], [0.10325235814074307, 0.18124806902417712, 0.11322798770185102], [0.10480602607076109, 0.18447577719504085, 0.1149032303108651], [0.10633955417621349, 0.18771269894521686, 0.11656539024350993], [0.10785297083092218, 0.19095891371065837, 0.11821465301736292], [0.10934630524287259, 0.19421449632956456, 0.11985120654661363], [0.11081958794061691, 0.19747951718156898, 0.12147524140906224], [0.11227285125743197, 0.20075404231766003, 0.12308695110755152], [0.113706129814793, 0.2040381335814737, 0.12468653232637883], [0.11511946100664691, 0.20733184872254534, 0.12627418518317554], [0.1165128854858628, 0.21063524150205992, 0.12785011347669853], [0.11788644765418299, 0.21394836179160054, 0.12941452493092973], [0.11924019615691589, 0.21727125566535316, 0.13096763143583748], [0.12057418438355699, 0.2206039654861931, 0.13250964928512182], [0.12188847097547184, 0.2239465299860438, 0.13404079941121932], [0.12318312034172044, 0.2272989843408748, 0.13556130761782226], [0.12445820318406359, 0.23066136024067158, 0.13707140481012495], [0.12571379703214872, 0.2340336859546926, 0.13857132722298834], [0.12694998678982505, 0.23741598639230338, 0.14006131664718174], [0.1281668652935146, 0.2408082831596569, 0.14154162065383566], [0.12936453388351488, 0.24421059461247346, 0.14301249281721415], [0.13054310298908373, 0.24762293590515277, 0.14447419293589053], [0.13170269272811447, 0.25104531903643956, 0.1459269872523864], [0.1328434335221802, 0.25447775289184116, 0.14737114867131162], [0.1339654667276644, 0.2579202432829991, 0.14880695697601956], [0.13506894528368824, 0.26137279298418187, 0.15023469904377038], [0.1361540343774794, 0.26483540176607334, 0.15165466905937425], [0.13722091212776352, 0.2683080664270149, 0.15306716872726295], [0.1382697702867517, 0.271790780821844, 0.15447250748191957], [0.13930081496119553, 0.2752835358884738, 0.1558710026965733], [0.14031426735293703, 0.2787863196723416, 0.15726297989004664], [0.1413103645193169, 0.2822991173488483, 0.15864877293161908], [0.142289360153694, 0.28582191124391093, 0.16002872424375406], [0.1432515253862969, 0.2893546808527299, 0.16140318500251255], [0.1441971496054517, 0.29289740285688415, 0.16277251533545473], [0.14512654129921948, 0.29645005113984313, 0.16413708451681472], [0.1460400289172567, 0.3000125968009987, 0.1654972711597065], [0.14693796175266738, 0.30358500816829653, 0.16685346340510454], [0.14782071084339368, 0.3071672508095593, 0.16820605910731407], [0.14868866989260401, 0.31075928754257476, 0.16955546601563484], [0.14954225620729, 0.3143610784440312, 0.1709021019518895], [0.1503819116541449, 0.31797258085736924, 0.1722463949834796], [0.15120810363154275, 0.32159374939962293, 0.17358878359160151], [0.1520213260562527, 0.32522453596731304, 0.17492971683424066], [0.15282210036320543, 0.32886488974146083, 0.1762696545035385], [0.15361097651642713, 0.33251475719178275, 0.17760906727710982], [0.15438853402891373, 0.3361740820801234, 0.17894843686287198], [0.15515538298892081, 0.3398428054631865, 0.18028825613691796], [0.15591216508980174, 0.34352086569461787, 0.18162902927396304], [0.15665955466015927, 0.3472081984264961, 0.18297127186986703], [0.15739825969072788, 0.3509047366102775, 0.1843155110557227], [0.1581290228539065, 0.35461041049725495, 0.18566228560298584], [0.15885262251157475, 0.35832514763856854, 0.18701214601910962], [0.1595698737062211, 0.36204887288482673, 0.1883656546331343], [0.16028162913006866, 0.365781508385379, 0.18972338567067223], [0.1609887800663473, 0.3695229735872851, 0.19108592531772042], [0.1616922572963582, 0.3732731852340314, 0.19245387177272855], [0.1623930319654953, 0.3770320573640352, 0.19382783528634243], [0.1630921164008896, 0.38079950130898077, 0.1952084381882439], [0.16379056487278745, 0.38457542569203246, 0.19659631490050877], [0.16448947429132857, 0.38835973642596816, 0.19799211193690508], [0.16518998482987113, 0.39215233671127353, 0.19939648788756642], [0.1658932804655635, 0.3959531270342421, 0.20081011338847304], [0.166600589427405, 0.39976200516512433, 0.20223367107520046], [0.16731318454171665, 0.4035788661563645, 0.20366785552039823], [0.1680323834645103, 0.4074036023409737, 0.20511337315448636], [0.16875954879008526, 0.4112361033310768, 0.20657094216908256], [0.16949608802490335, 0.4150762560166792, 0.20804129240268987], [0.17024345341575386, 0.4189239445646968, 0.20952516520821696], [0.17100314162122876, 0.42277905041829333, 0.21102331330192792], [0.17177669321562006, 0.4266414522965662, 0.21253650059345497], [0.1725656920146934, 0.43051102619463094, 0.21406550199656194], [0.17337176421315095, 0.43438764538414765, 0.2156111032203738], [0.174196577324217, 0.4382711804143329, 0.21717410054084768], [0.1750418389125363, 0.4421614991135102, 0.21875530055231346], [0.1759092951125111, 0.44605846659124265, 0.22035551989895852], [0.17680072892538157, 0.4499619452410963, 0.22197558498620257], [0.17771795828963766, 0.4538717947440886, 0.2236163316719602], [0.178662833920936, 0.45778787207287114, 0.22527860493786028], [0.1796372369194738, 0.46171003149669404, 0.22696325854055394], [0.18064307614457878, 0.46563812458721304, 0.22867115464331578], [0.18168228535855538, 0.4695720002251926, 0.23040316342821293], [0.1827568201439772, 0.47351150460815455, 0.23216016268918455], [0.1838686546011176, 0.477456481259039, 0.233943037406457], [0.18501977783468404, 0.48140677103593116, 0.23575267930278093], [0.18621219024170063, 0.4853622121429166, 0.23758998638206003], [0.18744789961499414, 0.4893226401421262, 0.23945586245100942], [0.1887289170794073, 0.49328788796703654, 0.24135121662454895], [0.19005725288048025, 0.4972577859370923, 0.24327696281571337], [0.19143491204781923, 0.5012321617737128, 0.24523401921092142], [0.19286388995773657, 0.505210840617762, 0.2472233077315104], [0.1943461678218979, 0.509193645048545, 0.24924575348250605], [0.1958837081305836, 0.5131803951044065, 0.2513022841896479], [0.1974784500806806, 0.5171709083050143, 0.25339382962574203], [0.1991323050198725, 0.5211649996753929, 0.2555213210274589], [0.20084715193916947, 0.5251624817718009, 0.2576856905037352], [0.20262483304633028, 0.5291631647095255, 0.2598878704369637], [0.204467149452764, 0.5331668561926818, 0.26212879287818813], [0.206375857005755, 0.5371733615461064, 0.2644093889375338], [0.20835266229704946, 0.5411824837494301, 0.26673058817112216], [0.2103992188771397, 0.5451940234734288, 0.26909331796570707], [0.21251712370282538, 0.5492077791187413, 0.2714985029222856], [0.21470791384316384, 0.5532235468570559, 0.2739470642399031], [0.21697306346622774, 0.5572411206748591, 0.27643991910086557], [0.21931398112597572, 0.5612602924198622, 0.2789779800585389], [0.22173200736531357, 0.5652808518501962, 0.28156215442887567], [0.22422841264772203, 0.5693025866864954, 0.28419334368676863], [0.2268043956263523, 0.5733252826669735, 0.2868724428682829], [0.22946108175552465, 0.5773487236056106, 0.28960033997974594], [0.23219952224604845, 0.5813726914535655, 0.2923779154146281], [0.23502069336196157, 0.5853969663639336, 0.29520604137906364], [0.23792549605282798, 0.5894213267599773, 0.2980855813267848], [0.24091475591248918, 0.5934455494069475, 0.30101738940417244], [0.2439892234519782, 0.5974694094876285, 0.3040023099060248], [0.2471495746716238, 0.6014926806817401, 0.3070411767425731], [0.2503964119149868, 0.6055151352493269, 0.31013481291816875], [0.25373026498509416, 0.6095365441182762, 0.3132840300219835], [0.25715159250188796, 0.6135566769761028, 0.3164896277309624], [0.26066078347841287, 0.6175753023661407, 0.31975239332517896], [0.26425815909238537, 0.6215921877882963, 0.3230731012156454], [0.26794397462927927, 0.6256070998045035, 0.32645251248454027], [0.27171842157278525, 0.6296198041490337, 0.32989137443772115], [0.2755816298187335, 0.6336300658438219, 0.3333904201693042], [0.27953366998896156, 0.6376376493189533, 0.3369503681380034], [0.2835745558223273, 0.6416423185384807, 0.34057192175484835], [0.2877042466209889, 0.6456438371317278, 0.3442557689818123], [0.2919226497312409, 0.6496419685302498, 0.34800258194081274], [0.2962296230395252, 0.6536364761106029, 0.3518130165324921], [0.30062497746549316, 0.6576271233431101, 0.3556877120641009], [0.3051084794357496, 0.6616136739467778, 0.3596272908857725], [0.3096798533232689, 0.6655958920505426, 0.3636323580344192], [0.3143387838391119, 0.6695735423610237, 0.3677035008844355], [0.3190849183647877, 0.6735463903369483, 0.37184128880436657], [0.3239178692149385, 0.677514202370436, 0.37604627281865705], [0.3288372158217989, 0.6814767459753105, 0.38031898527358976], [0.33384250683409117, 0.6854337899826277, 0.3846599395064855], [0.33893326212463143, 0.68938510474359, 0.38906962951724855], [0.344108974702066, 0.6933304623400306, 0.39354852964131404], [0.34936911252340047, 0.697269636802651, 0.398097094223074], [0.354713120205116, 0.7012024043371861, 0.40271575728885467], [0.3601404206316701, 0.7051285435586824, 0.407404932218529], [0.365650416461051, 0.7090478357340677, 0.4121650114148717], [0.3712424915278934, 0.7129600650331871, 0.4169963659697734], [0.3769160121453231, 0.7168650187884974, 0.4218993453264664], [0.3826703283074528, 0.7207624877635708, 0.426874276936929], [0.38850477479467865, 0.724652266430624, 0.4319214659136745], [0.39441867218475135, 0.7285341532572063, 0.4370411946751511], [0.4004113277726398, 0.7324079510022498, 0.4422337225840276], [0.40648203640264285, 0.7362734670216392, 0.4474992855776477], [0.41263008121642264, 0.7401305135834749, 0.4528380957899934], [0.41885473432075093, 0.7439789081931996, 0.4582503411645124], [0.42515525737890464, 0.74781847392875, 0.4637361850571962], [0.4315309021296915, 0.7516490397859019, 0.4692957658293329], [0.4379809108381271, 0.755470441033972, 0.4749291964293609], [0.44450451668174257, 0.7592825195820302, 0.4806365639632952], [0.4511009440764859, 0.7630851243557921, 0.48641792925318267], [0.4577694089460426, 0.766878111685348, 0.49227332638307436], [0.46450911893842234, 0.7706613457038759, 0.49820276223198207], [0.47131927359337594, 0.7744346987575222, 0.5042062159932884], [0.47819906446422616, 0.7781980518265826, 0.5102836386800519], [0.4851476751974689, 0.7819512949581628, 0.5164349526156181], [0.4921642815733072, 0.7856943277104902, 0.5226600509088999], [0.49924805151023793, 0.7894270596090324, 0.528958796913626], [0.506398145036514, 0.7931494106146145, 0.5353310236707783], [0.5136137142311699, 0.7968613116037284, 0.5417765333333355], [0.5208939031371336, 0.8005627048612254, 0.5482950965723069], [0.528237847648764, 0.8042535445856207, 0.5548864519629064], [0.5356446753758648, 0.8079337974072546, 0.5615503053495099], [0.5431135054862372, 0.8116034429195591, 0.5682863291878316], [0.5506434485283842, 0.8152624742237489, 0.5750941618624987], [0.558233606235997, 0.8189108984872628, 0.5819734069778754], [0.5658830713155681, 0.8225487375163245, 0.588923632619649], [0.5735909272182081, 0.8261760283430954, 0.5959443705842361], [0.5813562478966682, 0.8297928238278868, 0.6030351155725882], [0.5891780975482949, 0.8333991932770318, 0.6101953243443609], [0.5970555303443447, 0.8369952230771135, 0.6174244148277456], [0.6049875901460008, 0.8405810173463196, 0.6247217651794131], [0.6129733102071075, 0.8441566986038703, 0.6320867127880987], [0.6210117128633796, 0.8477224084586106, 0.6395185532141892], [0.629101809207598, 0.8512783083180583, 0.6470165390563735], [0.6372425987500262, 0.8548245801194263, 0.6545798787348152], [0.6454330690629193, 0.8583614270844092, 0.6622077351784434], [0.6536721954076695, 0.861889074499868, 0.6698992244017301], [0.6619589403427637, 0.8654077705269353, 0.6776534139536473], [0.670292253310307, 0.868917787041518, 0.6854693212183214], [0.6786710701982759, 0.8724194205097873, 0.6933459115430326], [0.6870943128752733, 0.8759129929029018, 0.7012820961645896], [0.6955608886937588, 0.8793988526560546, 0.7092767298994272], [0.7040696899570745, 0.8828773756779759, 0.7173286085559195], [0.7126195933446154, 0.8863489664182553, 0.7254364660189113], [0.7212094592884835, 0.8898140590014009, 0.7335989709460631], [0.7298381312936156, 0.8932731184384776, 0.7418147230026438], [0.738504435191736, 0.8967266419295534, 0.7500822485452499], [0.7472071783175026, 0.900175160273203, 0.7583999956446169], [0.755945148592551, 0.9036192394031619, 0.7667663283120103], [0.7647171134997374, 0.9070594820771404, 0.7751795197609306], [0.7735218189254033, 0.9104965297491636, 0.783637744493875], [0.7823579878412776, 0.9139310646651907, 0.7921390689495337], [0.79122431878925, 0.9173638122327802, 0.8006814403748957], [0.8001194841201199, 0.9207955437304958, 0.8092626734934449], [0.8090421279203749, 0.9242270794429251, 0.817880434416763], [0.8179908635354565, 0.9276592923352225, 0.8265322210808196], [0.8269642705600306, 0.9310931124203533, 0.8352153392634705], [0.8359608911072839, 0.934529532028408, 0.8439268729323351], [0.844979225077973, 0.9379696122690698, 0.852663647247446], [0.8540177240040997, 0.9414144910996233, 0.8614221819497985], [0.863074782804233, 0.9448653935946189, 0.8701986320294973], [0.8721487283913724, 0.9483236452977989, 0.87898871137326], [0.8812378033992858, 0.9517906899876957, 0.8877875933734316], [0.890340142117086, 0.955268113920236, 0.8965897799935405], [0.8994537336219597, 0.9587576798305327, 0.9053889271758421], [0.908576363256908, 0.9622613760595616, 0.9141776092709066], [0.9177055163843063, 0.9657814898283584, 0.9229469978386258], [0.9268382144426769, 0.9693207202671751, 0.9316864204851563], [0.9359707258804478, 0.9728823589346071, 0.9403827547526942], [0.9450980392156855, 0.9764705882352952, 0.9490196078431373]]
+grad_list = [
+    [0.02352941176470601, 0.05490196078431372, 0.03137254901960787],
+    [0.025423221664412132, 0.057920953380312966, 0.033516620406216086],
+    [0.027376785284830882, 0.06093685701603565, 0.035720426678078974],
+    [0.02938891743876659, 0.0639504745699993, 0.03798295006291389],
+    [0.03145841869575705, 0.06696255038243151, 0.04030317185736432],
+    [0.033584075048444885, 0.06997377604547542, 0.04260833195845542],
+    [0.03576465765226276, 0.07298479546414544, 0.044888919486002675],
+    [0.03799892263356237, 0.0759962092973116, 0.0471477168479796],
+    [0.04028561096212802, 0.07900857886908796, 0.049385189300118405],
+    [0.04255435348091496, 0.08202242962578685, 0.05160177112762838],
+    [0.04479522750797262, 0.0850382542012795, 0.053797868796876404],
+    [0.047011290960205, 0.08805651514356005, 0.05597386374386699],
+    [0.04920301153517722, 0.09107764734708199, 0.05813011485045571],
+    [0.05137081101697757, 0.09410206022865564, 0.06026696065107289],
+    [0.05351507020340438, 0.09713013967907827, 0.062384721306060466],
+    [0.05563613318418619, 0.1001622498180042, 0.06448370037222773],
+    [0.057734311075703586, 0.10319873457564618, 0.06656418639667772],
+    [0.0598098852979892, 0.10623991912163352, 0.0686264543561699],
+    [0.06186311046428467, 0.10928611115857814, 0.07067076696111699],
+    [0.06389421694104419, 0.11233760209556845, 0.07269737584065203],
+    [0.06590341312637987, 0.11539466811482368, 0.07470652262295904],
+    [0.06789088748697142, 0.11845757114304345, 0.07669843992315992],
+    [0.06985681038697011, 0.12152655973754478, 0.07867335224943414],
+    [0.07180133573715267, 0.12460186989603428, 0.08063147683667268],
+    [0.07372460248826435, 0.12768372579779083, 0.08257302441578668],
+    [0.07562673598889558, 0.13077234048311664, 0.08449819992578214],
+    [0.07750784922530482, 0.1338679164771084, 0.0864072031748393],
+    [0.0793680439581338, 0.13697064636311304, 0.08830022945588598],
+    [0.08120741176889373, 0.14008071331062474, 0.0901774701215026],
+    [0.08302603502740363, 0.1431982915618533, 0.09203911312243368],
+    [0.08482398778987404, 0.14632354688073884, 0.0938853435134896],
+    [0.08660133663613406, 0.14945663696777384, 0.09571634393019346],
+    [0.08835814145343088, 0.15259771184365092, 0.0975322950391592],
+    [0.09009445617335096, 0.15574691420443426, 0.09933337596485287],
+    [0.09181032946766504, 0.1589043797506794, 0.10111976469511005],
+    [0.09350580540821188, 0.16207023749268656, 0.1028916384675223],
+    [0.0951809240954313, 0.16524461003384922, 0.1046491741385914],
+    [0.09683572225960263, 0.1684276138338816, 0.10639254853734492],
+    [0.09847023383851092, 0.17161935945352033, 0.10812193880494256],
+    [0.10008449053481877, 0.17481995178216395, 0.10983752272163866],
+    [0.10167852235616967, 0.1780294902497653, 0.11153947902233724],
+    [0.10325235814074307, 0.18124806902417712, 0.11322798770185102],
+    [0.10480602607076109, 0.18447577719504085, 0.1149032303108651],
+    [0.10633955417621349, 0.18771269894521686, 0.11656539024350993],
+    [0.10785297083092218, 0.19095891371065837, 0.11821465301736292],
+    [0.10934630524287259, 0.19421449632956456, 0.11985120654661363],
+    [0.11081958794061691, 0.19747951718156898, 0.12147524140906224],
+    [0.11227285125743197, 0.20075404231766003, 0.12308695110755152],
+    [0.113706129814793, 0.2040381335814737, 0.12468653232637883],
+    [0.11511946100664691, 0.20733184872254534, 0.12627418518317554],
+    [0.1165128854858628, 0.21063524150205992, 0.12785011347669853],
+    [0.11788644765418299, 0.21394836179160054, 0.12941452493092973],
+    [0.11924019615691589, 0.21727125566535316, 0.13096763143583748],
+    [0.12057418438355699, 0.2206039654861931, 0.13250964928512182],
+    [0.12188847097547184, 0.2239465299860438, 0.13404079941121932],
+    [0.12318312034172044, 0.2272989843408748, 0.13556130761782226],
+    [0.12445820318406359, 0.23066136024067158, 0.13707140481012495],
+    [0.12571379703214872, 0.2340336859546926, 0.13857132722298834],
+    [0.12694998678982505, 0.23741598639230338, 0.14006131664718174],
+    [0.1281668652935146, 0.2408082831596569, 0.14154162065383566],
+    [0.12936453388351488, 0.24421059461247346, 0.14301249281721415],
+    [0.13054310298908373, 0.24762293590515277, 0.14447419293589053],
+    [0.13170269272811447, 0.25104531903643956, 0.1459269872523864],
+    [0.1328434335221802, 0.25447775289184116, 0.14737114867131162],
+    [0.1339654667276644, 0.2579202432829991, 0.14880695697601956],
+    [0.13506894528368824, 0.26137279298418187, 0.15023469904377038],
+    [0.1361540343774794, 0.26483540176607334, 0.15165466905937425],
+    [0.13722091212776352, 0.2683080664270149, 0.15306716872726295],
+    [0.1382697702867517, 0.271790780821844, 0.15447250748191957],
+    [0.13930081496119553, 0.2752835358884738, 0.1558710026965733],
+    [0.14031426735293703, 0.2787863196723416, 0.15726297989004664],
+    [0.1413103645193169, 0.2822991173488483, 0.15864877293161908],
+    [0.142289360153694, 0.28582191124391093, 0.16002872424375406],
+    [0.1432515253862969, 0.2893546808527299, 0.16140318500251255],
+    [0.1441971496054517, 0.29289740285688415, 0.16277251533545473],
+    [0.14512654129921948, 0.29645005113984313, 0.16413708451681472],
+    [0.1460400289172567, 0.3000125968009987, 0.1654972711597065],
+    [0.14693796175266738, 0.30358500816829653, 0.16685346340510454],
+    [0.14782071084339368, 0.3071672508095593, 0.16820605910731407],
+    [0.14868866989260401, 0.31075928754257476, 0.16955546601563484],
+    [0.14954225620729, 0.3143610784440312, 0.1709021019518895],
+    [0.1503819116541449, 0.31797258085736924, 0.1722463949834796],
+    [0.15120810363154275, 0.32159374939962293, 0.17358878359160151],
+    [0.1520213260562527, 0.32522453596731304, 0.17492971683424066],
+    [0.15282210036320543, 0.32886488974146083, 0.1762696545035385],
+    [0.15361097651642713, 0.33251475719178275, 0.17760906727710982],
+    [0.15438853402891373, 0.3361740820801234, 0.17894843686287198],
+    [0.15515538298892081, 0.3398428054631865, 0.18028825613691796],
+    [0.15591216508980174, 0.34352086569461787, 0.18162902927396304],
+    [0.15665955466015927, 0.3472081984264961, 0.18297127186986703],
+    [0.15739825969072788, 0.3509047366102775, 0.1843155110557227],
+    [0.1581290228539065, 0.35461041049725495, 0.18566228560298584],
+    [0.15885262251157475, 0.35832514763856854, 0.18701214601910962],
+    [0.1595698737062211, 0.36204887288482673, 0.1883656546331343],
+    [0.16028162913006866, 0.365781508385379, 0.18972338567067223],
+    [0.1609887800663473, 0.3695229735872851, 0.19108592531772042],
+    [0.1616922572963582, 0.3732731852340314, 0.19245387177272855],
+    [0.1623930319654953, 0.3770320573640352, 0.19382783528634243],
+    [0.1630921164008896, 0.38079950130898077, 0.1952084381882439],
+    [0.16379056487278745, 0.38457542569203246, 0.19659631490050877],
+    [0.16448947429132857, 0.38835973642596816, 0.19799211193690508],
+    [0.16518998482987113, 0.39215233671127353, 0.19939648788756642],
+    [0.1658932804655635, 0.3959531270342421, 0.20081011338847304],
+    [0.166600589427405, 0.39976200516512433, 0.20223367107520046],
+    [0.16731318454171665, 0.4035788661563645, 0.20366785552039823],
+    [0.1680323834645103, 0.4074036023409737, 0.20511337315448636],
+    [0.16875954879008526, 0.4112361033310768, 0.20657094216908256],
+    [0.16949608802490335, 0.4150762560166792, 0.20804129240268987],
+    [0.17024345341575386, 0.4189239445646968, 0.20952516520821696],
+    [0.17100314162122876, 0.42277905041829333, 0.21102331330192792],
+    [0.17177669321562006, 0.4266414522965662, 0.21253650059345497],
+    [0.1725656920146934, 0.43051102619463094, 0.21406550199656194],
+    [0.17337176421315095, 0.43438764538414765, 0.2156111032203738],
+    [0.174196577324217, 0.4382711804143329, 0.21717410054084768],
+    [0.1750418389125363, 0.4421614991135102, 0.21875530055231346],
+    [0.1759092951125111, 0.44605846659124265, 0.22035551989895852],
+    [0.17680072892538157, 0.4499619452410963, 0.22197558498620257],
+    [0.17771795828963766, 0.4538717947440886, 0.2236163316719602],
+    [0.178662833920936, 0.45778787207287114, 0.22527860493786028],
+    [0.1796372369194738, 0.46171003149669404, 0.22696325854055394],
+    [0.18064307614457878, 0.46563812458721304, 0.22867115464331578],
+    [0.18168228535855538, 0.4695720002251926, 0.23040316342821293],
+    [0.1827568201439772, 0.47351150460815455, 0.23216016268918455],
+    [0.1838686546011176, 0.477456481259039, 0.233943037406457],
+    [0.18501977783468404, 0.48140677103593116, 0.23575267930278093],
+    [0.18621219024170063, 0.4853622121429166, 0.23758998638206003],
+    [0.18744789961499414, 0.4893226401421262, 0.23945586245100942],
+    [0.1887289170794073, 0.49328788796703654, 0.24135121662454895],
+    [0.19005725288048025, 0.4972577859370923, 0.24327696281571337],
+    [0.19143491204781923, 0.5012321617737128, 0.24523401921092142],
+    [0.19286388995773657, 0.505210840617762, 0.2472233077315104],
+    [0.1943461678218979, 0.509193645048545, 0.24924575348250605],
+    [0.1958837081305836, 0.5131803951044065, 0.2513022841896479],
+    [0.1974784500806806, 0.5171709083050143, 0.25339382962574203],
+    [0.1991323050198725, 0.5211649996753929, 0.2555213210274589],
+    [0.20084715193916947, 0.5251624817718009, 0.2576856905037352],
+    [0.20262483304633028, 0.5291631647095255, 0.2598878704369637],
+    [0.204467149452764, 0.5331668561926818, 0.26212879287818813],
+    [0.206375857005755, 0.5371733615461064, 0.2644093889375338],
+    [0.20835266229704946, 0.5411824837494301, 0.26673058817112216],
+    [0.2103992188771397, 0.5451940234734288, 0.26909331796570707],
+    [0.21251712370282538, 0.5492077791187413, 0.2714985029222856],
+    [0.21470791384316384, 0.5532235468570559, 0.2739470642399031],
+    [0.21697306346622774, 0.5572411206748591, 0.27643991910086557],
+    [0.21931398112597572, 0.5612602924198622, 0.2789779800585389],
+    [0.22173200736531357, 0.5652808518501962, 0.28156215442887567],
+    [0.22422841264772203, 0.5693025866864954, 0.28419334368676863],
+    [0.2268043956263523, 0.5733252826669735, 0.2868724428682829],
+    [0.22946108175552465, 0.5773487236056106, 0.28960033997974594],
+    [0.23219952224604845, 0.5813726914535655, 0.2923779154146281],
+    [0.23502069336196157, 0.5853969663639336, 0.29520604137906364],
+    [0.23792549605282798, 0.5894213267599773, 0.2980855813267848],
+    [0.24091475591248918, 0.5934455494069475, 0.30101738940417244],
+    [0.2439892234519782, 0.5974694094876285, 0.3040023099060248],
+    [0.2471495746716238, 0.6014926806817401, 0.3070411767425731],
+    [0.2503964119149868, 0.6055151352493269, 0.31013481291816875],
+    [0.25373026498509416, 0.6095365441182762, 0.3132840300219835],
+    [0.25715159250188796, 0.6135566769761028, 0.3164896277309624],
+    [0.26066078347841287, 0.6175753023661407, 0.31975239332517896],
+    [0.26425815909238537, 0.6215921877882963, 0.3230731012156454],
+    [0.26794397462927927, 0.6256070998045035, 0.32645251248454027],
+    [0.27171842157278525, 0.6296198041490337, 0.32989137443772115],
+    [0.2755816298187335, 0.6336300658438219, 0.3333904201693042],
+    [0.27953366998896156, 0.6376376493189533, 0.3369503681380034],
+    [0.2835745558223273, 0.6416423185384807, 0.34057192175484835],
+    [0.2877042466209889, 0.6456438371317278, 0.3442557689818123],
+    [0.2919226497312409, 0.6496419685302498, 0.34800258194081274],
+    [0.2962296230395252, 0.6536364761106029, 0.3518130165324921],
+    [0.30062497746549316, 0.6576271233431101, 0.3556877120641009],
+    [0.3051084794357496, 0.6616136739467778, 0.3596272908857725],
+    [0.3096798533232689, 0.6655958920505426, 0.3636323580344192],
+    [0.3143387838391119, 0.6695735423610237, 0.3677035008844355],
+    [0.3190849183647877, 0.6735463903369483, 0.37184128880436657],
+    [0.3239178692149385, 0.677514202370436, 0.37604627281865705],
+    [0.3288372158217989, 0.6814767459753105, 0.38031898527358976],
+    [0.33384250683409117, 0.6854337899826277, 0.3846599395064855],
+    [0.33893326212463143, 0.68938510474359, 0.38906962951724855],
+    [0.344108974702066, 0.6933304623400306, 0.39354852964131404],
+    [0.34936911252340047, 0.697269636802651, 0.398097094223074],
+    [0.354713120205116, 0.7012024043371861, 0.40271575728885467],
+    [0.3601404206316701, 0.7051285435586824, 0.407404932218529],
+    [0.365650416461051, 0.7090478357340677, 0.4121650114148717],
+    [0.3712424915278934, 0.7129600650331871, 0.4169963659697734],
+    [0.3769160121453231, 0.7168650187884974, 0.4218993453264664],
+    [0.3826703283074528, 0.7207624877635708, 0.426874276936929],
+    [0.38850477479467865, 0.724652266430624, 0.4319214659136745],
+    [0.39441867218475135, 0.7285341532572063, 0.4370411946751511],
+    [0.4004113277726398, 0.7324079510022498, 0.4422337225840276],
+    [0.40648203640264285, 0.7362734670216392, 0.4474992855776477],
+    [0.41263008121642264, 0.7401305135834749, 0.4528380957899934],
+    [0.41885473432075093, 0.7439789081931996, 0.4582503411645124],
+    [0.42515525737890464, 0.74781847392875, 0.4637361850571962],
+    [0.4315309021296915, 0.7516490397859019, 0.4692957658293329],
+    [0.4379809108381271, 0.755470441033972, 0.4749291964293609],
+    [0.44450451668174257, 0.7592825195820302, 0.4806365639632952],
+    [0.4511009440764859, 0.7630851243557921, 0.48641792925318267],
+    [0.4577694089460426, 0.766878111685348, 0.49227332638307436],
+    [0.46450911893842234, 0.7706613457038759, 0.49820276223198207],
+    [0.47131927359337594, 0.7744346987575222, 0.5042062159932884],
+    [0.47819906446422616, 0.7781980518265826, 0.5102836386800519],
+    [0.4851476751974689, 0.7819512949581628, 0.5164349526156181],
+    [0.4921642815733072, 0.7856943277104902, 0.5226600509088999],
+    [0.49924805151023793, 0.7894270596090324, 0.528958796913626],
+    [0.506398145036514, 0.7931494106146145, 0.5353310236707783],
+    [0.5136137142311699, 0.7968613116037284, 0.5417765333333355],
+    [0.5208939031371336, 0.8005627048612254, 0.5482950965723069],
+    [0.528237847648764, 0.8042535445856207, 0.5548864519629064],
+    [0.5356446753758648, 0.8079337974072546, 0.5615503053495099],
+    [0.5431135054862372, 0.8116034429195591, 0.5682863291878316],
+    [0.5506434485283842, 0.8152624742237489, 0.5750941618624987],
+    [0.558233606235997, 0.8189108984872628, 0.5819734069778754],
+    [0.5658830713155681, 0.8225487375163245, 0.588923632619649],
+    [0.5735909272182081, 0.8261760283430954, 0.5959443705842361],
+    [0.5813562478966682, 0.8297928238278868, 0.6030351155725882],
+    [0.5891780975482949, 0.8333991932770318, 0.6101953243443609],
+    [0.5970555303443447, 0.8369952230771135, 0.6174244148277456],
+    [0.6049875901460008, 0.8405810173463196, 0.6247217651794131],
+    [0.6129733102071075, 0.8441566986038703, 0.6320867127880987],
+    [0.6210117128633796, 0.8477224084586106, 0.6395185532141892],
+    [0.629101809207598, 0.8512783083180583, 0.6470165390563735],
+    [0.6372425987500262, 0.8548245801194263, 0.6545798787348152],
+    [0.6454330690629193, 0.8583614270844092, 0.6622077351784434],
+    [0.6536721954076695, 0.861889074499868, 0.6698992244017301],
+    [0.6619589403427637, 0.8654077705269353, 0.6776534139536473],
+    [0.670292253310307, 0.868917787041518, 0.6854693212183214],
+    [0.6786710701982759, 0.8724194205097873, 0.6933459115430326],
+    [0.6870943128752733, 0.8759129929029018, 0.7012820961645896],
+    [0.6955608886937588, 0.8793988526560546, 0.7092767298994272],
+    [0.7040696899570745, 0.8828773756779759, 0.7173286085559195],
+    [0.7126195933446154, 0.8863489664182553, 0.7254364660189113],
+    [0.7212094592884835, 0.8898140590014009, 0.7335989709460631],
+    [0.7298381312936156, 0.8932731184384776, 0.7418147230026438],
+    [0.738504435191736, 0.8967266419295534, 0.7500822485452499],
+    [0.7472071783175026, 0.900175160273203, 0.7583999956446169],
+    [0.755945148592551, 0.9036192394031619, 0.7667663283120103],
+    [0.7647171134997374, 0.9070594820771404, 0.7751795197609306],
+    [0.7735218189254033, 0.9104965297491636, 0.783637744493875],
+    [0.7823579878412776, 0.9139310646651907, 0.7921390689495337],
+    [0.79122431878925, 0.9173638122327802, 0.8006814403748957],
+    [0.8001194841201199, 0.9207955437304958, 0.8092626734934449],
+    [0.8090421279203749, 0.9242270794429251, 0.817880434416763],
+    [0.8179908635354565, 0.9276592923352225, 0.8265322210808196],
+    [0.8269642705600306, 0.9310931124203533, 0.8352153392634705],
+    [0.8359608911072839, 0.934529532028408, 0.8439268729323351],
+    [0.844979225077973, 0.9379696122690698, 0.852663647247446],
+    [0.8540177240040997, 0.9414144910996233, 0.8614221819497985],
+    [0.863074782804233, 0.9448653935946189, 0.8701986320294973],
+    [0.8721487283913724, 0.9483236452977989, 0.87898871137326],
+    [0.8812378033992858, 0.9517906899876957, 0.8877875933734316],
+    [0.890340142117086, 0.955268113920236, 0.8965897799935405],
+    [0.8994537336219597, 0.9587576798305327, 0.9053889271758421],
+    [0.908576363256908, 0.9622613760595616, 0.9141776092709066],
+    [0.9177055163843063, 0.9657814898283584, 0.9229469978386258],
+    [0.9268382144426769, 0.9693207202671751, 0.9316864204851563],
+    [0.9359707258804478, 0.9728823589346071, 0.9403827547526942],
+    [0.9450980392156855, 0.9764705882352952, 0.9490196078431373],
+]
 
 cmap_grad = LinearSegmentedColormap.from_list("cmap_grad", grad_list)
 
 # # grad_list = ["#000000", "#1A1F16", "#1E3F20", "#294C28", "#345830", "#4A7856", "#6FB28A", "#94ECBE", "#FFFFFF"]
 # grad_cdict = {"red": [], "green": [], "blue": []}
 # cpoints = np.linspace(0, 1, len(grad_list))
 # for i in range(len(grad_list)):
```

## autoprof/utils/decorators.py

```diff
@@ -1,14 +1,36 @@
 from functools import wraps
-import numpy as np
+import inspect
 import warnings
 
+import numpy as np
+
+
 def ignore_numpy_warnings(func):
     @wraps(func)
     def wrapped(*args, **kwargs):
-        old_settings = np.seterr(all='ignore')
-        warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)
+        old_settings = np.seterr(all="ignore")
+        warnings.filterwarnings("ignore", category=np.VisibleDeprecationWarning)
         result = func(*args, **kwargs)
         np.seterr(**old_settings)
-        warnings.filterwarnings('default', category=np.VisibleDeprecationWarning)
+        warnings.filterwarnings("default", category=np.VisibleDeprecationWarning)
         return result
+
     return wrapped
+
+
+def default_internal(func):
+    sig = inspect.signature(func)
+
+    @wraps(func)
+    def wrapper(self, *args, **kwargs):
+        bound = sig.bind(self, *args, **kwargs)
+        bound.apply_defaults()
+
+        if bound.arguments.get("image") is None:
+            bound.arguments["image"] = self.target
+        if bound.arguments.get("parameters") is None:
+            bound.arguments["parameters"] = self.parameters
+
+        return func(*bound.args, **bound.kwargs)
+
+    return wrapper
```

## autoprof/utils/interpolate.py

```diff
@@ -5,45 +5,48 @@
 from torch.nn.functional import conv2d
 from .operations import fft_convolve_torch
 
 
 def _h_poly(t):
     """Helper function to compute the 'h' polynomial matrix used in the
     cubic spline.
-    
+
     Args:
         t (Tensor): A 1D tensor representing the normalized x values.
-    
+
     Returns:
         Tensor: A 2D tensor of size (4, len(t)) representing the 'h' polynomial matrix.
 
     """
 
     tt = t[None, :] ** (torch.arange(4, device=t.device)[:, None])
     A = torch.tensor(
         [[1, 0, -3, 2], [0, 1, -2, 1], [0, 0, 3, -2], [0, 0, -1, 1]],
         dtype=t.dtype,
         device=t.device,
     )
     return A @ tt
 
-def cubic_spline_torch(x: torch.Tensor, y: torch.Tensor, xs: torch.Tensor, extend: str = "const") -> torch.Tensor:
+
+def cubic_spline_torch(
+    x: torch.Tensor, y: torch.Tensor, xs: torch.Tensor, extend: str = "const"
+) -> torch.Tensor:
     """Compute the 1D cubic spline interpolation for the given data points
     using PyTorch.
 
     Args:
         x (Tensor): A 1D tensor representing the x-coordinates of the known data points.
         y (Tensor): A 1D tensor representing the y-coordinates of the known data points.
         xs (Tensor): A 1D tensor representing the x-coordinates of the positions where
                      the cubic spline function should be evaluated.
         extend (str, optional): The method for handling extrapolation, either "const" or "linear".
                                 Default is "const".
                                 "const": Use the value of the last known data point for extrapolation.
                                 "linear": Use linear extrapolation based on the last two known data points.
-    
+
     Returns:
         Tensor: A 1D tensor representing the interpolated values at the specified positions (xs).
 
     """
     m = (y[1:] - y[:-1]) / (x[1:] - x[:-1])
     m = torch.cat([m[[0]], (m[1:] + m[:-1]) / 2, m[[-1]]])
     idxs = torch.searchsorted(x[:-1], xs) - 1
```

## autoprof/utils/operations.py

```diff
@@ -2,23 +2,27 @@
 
 import torch
 import matplotlib.pyplot as plt
 import numpy as np
 from astropy.convolution import convolve, convolve_fft
 from scipy.fft import next_fast_len
 
+
 def fft_convolve_torch(img, psf, psf_fft=False, img_prepadded=False):
     # Ensure everything is tensor
     img = torch.as_tensor(img)
     psf = torch.as_tensor(psf)
 
     if img_prepadded:
         s = img.size()
     else:
-        s = tuple(next_fast_len(int(d+(p+1)/2), real = True) for d,p in zip(img.size(), psf.size())) #list(int(d + (p + 1) / 2) for d, p in zip(img.size(), psf.size()))
+        s = tuple(
+            next_fast_len(int(d + (p + 1) / 2), real=True)
+            for d, p in zip(img.size(), psf.size())
+        )  # list(int(d + (p + 1) / 2) for d, p in zip(img.size(), psf.size()))
 
     img_f = torch.fft.rfft2(img, s=s)
 
     if not psf_fft:
         psf_f = torch.fft.rfft2(psf, s=s)
     else:
         psf_f = psf
@@ -67,33 +71,44 @@
         shifts=(
             -int((sum(kernel.size()[0] for kernel in kernels) - 1) / 2),
             -int((sum(kernel.size()[1] for kernel in kernels) - 1) / 2),
         ),
         dims=(0, 1),
     )[: img.size()[0], : img.size()[1]]
 
-def displacement_spacing(N, dtype = torch.float64, device = "cpu"):
-    return torch.linspace(-(N - 1)/(2*N), (N - 1)/(2*N), N, dtype = dtype, device = device)
-    
-def displacement_grid(*N, pixelscale = 1., dtype = torch.float64, device = "cpu"):
-    return torch.meshgrid(*tuple(displacement_spacing(n, dtype = dtype, device = device)*pixelscale for n in N), indexing = "xy")
-    
+
+def displacement_spacing(N, dtype=torch.float64, device="cpu"):
+    return torch.linspace(
+        -(N - 1) / (2 * N), (N - 1) / (2 * N), N, dtype=dtype, device=device
+    )
+
+
+def displacement_grid(*N, pixelscale=1.0, dtype=torch.float64, device="cpu"):
+    return torch.meshgrid(
+        *tuple(
+            displacement_spacing(n, dtype=dtype, device=device) * pixelscale for n in N
+        ),
+        indexing="xy"
+    )
+
+
 def selective_integrate(
-        X: torch.Tensor,
-        Y: torch.Tensor,
-        data: torch.Tensor,
-        image_header: "Image_Header",
-        eval_brightness: Callable,
-        max_depth: int = 3,
-        _depth: int = 1,
-        _reference_brightness: Optional[float] = None,
-        integrate_threshold: float = 1e-2,
+    X: torch.Tensor,
+    Y: torch.Tensor,
+    data: torch.Tensor,
+    image_header: "Image_Header",
+    eval_brightness: Callable,
+    eval_parameters: "Parameter_Group",
+    max_depth: int = 3,
+    _depth: int = 1,
+    _reference_brightness: Optional[float] = None,
+    integrate_threshold: float = 1e-2,
 ):
     """Sample the model at higher resolution than the input image.
-    
+
     This function selectively refines the integration of an input
     image based on the local curvature of the image data.  It
     recursively evaluates the model at higher resolutions in areas
     where the curvature exceeds the specified threshold.  With
     each level of recursion, the function refines the affected
     areas using a 3x3 grid for super-resolution.
 
@@ -107,54 +122,69 @@
       max_depth (int, optional): The maximum recursion depth allowed. Default is 3.
       _reference_brightness (float or None, optional): The reference brightness value used to normalize the curvature
                                                        values. If None, the maximum value of the input data divided by
                                                        10 will be used. Default is None.
 
     Returns:
         None. The function updates the input data tensor in-place with the selectively integrated values.
-  
+
     """
     # check recursion depth, exit if too deep
     if _depth > max_depth:
         return
-        
+
     with torch.no_grad():
         if _reference_brightness is None:
-            _reference_brightness = torch.max(data)/10
-        curvature_kernel = torch.tensor([[0,1.,0],[1.,-4,1.],[0,1.,0]], device = data.device, dtype = data.dtype)
+            _reference_brightness = torch.max(data) / 10
+        curvature_kernel = torch.tensor(
+            [[0, 1.0, 0], [1.0, -4, 1.0], [0, 1.0, 0]],
+            device=data.device,
+            dtype=data.dtype,
+        )
         if _depth == 1:
             curvature = torch.abs(fft_convolve_torch(data, curvature_kernel))
-            curvature[:,0] = 0
-            curvature[:,-1] = 0
-            curvature[0,:] = 0
-            curvature[-1,:] = 0
+            curvature[:, 0] = 0
+            curvature[:, -1] = 0
+            curvature[0, :] = 0
+            curvature[-1, :] = 0
             curvature /= _reference_brightness
             select = curvature > integrate_threshold
         else:
-            curvature = torch.sum(data * curvature_kernel, axis = (1,2)) / _reference_brightness
+            curvature = (
+                torch.sum(data * curvature_kernel, axis=(1, 2)) / _reference_brightness
+            )
             select = curvature > integrate_threshold
-            select = select.view(-1,1,1).repeat(1,3,3)
-        
-        # compute the subpixel coordinate shifts for even integration within a pixel 
-        shiftsx, shiftsy = displacement_grid(3, 3, pixelscale = image_header.pixelscale, device = data.device, dtype = data.dtype)
-                        
+            select = select.view(-1, 1, 1).repeat(1, 3, 3)
+
+        # compute the subpixel coordinate shifts for even integration within a pixel
+        shiftsx, shiftsy = displacement_grid(
+            3,
+            3,
+            pixelscale=image_header.pixelscale,
+            device=data.device,
+            dtype=data.dtype,
+        )
+
     # Reshape coordinates to add two dimensions with the super-resolved coordiantes
-    Xs = X[select].view(-1,1,1).repeat(1,3,3) + shiftsx
-    Ys = Y[select].view(-1,1,1).repeat(1,3,3) + shiftsy
+    Xs = X[select].view(-1, 1, 1).repeat(1, 3, 3) + shiftsx
+    Ys = Y[select].view(-1, 1, 1).repeat(1, 3, 3) + shiftsy
     # evaluate the model on the new smaller coordinate grid in each pixel
-    res = eval_brightness(image = image_header.super_resolve(3), X = Xs, Y = Ys)
-    
+    res = eval_brightness(
+        image=image_header.super_resolve(3), parameters=eval_parameters, X=Xs, Y=Ys
+    )
+
     # Apply recursion to integrate any further pixels as needed
     selective_integrate(
-        X = Xs,
-        Y = Ys,
-        data = res,
-        image_header = image_header.super_resolve(3),
-        eval_brightness = eval_brightness,
-        _depth = _depth+1,
-        max_depth = max_depth,
-        _reference_brightness = _reference_brightness,
-        integrate_threshold = integrate_threshold,
+        X=Xs,
+        Y=Ys,
+        data=res,
+        image_header=image_header.super_resolve(3),
+        eval_brightness=eval_brightness,
+        eval_parameters=eval_parameters,
+        _depth=_depth + 1,
+        max_depth=max_depth,
+        _reference_brightness=_reference_brightness,
+        integrate_threshold=integrate_threshold,
     )
-    
+
     # Update the pixels with the new integrated values
-    data[select] = res.sum(axis = (1,2))
+    data[select] = res.sum(axis=(1, 2))
```

## autoprof/utils/conversions/optimization.py

```diff
@@ -1,74 +1,90 @@
 import numpy as np
 import torch
 from ... import AP_config
 
 
 def boundaries(val, limits):
     """val in limits expanded to range -inf to inf"""
-    tval = val if isinstance(val, torch.Tensor) else torch.tensor(val,device=AP_config.ap_device, dtype = AP_config.ap_dtype)
+    tval = (
+        val
+        if isinstance(val, torch.Tensor)
+        else torch.tensor(val, device=AP_config.ap_device, dtype=AP_config.ap_dtype)
+    )
     if limits[0] is None:
         return tval - 1.0 / (tval - limits[1])  # fixme check + or -?
     elif limits[1] is None:
         return tval - 1.0 / (tval - limits[0])
     return torch.tan((tval - limits[0]) * np.pi / (limits[1] - limits[0]) - np.pi / 2)
 
 
 def inv_boundaries(val, limits):
     """val in range -inf to inf compressed to within the limits"""
 
-    tval = torch.as_tensor(val, device = AP_config.ap_device, dtype = AP_config.ap_dtype)
+    tval = torch.as_tensor(val, device=AP_config.ap_device, dtype=AP_config.ap_dtype)
     if limits[0] is None:
         return (tval + limits[1] - torch.sqrt(torch.pow(tval - limits[1], 2) + 4)) * 0.5
     elif limits[1] is None:
         return (tval + limits[0] + torch.sqrt(torch.pow(tval - limits[0], 2) + 4)) * 0.5
     return (torch.arctan(tval) + np.pi / 2) * (limits[1] - limits[0]) / np.pi + limits[
         0
     ]
 
 
 def d_boundaries_dval(val, limits):
     """derivative of: val in limits expanded to range -inf to inf"""
-    tval = torch.as_tensor(val, device = AP_config.ap_device, dtype = AP_config.ap_dtype)
+    tval = torch.as_tensor(val, device=AP_config.ap_device, dtype=AP_config.ap_dtype)
     if limits[0] is None:
         return 1.0 + 1.0 / (tval - limits[1]) ** 2
     elif limits[1] is None:
         return 1.0 - 1.0 / (tval - limits[0]) ** 2
     return (np.pi / (limits[1] - limits[0])) / torch.cos(
         (tval - limits[0]) * np.pi / (limits[1] - limits[0]) - np.pi / 2
     ) ** 2
 
 
 def d_inv_boundaries_dval(val, limits):
     """derivative of: val in range -inf to inf compressed to within the limits"""
-    tval = torch.as_tensor(val, device = AP_config.ap_device, dtype = AP_config.ap_dtype)
+    tval = torch.as_tensor(val, device=AP_config.ap_device, dtype=AP_config.ap_dtype)
     if limits[0] is None:
         return 0.5 - 0.5 * (tval - limits[1]) / torch.sqrt(
             torch.pow(tval - limits[1], 2) + 4
         )
     elif limits[1] is None:
         return 0.5 + 0.5 * (tval - limits[0]) / torch.sqrt(
             torch.pow(tval - limits[0], 2) + 4
         )
     return (limits[1] - limits[0]) / (np.pi * (tval ** 2 + 1))
 
 
 def cyclic_boundaries(val, limits):
     """Applies cyclic boundary conditions to the input value."""
-    tval = val if isinstance(val, torch.Tensor) else torch.tensor(val,device=AP_config.ap_device, dtype = AP_config.ap_dtype)
+    tval = (
+        val
+        if isinstance(val, torch.Tensor)
+        else torch.tensor(val, device=AP_config.ap_device, dtype=AP_config.ap_dtype)
+    )
     return limits[0] + ((tval - limits[0]) % (limits[1] - limits[0]))
 
 
 def cyclic_difference_torch(val1, val2, period):
     """Applies the difference operation between two values with cyclic
     boundary conditions.
 
     """
-    tval1 = val1 if isinstance(val1, torch.Tensor) else torch.tensor(val1, device = AP_config.ap_device, dtype = AP_config.ap_dtype)
-    tval2 = val2 if isinstance(val2, torch.Tensor) else torch.tensor(val2, device = AP_config.ap_device, dtype = AP_config.ap_dtype)
+    tval1 = (
+        val1
+        if isinstance(val1, torch.Tensor)
+        else torch.tensor(val1, device=AP_config.ap_device, dtype=AP_config.ap_dtype)
+    )
+    tval2 = (
+        val2
+        if isinstance(val2, torch.Tensor)
+        else torch.tensor(val2, device=AP_config.ap_device, dtype=AP_config.ap_dtype)
+    )
     return torch.arcsin(torch.sin((tval1 - tval2) * np.pi / period)) * period / np.pi
 
 
 def cyclic_difference_np(val1, val2, period):
     """Applies the difference operation between two values with cyclic
     boundary conditions.
```

## autoprof/utils/initialize/construct_psf.py

```diff
@@ -1,63 +1,68 @@
 import numpy as np
 
 from .center import Lanczos_peak, center_of_mass, GaussianDensity_Peak
 from ..interpolate import shift_Lanczos_np, point_Lanczos
 
 
-def gaussian_psf(sigma, img_width, pixelscale, upsample = 4):
+def gaussian_psf(sigma, img_width, pixelscale, upsample=4):
     assert img_width % 2 == 1, "psf images should have an odd shape"
 
     # Number of super sampled pixels
     N = img_width * upsample
     # Grid of centered pixel locations
     XX, YY = np.meshgrid(
         np.linspace(
-            -(N - 1) * pixelscale / (2*upsample),
-            (N - 1) * pixelscale / (2*upsample),
+            -(N - 1) * pixelscale / (2 * upsample),
+            (N - 1) * pixelscale / (2 * upsample),
             N,
         ),
         np.linspace(
-            -(N - 1) * pixelscale / (2*upsample),
-            (N - 1) * pixelscale / (2*upsample),
+            -(N - 1) * pixelscale / (2 * upsample),
+            (N - 1) * pixelscale / (2 * upsample),
             N,
         ),
     )
     # Evaluate the Gaussian at each pixel
     ZZ = np.exp(-0.5 * (XX ** 2 + YY ** 2) / sigma ** 2)
 
     # Reduce the super-sampling back to native resolution
-    ZZ = ZZ.reshape(img_width, upsample, img_width, upsample).sum(axis = (1,3)) / (upsample**2)
+    ZZ = ZZ.reshape(img_width, upsample, img_width, upsample).sum(axis=(1, 3)) / (
+        upsample ** 2
+    )
 
     # Normalize the PSF
     return ZZ / np.sum(ZZ)
 
-def moffat_psf(n, Rd, img_width, pixelscale, upsample = 4):
+
+def moffat_psf(n, Rd, img_width, pixelscale, upsample=4):
     assert img_width % 2 == 1, "psf images should have an odd shape"
 
     # Number of super sampled pixels
     N = img_width * upsample
     # Grid of centered pixel locations
     XX, YY = np.meshgrid(
         np.linspace(
-            -(N - 1) * pixelscale / (2*upsample),
-            (N - 1) * pixelscale / (2*upsample),
+            -(N - 1) * pixelscale / (2 * upsample),
+            (N - 1) * pixelscale / (2 * upsample),
             N,
         ),
         np.linspace(
-            -(N - 1) * pixelscale / (2*upsample),
-            (N - 1) * pixelscale / (2*upsample),
+            -(N - 1) * pixelscale / (2 * upsample),
+            (N - 1) * pixelscale / (2 * upsample),
             N,
         ),
     )
     # Evaluate the Moffat at each pixel
-    ZZ = 1. / (1. + (XX ** 2 + YY ** 2) / (Rd**2)) ** n
+    ZZ = 1.0 / (1.0 + (XX ** 2 + YY ** 2) / (Rd ** 2)) ** n
 
     # Reduce the super-sampling back to native resolution
-    ZZ = ZZ.reshape(img_width, upsample, img_width, upsample).sum(axis = (1,3)) / (upsample**2)
+    ZZ = ZZ.reshape(img_width, upsample, img_width, upsample).sum(axis=(1, 3)) / (
+        upsample ** 2
+    )
 
     # Normalize the PSF
     return ZZ / np.sum(ZZ)
 
 
 def construct_psf(
     stars, image, sky_est, size=51, mask=None, keep_init=False, Lanczos_scale=3
```

## Comparing `autoprof-0.7.3.dist-info/LICENSE` & `autoprof-0.8.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `autoprof-0.7.3.dist-info/METADATA` & `autoprof-0.8.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: autoprof
-Version: 0.7.3
+Version: 0.8.0
 Summary: A fast, flexible, differentiable, and automated astronomical image modelling tool for precise parallel multi-wavelength photometry
 Home-page: https://github.com/ConnorStoneAstro/AutoProf
 Author: Connor Stone
 Author-email: connorstone628@gmail.com
 License: GPL-3.0 license
 Platform: UNKNOWN
 Classifier: Development Status :: 1 - Planning
```

## Comparing `autoprof-0.7.3.dist-info/RECORD` & `autoprof-0.8.0.dist-info/RECORD`

 * *Files 21% similar despite different names*

```diff
@@ -1,82 +1,83 @@
 autoprof/AP_config.py,sha256=fIxYQr2lxsjA3ONiSLuKMAKmL2BPM7Xz99L3gGab8AQ,3171
-autoprof/__init__.py,sha256=EvAu6BNZZ-ViFu_bh8IwHsvAE8tgubgY60hSZ5NL0Mk,5755
+autoprof/__init__.py,sha256=62qfOaqhJ3suxA4LfXORhywoMFfCCHx_SQlFuZxh6_k,5755
 autoprof/__main__.py,sha256=Ce_QoW2_-x3o3ZXbErfBFzJ_M20JzoaB3dUvwzAhXx4,281
 autoprof/fit/__init__.py,sha256=vPVo-YP7Ns-Y9hsAI_riY93kTtIi1FD5yw6Mdw3bQUY,1092
-autoprof/fit/base.py,sha256=XqH9gP9BgtFX05vO6aUg40XpDJ8jLTn1DmWhtF5HGvs,6682
+autoprof/fit/base.py,sha256=1xFrf1vGTdGEojEqfIb0L6jrpFiWTaESTTLYFUsO3ls,6406
 autoprof/fit/gp.py,sha256=PvMC6LeAIYWwDteVVo3AY7lb_TkQOY2-C5yWfK4CpUY,30
-autoprof/fit/gradient.py,sha256=N1RzlOkWjo0yoNxD483v6EVFtvNODiypLkCy7WoeEQw,6704
-autoprof/fit/hmc.py,sha256=4g0KS4U_mLbUT6VrNOcEG1bgXginFC2h0FQ-qZEiZok,6912
-autoprof/fit/iterative.py,sha256=5Jaa5ks3gsr0u1stvMNSZbCpJ71Q4E1RGhVV8SGWnJA,13206
-autoprof/fit/lm.py,sha256=kNPkGjTv9izC5oMAV56EMkBP7vHf8XyYqhUIJUK-x4k,31364
-autoprof/fit/mhmcmc.py,sha256=-3f_LfXFzB1KivEhHqdfUT38CpLw5JE_7_6aKWNjOJY,4317
-autoprof/fit/nuts.py,sha256=7DHgU_27_Eai7LF-Y_imDq4JUzbaiVSBzmYNszxHRPY,7109
+autoprof/fit/gradient.py,sha256=xnOaSpTjS1YWaDm-GIk0woorWItpO6XJdejIAzt-DEY,6961
+autoprof/fit/hmc.py,sha256=aqytP4wzaGriwgeKppcangTMLZ10g7zYaXid9WabvmY,6939
+autoprof/fit/iterative.py,sha256=l82bvoU0Qqvm0KPL-NXnV2yx_q86uHARTn_gNnikN3A,13401
+autoprof/fit/lm.py,sha256=shI1PvH09zfzsyDBaGi3hO-l_aWGZjtJYHfoHtviR6g,31418
+autoprof/fit/mhmcmc.py,sha256=nBHVLWzrhJsZ0FaC-iYUYmjnapFwtSQFUryTYd4dZIQ,4381
+autoprof/fit/nuts.py,sha256=HM_ZAQrf1a_UhE6QjewgU1EbhNPplP9o3YfG8wYDfbQ,7150
 autoprof/image/__init__.py,sha256=UPRYMGXs_WUIEkyoDh0467vU495wES6JOLkL9kFKMP8,1150
-autoprof/image/image_header.py,sha256=EZc6YXArsirO5TIYOHzAcQXQseINYGmQBK6RbU637cI,11195
-autoprof/image/image_object.py,sha256=qqZ6hKfp3c0et4om-AmagH7Np4vZmjxaROJ_ysq81z8,21644
+autoprof/image/image_header.py,sha256=mnapNv8hdZKUnCa18QlxdOzrGgyjrhFEHMPq9cxTA4A,11526
+autoprof/image/image_object.py,sha256=_UGMOu3HiPFsflAHEe8AYhbhFa02MRN7FcnIyaffQt4,21625
 autoprof/image/jacobian_image.py,sha256=1s3eAq3xB353i_srThMZVaJ7Wp-aXu0POLfvZ1JQSgg,5269
 autoprof/image/model_image.py,sha256=kcGG1_d-mYMUmDsYcJ9bTA7XNecS1rbt4dkRbcPNoLk,6615
-autoprof/image/psf_image.py,sha256=kDZerYwHv8oiXcMGqkkeyGRujkjJ_6h7ffQC1LdUZfQ,6868
-autoprof/image/target_image.py,sha256=vMLjom2MCH6DwozIc9m8sEW8RNJsKFzpVQDM2q6gza8,14679
-autoprof/image/window_object.py,sha256=DbOnZQmbYMQKB1T_Z-Fpc6PdEENFIGxy7QSGLY0s4jI,22836
+autoprof/image/psf_image.py,sha256=cilte2jyfyQP671xEngiS9OsAMPdkZ-BJZlX9Gg-9ow,6721
+autoprof/image/target_image.py,sha256=RR--6U6VULnGB3RnDEQuRuA39i-ECr-lOaJ_XLewO9M,14763
+autoprof/image/window_object.py,sha256=7pUEzy2-TjqGukM9wQ68uiiFC5_FeqN-u5Xgv0nOoBY,22617
 autoprof/models/__init__.py,sha256=V5ziTIawNay5GoqHIz-x1rnIOZqARe5VmMyFPCWLOR8,654
-autoprof/models/_model_methods.py,sha256=rZh4fuVedfFmzaLJsrdZ_a4WG96JTk9E76SX8Pe0Ues,4277
-autoprof/models/_shared_methods.py,sha256=xVoaFC7G93XAA1gW4FEwT7lvfeDl66E00NdvvEgpph0,20408
-autoprof/models/core_model.py,sha256=zP6RtZ39hHORvItYrlV-jnD0Lh56jjYHR52IF3OLJK8,21301
-autoprof/models/edgeon_model.py,sha256=sLMnjHHsBsVrDXzXSyoXe0BOw41lvE_NF5TOqExIuPU,5971
-autoprof/models/exponential_model.py,sha256=UTXjid2c4FzytoNsy92H5a1wNgMMbO7vax8Xxfy90s0,12945
-autoprof/models/flatsky_model.py,sha256=fRWxSHFhMDy_-UBixndvHszgO5NjHAYgkMH0EyKqxHg,2025
-autoprof/models/foureirellipse_model.py,sha256=-_-qhJ1Sm1FEkvsnrylmu2v5x41dmC4nQqi2a4VPWiU,8373
-autoprof/models/galaxy_model_object.py,sha256=oUUW1AYknC9HtvZb-Sx-Rib2DTl-ARyMYpIMPjs1c7c,4905
-autoprof/models/gaussian_model.py,sha256=7tO9Oi42PQz5qnwlC0DTC2bBTolcUuYZB4wW_m2fgAY,11956
-autoprof/models/group_model_object.py,sha256=9D4ESQ6Ip468Qo08LySQDFrSD6ngnmOoAJd5YQSRb8w,14833
-autoprof/models/model_object.py,sha256=Zx4wH5SDf5yB4U5WEDmbbxNduNSpN0Fa8wRNLzwel5k,26717
-autoprof/models/moffat_model.py,sha256=95QW6XkGdTjnoTRUOD4rsb4DtCS6BSKd2SR9rFnzuTo,3487
-autoprof/models/nuker_model.py,sha256=y0kt5RvOyXeFEmyaf2MGerojt0g5SIA5FHpzTub0Ojk,17419
-autoprof/models/parameter_object.py,sha256=7IxvTaTbVl8B6nMsJOdwIYVNUMS6vQpAEz0Hpx9zO5E,17694
-autoprof/models/planesky_model.py,sha256=pvlx5mtww1ICJIDf4ME5k99xo3aayo6hBNPJs2-Xd7I,2292
-autoprof/models/psf_model.py,sha256=bmXqBxpwmf8EBn4CmM47DzJamob5AoDsnixywpe3ggA,3590
-autoprof/models/ray_model.py,sha256=9_VgnGFUaYPh33hQ0Ycoa_13Z-pBC17pKOfhPQY7CWg,4653
-autoprof/models/sersic_model.py,sha256=upYrrTHjkUXB6fTBrROtplImIZXEsDYwykntxZWAqjc,14762
+autoprof/models/_model_methods.py,sha256=pYubEnjjUbsPxIybEXoytEuFmohtTjvF9VeiMVLy5go,3360
+autoprof/models/_shared_methods.py,sha256=SbGqpY1kiwMaPSuZ4ixGQ-PdI5mUdNvAcuqA0Abr8jA,19225
+autoprof/models/core_model.py,sha256=18_EN321UYxLRJSOnI1bbOrMPEIM3LRFUoJh9fVPq6E,12359
+autoprof/models/edgeon_model.py,sha256=0jJyi-pwIgJZnOSb6ADOdxrPeU192zw7D4IibKdf308,6986
+autoprof/models/exponential_model.py,sha256=IlTjMJQp0OAxec5b_clA1U71TuNBCNDYlTl3oYL-UQI,14433
+autoprof/models/flatsky_model.py,sha256=HLvoGE-uwjrIbeuDWav2_qKgo3oxUfdrLfMPaZ6Hx3s,2123
+autoprof/models/foureirellipse_model.py,sha256=3EIwbBnOA4pEk3XuTMbtcWM73pPc0VbPnvonZk8Lhmk,10650
+autoprof/models/galaxy_model_object.py,sha256=c296z3IMsC4zM7XD99mCXhP_t_txEz9F5A1LUj6mVzc,5362
+autoprof/models/gaussian_model.py,sha256=Hbse8M-ifNsf47ozvC4cY2p_189si-mlvs3euTKnwQ8,13269
+autoprof/models/group_model_object.py,sha256=2uZIpa7H27XWDQGwa9z7fo5ieM18qp-F2QJf5G-Xtqw,11139
+autoprof/models/model_object.py,sha256=y8qZDAGDkKMYW8jGXSvxrVx88QmMZ7Z_ihTcuB4Lkyw,27706
+autoprof/models/moffat_model.py,sha256=2IubJNQ40bi3lJu791bqNkqGUUJe-LeogKbl_ci4g9Q,3927
+autoprof/models/nuker_model.py,sha256=MfNh_P4RhWBwgPy-tQjNR_QnlfGJin6tE9e7UKGUwiE,18974
+autoprof/models/parameter_group.py,sha256=ctOQfhfUUiACOimNynmweJW4ZoLVmnjdVsyLerPJkUc,12454
+autoprof/models/parameter_object.py,sha256=3bxOeP7MqMkh27_fBz9SMxMQD5dA9ET-V457cdu3xLc,18097
+autoprof/models/planesky_model.py,sha256=_CNa2fZc8qHqN6cm9Yv6Y2kEGInHKy-p0nJ6LCLDeMU,2488
+autoprof/models/psf_model.py,sha256=3H0u0v8etaN2nPzuKyzD-7yH0LwU3Z2n8drDTYreh_k,3785
+autoprof/models/ray_model.py,sha256=RmYcYGFUUbYF10ZwvEgLjr1a2AkEFs5aatHNHyeP8do,5021
+autoprof/models/sersic_model.py,sha256=UPbu40EU3cJHa-_unlOnpqb1A-NKm87BwXgwXCwXg8Q,16233
 autoprof/models/sky_model_object.py,sha256=WD450x05pnwMDOzDo5yhQfqYXAHgE8QPkJLVyKJeFGQ,875
-autoprof/models/spline_model.py,sha256=BqAZ2G9nBdxQaNuFI_gJPAFPYcc25ZuNSm5HvfBaXyw,10300
-autoprof/models/star_model_object.py,sha256=kc57eQy02n02zCJKKqLDXoqoa0ZqgrzBONLpJUgRKZ4,1125
-autoprof/models/superellipse_model.py,sha256=6zfF5DJ2__qu_-2R6Attn4UKC8Z-ru8YL6Rpem40hqw,3073
-autoprof/models/warp_model.py,sha256=7zEmr2bwZ2J8cj4tfvtlPetnSX7jy4DHsF022V6ytM4,4412
-autoprof/models/wedge_model.py,sha256=VKOs0mEYm3WUB-xj_CePEWDxZVj63hxmrKVmiqHtVqw,3546
+autoprof/models/spline_model.py,sha256=oqhe_37BVZh3EAmsMFMtuTt5A8FR8AXuMomPE1tx-S8,10695
+autoprof/models/star_model_object.py,sha256=6KSF_AZ-Ahj3JnWPC7Flihp0VAiZj9TMD_qd9I555Gs,1226
+autoprof/models/superellipse_model.py,sha256=z5tDajtolns9PQR2lrH_zg3hgHtrNuneTZny7IzpwGQ,3259
+autoprof/models/warp_model.py,sha256=VAqnGbqtMsLsKaBzcTontShuM9B7AFe2-GssMahrUwo,4700
+autoprof/models/wedge_model.py,sha256=1d2zwX1RZfWY_5vEg5OyXgKBCVNwFtF7XmfUN5POGtM,4004
 autoprof/parse_config/__init__.py,sha256=CT6gEcILfcEdz3I5nbgqKeno8tyGZsMtHmfXQUWejUA,57
 autoprof/parse_config/basic_config.py,sha256=amQEkpKoDp04RVYXNrO4lO0j4T_G1BK7MaLmemtaN-4,4147
 autoprof/parse_config/galfit_config.py,sha256=0HqkIJwgv3XKiW2EZAidXqneDQRaOkgfMxNksxKwuBY,4590
 autoprof/parse_config/shared_methods.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 autoprof/plots/__init__.py,sha256=p8lf0eFHXeZ7-3s0SHRb3zIH1pR6x_jnMxIPUHaEPls,67
-autoprof/plots/image.py,sha256=1u2WhxvLDbIfC4hTW8tXkN6u2Grj6zkc7sLYrK-RVSs,6903
-autoprof/plots/profile.py,sha256=zyyFTrW-u44d9xt4bX0euAXz765KU7XGZfrmQvgYC8I,7559
+autoprof/plots/image.py,sha256=1bJUoQZ0TBGkB5_C7QzJFReMKnEmE4BKO89i_4wV7Ok,6959
+autoprof/plots/profile.py,sha256=34DuCQscmFsXjSCoFUXJNooQ3wewCTh-npb-p2K1gCk,7557
 autoprof/plots/shared_elements.py,sha256=-9cuoMXOSZh7uB32Fkn2R5wCFecNU3WIGvVrjmP8ESY,3048
-autoprof/plots/visuals.py,sha256=NQPn6pQPxDUhETndE6AaXpeRCwl-dzuKuThaSlvH7Vs,19994
+autoprof/plots/visuals.py,sha256=hZyvNt3wY8rbZOXEtFM6nSkGPili7Mm-4RSd1fnZqMw,21022
 autoprof/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 autoprof/utils/angle_operations.py,sha256=oJp9g9v5v7SGzuDRXILg7B0d2CcXygT3GXAzoUbtPGk,800
-autoprof/utils/decorators.py,sha256=VqQDC7VKc3jo_KwoDlW5Yfje3EW1xO_kWC-oOTEZpao,472
-autoprof/utils/interpolate.py,sha256=_60G41dDv17blkuFOomxDCQtMu_boNnChV5-a6g3KfQ,9820
-autoprof/utils/operations.py,sha256=LLO8LB02L3sJMsmlKiH3XS2m4dZBFxwq2aN8o8v0evs,6369
+autoprof/utils/decorators.py,sha256=Jr7PTg_RO2IMTDy7foPjCNXMoDsWPTReO_VAlO76_GA,976
+autoprof/utils/interpolate.py,sha256=pKldYZuyTnCHWMVkQqWAYSlmz92_Iv4myOKEncVa8MI,9815
+autoprof/utils/operations.py,sha256=FCIv5OBdP21RrqHhXgSzveKsrNTP12525Jut_sQ4pFE,6633
 autoprof/utils/optimization.py,sha256=VkAusKnyc4zyztbceazKADVy85g6VV7qqYIw6V7cQos,963
 autoprof/utils/parametric_profiles.py,sha256=JY6reeVkATmuPkhKY7cWPgrnpZaM--simb-8mS2xh1A,5990
 autoprof/utils/conversions/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 autoprof/utils/conversions/coordinates.py,sha256=zXdOxPurvoh3szKaEKx02jRCK_z1JfWeg17Z1Hl9a7g,2317
 autoprof/utils/conversions/dict_to_hdf5.py,sha256=XIy_JvX8Nrp-9N3sk5F3gIY2YLX5I88HxEYWbPGbfsU,1095
 autoprof/utils/conversions/functions.py,sha256=YEKL5WAZvBQkR_P0DK255SIYtJoRzQmnbcEoCbweHIs,1829
-autoprof/utils/conversions/optimization.py,sha256=SK-NgobNShnoPN4mTXyIHm4EDbEKvxQYjDGwSC9fuBM,3154
+autoprof/utils/conversions/optimization.py,sha256=SpxOQyC1uoaoMhn4U1V9nOrdAdyUWR59LptQ77uVpEY,3260
 autoprof/utils/conversions/units.py,sha256=KtYFzdH1_vG7JAPWiAkrAISfPmsN_0GNk9aJbFWLXEc,2536
 autoprof/utils/initialize/__init__.py,sha256=3loeT7k8s7wtWy_RZvGgTyxnlLKCe3AzpPUBI995Qz0,281
 autoprof/utils/initialize/center.py,sha256=PiL0-oXOzY-J3IUoK-bJy_w1Fv7LZZwdEcN7-kRJcZM,3103
-autoprof/utils/initialize/construct_psf.py,sha256=Ai_drJ50Bi2xQx4UcJpjOCkU3k24lejWolNmHPl0nnc,4495
+autoprof/utils/initialize/construct_psf.py,sha256=B79DqCOfW0rkhHlmNZ9P-lC0oH3JjMsn-A88yNYbw4c,4542
 autoprof/utils/initialize/initialize.py,sha256=V1Epy8vudmquOxSB5S-moCcS7bvjdr5qze6IcqihsSs,3921
 autoprof/utils/initialize/segmentation_map.py,sha256=6fG5U4y5P6MDnX4_6ROBdRhUq6TxgbwVG1V3MaLf7-c,7036
 autoprof/utils/isophote/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 autoprof/utils/isophote/ellipse.py,sha256=p2SGzU067jBIBrKjhYKpnJQF7MSThMcnLajsaXeJ23k,1085
 autoprof/utils/isophote/extract.py,sha256=ousarHmkj7GrgAZ6mO3G-QY0tXjhd8bBh6lHzb--d6U,8531
 autoprof/utils/isophote/integrate.py,sha256=jNOCbSYC1dZO1pasEMcRUqZCpt43DEPVME4Hsa37DKQ,7012
-autoprof-0.7.3.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
-autoprof-0.7.3.dist-info/METADATA,sha256=3KRTMYL8WJtSPWKNAXyiFx873W48mArDa_nylBV5sfs,3812
-autoprof-0.7.3.dist-info/WHEEL,sha256=a-zpFRIJzOq5QfuhBzbhiA1eHTzNCJn8OdRvhdNX0Rk,110
-autoprof-0.7.3.dist-info/entry_points.txt,sha256=CJw03tyO_XyE5_-xxRzbAg74ITHASY47DhUiRVsn67s,57
-autoprof-0.7.3.dist-info/top_level.txt,sha256=8N1I5eyEKnh1QOUENsiy7fDvtU-sfyRCYsUJPzrvPvc,9
-autoprof-0.7.3.dist-info/RECORD,,
+autoprof-0.8.0.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
+autoprof-0.8.0.dist-info/METADATA,sha256=tkmnoO5soCTPRw2ifjp_K9uZ1iZWW0_6_VqsZC9b09M,3812
+autoprof-0.8.0.dist-info/WHEEL,sha256=a-zpFRIJzOq5QfuhBzbhiA1eHTzNCJn8OdRvhdNX0Rk,110
+autoprof-0.8.0.dist-info/entry_points.txt,sha256=CJw03tyO_XyE5_-xxRzbAg74ITHASY47DhUiRVsn67s,57
+autoprof-0.8.0.dist-info/top_level.txt,sha256=8N1I5eyEKnh1QOUENsiy7fDvtU-sfyRCYsUJPzrvPvc,9
+autoprof-0.8.0.dist-info/RECORD,,
```

